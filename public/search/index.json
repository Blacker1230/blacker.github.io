[{"content":"本文旨在回答如下问题：\nRust 项目中，如何配置 dependencies 的路径为指定仓库。 在不指定 branch 或 version 的情况下，dependencies 会拉取什么版本/仓库里的数据。 Rust 项目中，配置 dependencies 的最佳实践。 以下为正文。\n# 如何配置 dependencies 的路径 ","date":"2024-05-07T11:39:00+08:00","permalink":"http://localhost:1313/p/cargo-config-%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"Cargo config 使用备注"},{"content":" 很久没有找工作的经历了，反而由于种种原因，最近接触了一些候选人。总体的感觉是最近是越来越卷了。 候选人的的水平明显比笔者毕业的时候高的多，也可能是笔者太菜了。其中一个合并区间的问题，笔者看到了 一个很有意思的解法。在这里记录下。\n《合并区间》问题的思路很明显：排序、合并。笔者最近见到了一种特殊场景下很有意思的解法：在数据范围较小的情况下，使用桶的思想来 解决，就不再需要进行排序了。算法复杂度也从时间复杂度o(nlgn)降到了o(n)。这里记录下。\n# 题目描述 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。 示例 1： 输入：intervals = [[1,3],[2,6],[8,10],[15,18]] 输出：[[1,6],[8,10],[15,18]] 解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 示例 2： 输入：intervals = [[1,4],[4,5]] 输出：[[1,5]] 解释：区间 [1,4] 和 [4,5] 可被视为重叠区间。 提示： 1 \u0026lt;= intervals.length \u0026lt;= 10000 intervals[i].length == 2 0 \u0026lt;= starti \u0026lt;= endi \u0026lt;= 10000 # 两种解法 # 排序 先排序，然后遍历、比较。关键点在于需要处理好比较时的边界条件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 impl Solution { pub fn merge(mut intervals: Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt;) -\u0026gt; Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt; { let mut merged = vec![]; intervals.sort_by(|x, y| x[0].cmp(\u0026amp;y[0])); let mut interval = (None, None); for v in intervals.iter() { if interval.0.is_none() { interval.0 = Some(v[0]); interval.1 = Some(v[1]); continue; } // [0, 1] and [1, 2] if interval.1.is_some() \u0026amp;\u0026amp; interval.1.unwrap() \u0026gt;= v[0] { if interval.1.unwrap() \u0026lt; v[1] { interval.1 = Some(v[1]); } continue; } // [0, 1] and [2, 3] merged.push(vec![interval.0.unwrap(), interval.1.unwrap()]); interval.0 = Some(v[0]); interval.1 = Some(v[1]); } if interval.0.is_some() { merged.push(vec![interval.0.unwrap(), interval.1.unwrap()]); } merged } } # 桶处理 采用匹配的思路，借助桶来记录数组的各个区间。这个思路还需要再体会下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 impl Solution { pub fn merge(intervals: Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt;) -\u0026gt; Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt; { let mut merged = vec![]; if intervals.len() == 0 { return merged; } // 0. 找出桶的范围。这一步可以去掉，直接设一个 10000 大小的桶。 let mut max = 0; for iter in intervals.iter() { if max \u0026lt; iter[1] { max = iter[1]; } } // 由于 rust 的枚举特性，这里就不需要使用两个 bucket 了。 let mut bucket = vec![None; (max + 1) as usize]; for iter in intervals.iter() { if bucket[iter[0] as usize].is_none() { bucket[iter[0] as usize] = Some(0); } if bucket[iter[1] as usize].is_none() { bucket[iter[1] as usize] = Some(0); } bucket[iter[0] as usize] = Some(bucket[iter[0] as usize].unwrap() + 1); bucket[iter[1] as usize] = Some(bucket[iter[1] as usize].unwrap() - 1); } let mut start = None; let mut sum = 0; let mut p = 0 as usize; loop { if p \u0026gt;= bucket.len() { break; } let iter = bucket[p]; if iter.is_none() { p += 1; continue; } if start.is_none() { start = Some(p); } sum += iter.unwrap(); if sum == 0 { merged.push(vec![start.unwrap() as i32, p as i32]); start = None; } p += 1; } merged } } # 后记 这个问题是leetcode上的56. 合并区间。一般刷题 的人都会刷到。惭愧的是笔者已经没有印象了。得赶紧把插件修一修，有时间刷点题。\n","date":"2024-04-20T17:11:31+08:00","permalink":"http://localhost:1313/p/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/","title":"合并区间"},{"content":" BPF 技术看起来还有很多不易察觉的缺陷。最近又踩了一个坑。记录下。\nLRU_HASH_MAP 在实现的时候，出现了不符合预期的数据驱逐问题：设定一个 512 大小的LRU_HASH_MAP，很可能出现在40-50个key的时候，之前的key就被覆盖。在一段时间未更新时，重新更新也可能会出现异常。总结就是，执行了写入操作，很可能没有写入。这个问题在Elements incorrectly evicted from eBPF LRU hash map有较为详细的描述。\n但是，笔者之所以使用LRU_HASH_MAP主要是期望保持整个程序的鲁棒性：期望可以一直写入key而不需对bpf map的状态进行维护。如果使用固定大小的HASH_MAP，当写入的key超过map的预设大小时，测试的demo会出现崩溃的现象。由于LRU_HASH_MAP的功能出现了不符合预期的情况，显然也就需要使用HASH_MAP来替代了。 笔者遇到的需要使用LRU_HASH_MAP的场景有两种：1. 作为配置项。用户态的代码向BPF MAP里写入配置，而后在BPF里使用。2. 作为数据中转。比如涉及多个hook点配合时，就需要使用BPF MAP来存储一些中间数据。对于场景1，可以直接使用HASH_MAP来替代，用户态添加一些检查的措施，定期批量对MAP进行数据清理以及数据写入即可。但是对于场景2，可能会麻烦很多：数据是随时产出的，用户态没有办法控制其产出的频率、周期。目前能想到的是设置一个较大的MAP（这个异常的触发是否和MAP的大小有关？），仍然使用LRU_HASH_MAP；或者设置一个较大的HASH_MAP，然后定时在用户态进行数据的清理。\n以上。\n","date":"2024-03-12T11:02:00Z","permalink":"http://localhost:1313/p/bpf-lru_hash_map-%E5%8F%8A-hash_map-%E7%9A%84%E4%BD%BF%E7%94%A8%E5%BC%82%E5%B8%B8/","title":"BPF LRU_HASH_MAP 及 HASH_MAP 的使用异常"},{"content":" 最近做了一些 TCP 连接观测相关的项目，又到了一个节奏点上了。这里趁着这个机会，做一些总结，同时描述一下 tcp close 过程中的一些疑惑。\n在一些场景下，对服务的调用观测是很有价值的。笔者最近实践了使用tcp_close对服务主被调信息的观测，在这里作一下记录。\n# 一、tcp close 的一般过程 首先来看一下tcp close的过程。\n对tcp涉及操作的分析最权威的自然是RFC文档。依据RFC-793文档中的描述，tcp close时的状态转移信息为如下：\n但是涉及到具体的Linux下的tcp close的过程分析，文档就比较少了。笔者找到了一篇介绍Linux下tcp操作相关的介绍文档。Analysis_TCP_in_Linux中描述了主动触发close及被动触发close的socket双方涉及的函数调用，这为后面的验证提供了思路。\n# 二、BPF 来观测 tcp close 过程 依据Analysis_TCP_in_Linux中的描述，笔者使用python构建了如下的验证demo。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # coding=UTF-8 import socket import time import getopt import sys srv_ip = \u0026#34;\u0026#34; srv_port = 0 def server(srv_ip, srv_port): conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM) conn.bind((srv_ip, srv_port)) conn.listen(1024) conn.setblocking(1) index = 0 while True: connection, address = conn.accept() try: dst = connection.getpeername() while True: request = connection.recv(1024) req_str = str(request.decode()) if req_str == \u0026#39;end\u0026#39;: # 这里以客户端传输一个特殊信息作为结束信息 # tcp server 和 client 之间的 close 是没有必然联系的 # 只能约定一个关闭条件。此时，无法确定客户端是否发起了断联 print(\u0026#34;rcv end, close...\u0026#34;) connection.close() time.sleep(2) break # pass print(\u0026#34;conn: %s:%d received: %s\u0026#34; % (dst[0], dst[1], req_str)) response = (\u0026#34;client, msg index: %d\u0026#34; % index).encode() connection.send(response) index += 1 print(\u0026#34;conn: %s:%d closed\u0026#34; % (dst[0], dst[1])) except Exception as e: print(\u0026#34;handle exception during dst. %s ...\u0026#34; % e) # pass # pass def client(srv_ip, srv_port): try: server_addr = (srv_ip, srv_port) conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM) conn.connect(server_addr) msg = (\u0026#34;server, msg index: 0\u0026#34;).encode() conn.send(msg) data = conn.recv(1024) print(\u0026#34;rcv from server: %s\u0026#34; % str(data.decode())) conn.send(\u0026#34;end\u0026#34;.encode()) print(\u0026#34;end. close ...\u0026#34;) time.sleep(2) conn.close() time.sleep(2) except Exception as e: print(\u0026#34;connection with server with error, %s\u0026#34; % e) return if __name__ == \u0026#34;__main__\u0026#34;: work_mode = \u0026#34;s\u0026#34; try: opts, args = getopt.getopt(sys.argv[1:], \u0026#34;i:p:s:c\u0026#34;, [\u0026#34;srv_ip=\u0026#34;, \u0026#34;port=\u0026#34;, \u0026#34;server\u0026#34;, \u0026#34;client\u0026#34;]) if len(opts) == 0: print(\u0026#34;unknown opts\u0026#34;) sys.exit(0) for opt, arg in opts: if opt in (\u0026#34;-i\u0026#34;, \u0026#34;--srv_ip\u0026#34;): srv_ip = arg if opt in (\u0026#34;-p\u0026#34;, \u0026#34;--port\u0026#34;): srv_port = int(arg) if opt in (\u0026#34;--server\u0026#34;): work_mode = \u0026#34;s\u0026#34; if opt in (\u0026#34;--client\u0026#34;): work_mode = \u0026#34;c\u0026#34; except Exception as e: print(\u0026#34;unknown args\u0026#34;) sys.exit(0) if work_mode == \u0026#34;s\u0026#34;: server(srv_ip, srv_port) else: client(srv_ip, srv_port) 从demo中可以看到，笔者构建的测试代码中，是server端发起的close，而后client端发起close。\n同时，笔者使用bpftrace构造了如下的观测代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 #include \u0026lt;net/sock.h\u0026gt; /* TCP_ESTABLISHED = 1, TCP_SYN_SENT = 2, TCP_SYN_RECV = 3, TCP_FIN_WAIT1 = 4, TCP_FIN_WAIT2 = 5, TCP_TIME_WAIT = 6, TCP_CLOSE = 7, TCP_CLOSE_WAIT = 8, TCP_LAST_ACK = 9, TCP_LISTEN = 10, TCP_CLOSING = 11, TCP_NEW_SYN_RECV = 12, TCP_MAX_STATES = 13 每个 hook 点关注 进程的 pid, sk_state */ kprobe:tcp_close / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_close] pid: %d, state: %d, sock: %d, sk_max_ack_backlog: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk, $sk-\u0026gt;sk_max_ack_backlog); } kprobe:tcp_set_state / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; $ns = arg1; printf(\u0026#34;[tcp_set_state] pid: %d, state: %d, ns: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $ns, $sk); } kprobe:tcp_rcv_established / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_rcv_established] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_fin / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_fin] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_send_fin / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_send_fin] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_timewait_state_process / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_timewait_state_process] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_rcv_state_process / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_rcv_state_process] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_v4_do_rcv / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_v4_do_rcv] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_timewait_state_process / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_stream_wait_close] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } 首先启动bpftrace，然后启动server，使用client进行通信。此时bpftrace端的输出为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [tcp_close] pid: 2828708, state: 1, sock: -1907214080, sk_max_ack_backlog: 1024 [tcp_set_state] pid: 2828708, state: 1, ns: 4, sk: -1907214080 [tcp_send_fin] pid: 2828708, state: 4, sk: -1907214080 [tcp_v4_do_rcv] pid: 2828708, state: 1, sk: -1907216512 [tcp_rcv_established] pid: 2828708, state: 1, sk: -1907216512 [tcp_fin] pid: 2828708, state: 1, sk: -1907216512 [tcp_set_state] pid: 2828708, state: 1, ns: 8, sk: -1907216512 [tcp_v4_do_rcv] pid: 2855763, state: 1, sk: -1907214080 [tcp_rcv_established] pid: 2855763, state: 1, sk: -1907214080 [tcp_close] pid: 2855763, state: 8, sock: -1907216512, sk_max_ack_backlog: 0 [tcp_set_state] pid: 2855763, state: 8, ns: 9, sk: -1907216512 [tcp_send_fin] pid: 2855763, state: 9, sk: -1907216512 [tcp_timewait_state_process] pid: 2855763, state: 6, sk: -2077492080 [tcp_stream_wait_close] pid: 2855763, state: 6, sk: -2077492080 [tcp_v4_do_rcv] pid: 2855763, state: 9, sk: -1907216512 [tcp_rcv_state_process] pid: 2855763, state: 9, sk: -1907216512 [tcp_set_state] pid: 2855763, state: 9, ns: 7, sk: -1907216512 # 三、笔者的困惑 这里，笔者观测到的结果和Analysis_TCP_in_Linux存在出入，主动发起close的一方，在第三次挥手时，响应的并不是tcp_rcv_state_process。相反的，被动close的socket在第四次挥手时触发了这个函数。而且，主动close的socket，第二次挥手时，响应的socket看起来发生了变更，而且其状态是TCP_ESTABLISHED。这其中需要继续探索。\n以上，作为记录了部分总结。\n","date":"2024-02-24T15:55:00Z","permalink":"http://localhost:1313/p/tcp-close-%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90/","title":"TCP close 过程分析"},{"content":" 搞项目。\n观测服务的请求调用需求是客观存在的。一般是需要观测服务的主动发起的调用信息，但是偶尔也会遇到需要观测服务被调用信息的需求。但是一般待采集的服务都是挂载在LVS下面的。这就势必涉及到LVS预设的工作模式下，一般都是FULLNET，需要的real client ip的信息获取方式。\n笔者通过调研，实现了一种通过BPF来观测挂载在LVS下的RS被调用TCP连接信息的方式。本文中关于toa的操作及代码定义均引用自Huawei/TCP_option_address。\n# 一、效果 先看下采集效果：\n# 二、LVS FullNat 关于LVS的Nat,DR,Tun以及FullNat模式的介绍已经有了很多的资料，比如这篇文章就介绍的很详细。这里笔者附上FullNat模式下的示意图：\n如图所示，如果需要在RS上获取CIP，就涉及到TOA信息的解析。TOA (tcp optional address)是利用tcp协议option字段来传递信息的一种工作方式。关于TOA的约定笔者并没有找到官方的RFC文档。只有一些结构的定义。\n1 2 3 4 5 6 7 /* MUST be 4 bytes alignment */ struct toa_data { __u8 opcode; __u8 opsize; __u16 port; __u32 ip; }; 同时，rfc793里对TCP header的约定如下，理论上toa_data应该写在Options字段中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | |U|A|P|R|S|F| | | Offset| Reserved |R|C|S|S|Y|I| Window | | | |G|K|H|T|N|N| | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ TCP Header Format 一般来说，将real-client ip写入tcp option字段的操作是在LVS上进行的。而解析并且方便RS操作，主要是需要在getname的时候需要返回real-client ip以便于做进一步的业务逻辑，比如按照IP限流等，是RS的toa模块在操作的。一般是在tcp握手的第三个SYN报文处理时，toa.ko通过tcp_v4_syn_recv_sock处理的hook函数方式来触发toa数据的处理。\n这里附一段这里的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 static struct sock * tcp_v4_syn_recv_sock_toa(struct sock *sk, struct sk_buff *skb, struct request_sock *req, struct dst_entry *dst) #endif { struct sock *newsock = NULL; TOA_DBG(\u0026#34;tcp_v4_syn_recv_sock_toa called \u0026#34;); /* call orginal one */ #if LINUX_VERSION_CODE \u0026gt;= KERNEL_VERSION(4,4,0) newsock = tcp_v4_syn_recv_sock(sk, skb, req, dst, req_unhash, own_req); #else newsock = tcp_v4_syn_recv_sock(sk, skb, req, dst); #endif /* set our value if need */ if (NULL != newsock \u0026amp;\u0026amp; NULL == newsock-\u0026gt;sk_user_data) { newsock-\u0026gt;sk_user_data = get_toa_data(skb); if (NULL != newsock-\u0026gt;sk_user_data) TOA_INC_STATS(ext_stats, SYN_RECV_SOCK_TOA_CNT); else TOA_INC_STATS(ext_stats, SYN_RECV_SOCK_NO_TOA_CNT); TOA_DBG(\u0026#34;tcp_v4_syn_recv_sock_toa: set \u0026#34; \u0026#34;sk-\u0026gt;sk_user_data to %p \u0026#34;, newsock-\u0026gt;sk_user_data); } return newsock; } static void *get_toa_data(struct sk_buff *skb) { struct tcphdr *th; int length; unsigned char *ptr; struct toa_data tdata; void *ret_ptr = NULL; unsigned char buff[(15 * 4) - sizeof(struct tcphdr)]; TOA_DBG(\u0026#34;get_toa_data called \u0026#34;); if (NULL != skb) { th = tcp_hdr(skb); length = (th-\u0026gt;doff * 4) - sizeof(struct tcphdr); ptr = skb_header_pointer(skb, sizeof(struct tcphdr), length, buff); if (!ptr) return NULL; while (length \u0026gt; 0) { int opcode = *ptr++; int opsize; switch (opcode) { case TCPOPT_EOL: return NULL; case TCPOPT_NOP:\t/* Ref: RFC 793 section 3.1 */ length--; continue; default: opsize = *ptr++; if (opsize \u0026lt; 2)\t/* \u0026#34;silly options\u0026#34; */ return NULL; if (opsize \u0026gt; length) /* don\u0026#39;t parse partial options */ return NULL; if (TCPOPT_TOA == opcode \u0026amp;\u0026amp; // 254 TCPOLEN_TOA == opsize) { // 8 memcpy(\u0026amp;tdata, ptr - 2, sizeof(tdata)); TOA_DBG(\u0026#34;find toa data: ip = \u0026#34; \u0026#34;%u.%u.%u.%u, port = %u \u0026#34;, NIPQUAD(tdata.ip), ntohs(tdata.port)); memcpy(\u0026amp;ret_ptr, \u0026amp;tdata, sizeof(ret_ptr)); TOA_DBG(\u0026#34;coded toa data: %p \u0026#34;, ret_ptr); return ret_ptr; } ptr += opsize - 2; length -= opsize; } } } return NULL; } 可以看到，这里首先调用了原有的tcp_v4_syn_recv_sock函数，并且在sk_user_data未被占用的情况下，通过get_toa_data的方式，从原始的skb中将toa信息解析出来，并将数据赋值给sk-\u0026gt;sk_user_data。\n虽然这部分逻辑并不完全理解，但是从逻辑来看，只要读取sk_user_data并且判断其中是否有符合条件的值，即可获取real-client ip。\n至此，基本的逻辑就梳理出来了。对应的BPF处理逻辑也就很清晰了。\n# 三、BPF 逻辑 直接上代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 #define INADDR_LOOPBACK 0x7f000001 /* 127.0.0.1 */ #define INADDR_LOOPBACK_HOST INADDR_LOOPBACK #define INADDR_LOOPBACK_NET 0x0100007f /* 127.0.0.1 */ #define ns2sec(ns) ((ns) / (1000 * 1000 * 1000)) #ifndef memcpy #define memcpy(dest, src, n) __builtin_memcpy((dest), (src), (n)) #endif #define MERGE_SEC 10 typedef struct { u8 opcode; u8 opsize; u16 port; u32 ip; } toa_data_t; // 一般 toa 模块里只会填充一个 toa 数据 #define TCP_OPTION_LEN 1 struct tcp_event { u32 raddr; u32 laddr; u16 rport; u16 lport; int err; u64 toa_addr; toa_data_t toa_data; u64 sec; u64 ns; }; typedef struct tcp_event tcp_event_t; const struct tcp_event* unused_0x01 __attribute__((unused)); struct { __uint(type, BPF_MAP_TYPE_LRU_HASH); __uint(key_size, sizeof(tcp_event_t)); __uint(value_size, sizeof(u64)); // timestamp __uint(max_entries, 1024); } tcp_event_map SEC(\u0026#34;.maps\u0026#34;); struct { __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY); __uint(max_entries, 1024); } events SEC(\u0026#34;.maps\u0026#34;); enum toa_type { ipopt_toa = 254, // IP_v4 客户端 IP，目前仅考虑 }; #define _AF_INET 2 /* internetwork: UDP, TCP, etc. */ #define _IPPROTO_TCP 6 SEC(\u0026#34;kretprobe/inet_csk_accept\u0026#34;) int kretprobe__inet_csk_accept(struct pt_regs* ctx) { u64 start_ns = bpf_ktime_get_ns(); tcp_event_t event = {}; struct sock* sk = (struct sock*)PT_REGS_RC(ctx); if (sk == NULL) { return 0; } struct sock_common sk_common = {}; bpf_probe_read(\u0026amp;sk_common, sizeof(sk_common), (const void*)(sk)); if (sk_common.skc_family != _AF_INET) { return 0; } // 不处理本地回环 if (sk_common.skc_rcv_saddr == INADDR_LOOPBACK_NET || sk_common.skc_daddr == INADDR_LOOPBACK_NET) { return 0; } event.laddr = bpf_ntohl(sk_common.skc_rcv_saddr); event.raddr = bpf_ntohl(sk_common.skc_daddr); event.lport = sk_common.skc_num; event.rport = bpf_ntohs(sk_common.skc_dport); int err; toa_data_t toa_data[TCP_OPTION_LEN] = {}; err = BPF_CORE_READ_INTO(\u0026amp;toa_data, sk, sk_user_data); if (err) { return 0; } u8 i = 0; #pragma unroll for (i = 0; i \u0026lt; TCP_OPTION_LEN; i++) { if (toa_data[i].opcode != ipopt_toa) { continue; } memcpy(\u0026amp;event.toa_data, \u0026amp;toa_data[i], sizeof(toa_data_t)); } u32 raddr = event.raddr; if (event.toa_data.ip != 0 \u0026amp;\u0026amp; event.toa_data.port != 0) { // 挂载在 lvs 时，DS 的 IP 会发生变更。这里也给聚合掉。 event.raddr = 0; } // remote port 都不要 event.toa_data.port = 0; event.rport = 0; u64 sec = 0; u64 now_ns = bpf_ktime_get_ns(); u64* last_ns = (u64*)bpf_map_lookup_elem(\u0026amp;tcp_event_map, \u0026amp;event); if (last_ns != NULL) { sec = ns2sec((now_ns - *last_ns)); if (sec \u0026lt;= MERGE_SEC) { return 0; } } else { sec = 99; } bpf_map_update_elem(\u0026amp;tcp_event_map, \u0026amp;event, \u0026amp;now_ns, BPF_ANY); event.sec = sec; event.raddr = raddr; u64 end_ns = bpf_ktime_get_ns(); event.ns = end_ns - start_ns; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } 以上，周末愉快。\n","date":"2024-01-03T16:15:00Z","permalink":"http://localhost:1313/p/bpf-%E8%8E%B7%E5%8F%96-lvs-fullnat-%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84-client-ip/","title":"BPF 获取 LVS FullNat 模式下的 Client IP"},{"content":" 2023年就要结束了，算起来距离上一次更新也有很久了。搜肠刮肚，总得在23年结束前再搞两篇总结，算是有始有终。总结今年，总还是绕不过 BPF，golang。既然如此，就对BPF观测golang这个话题再往下挖掘下，先做第一篇文章。下旬如果有时间并且顺利的话，希望能把BPF的原理总结完成。\n在无侵入观测服务拓扑四元组的一种实现中，笔者有提到追踪golang处理过程的两个无法解决的问题是golang里的channel处理以及goroutine pool。再深究下，这两个问题实际上都可以归纳到对channel的处理，因为很多goroutine pool都离不了channel的使用，比如Jeffail/tunny这个库。\n本文将会构建一个channel的追踪的方案。\n# 一、追踪效果 按照惯例，我们还是来看下效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // terminal 1，启动服务 $ ./drink-srv // terminal 2，启动追踪脚本 $ sudo bpftrace ./drink.bt Attaching 7 probes... // 启动后停止在这里 serve HTTP: /alcohol // 触发接口后输出 caller: /alcohol, callee: :/unknown/prepare/hotel serve HTTP: /tea caller: /tea, callee: :/unknown/prepare/club // terminal 3，触发服务接口 $ curl \u0026#34;localhost:1423/alcohol?age=22\u0026#34; $ curl \u0026#34;localhost:1423/tea?age=12\u0026#34; # 二、方案设计 关于golang channel的实现及设计，可以参见图解Go的channel底层实现，里面有非常生动的动图实现；搭配源码食用更好runtime/chan.go。\n笔者在这里再简单的总结下，对send及recv两种操作设计的状态做一个简单的概述： chan-send的状态： chan-recv的状态： 比如，对于下面的代码，派生出的g1在开启select后，由于ticketChan是空的，会触发g1让出m里的执行权限，进入gopark状态。同时，ticketChan会将g1封装成sudog，放到recvq队列中。当一段时间之后，其他的g将数据写入channel里时，会在chansend时，检查到recvq不为空，会直接将数据拷贝到空闲的sudog中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 var ticketChan = make(chan TicketInfo, 10) func HandleDrink() { for { select { case info, ok := \u0026lt;-ticketChan: ... } } } } func main() { go HandleDrink() ... } chanrecv进入recvq对应的golang处理逻辑在这里：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // runtime/chan.go ... // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) ... chansend直接将数据拷贝到recvq对应的golang处理逻辑在这里：\n1 2 3 4 5 6 7 8 9 10 // runtime/chan.go ... if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } ... # 三、方案实现 了解了channel的处理流程，追踪的方案就比较明确了，直接在关键的函数处设置hook点即可。先来看下目标服务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) const ( ALCOHOL = iota + 1001 COCO COFFEE TEA ) type TicketInfo struct { Age int Name string Type int } var ticketChan = make(chan TicketInfo, 10) func AlcoholH(c *gin.Context) { var ticket = TicketInfo{} var err error ticket.Age, err = strconv.Atoi(c.Query(\u0026#34;age\u0026#34;)) if err != nil { c.String(http.StatusOK, \u0026#34;handle failed\u0026#34;) return } ticket.Name = c.Query(\u0026#34;name\u0026#34;) ticket.Type = ALCOHOL ticketChan \u0026lt;- ticket return } func TeaH(c *gin.Context) { var ticket = TicketInfo{} var err error ticket.Age, err = strconv.Atoi(c.Query(\u0026#34;age\u0026#34;)) if err != nil { log.Println(\u0026#34;handle failed, \u0026#34;, err.Error()) c.String(http.StatusOK, \u0026#34;handle failed\u0026#34;) return } ticket.Name = c.Query(\u0026#34;name\u0026#34;) ticket.Type = TEA ticketChan \u0026lt;- ticket c.String(http.StatusOK, \u0026#34;okay\u0026#34;) return } func HandleDrink() { for { select { case info, ok := \u0026lt;-ticketChan: if !ok { log.Println(\u0026#34;chan closed.\u0026#34;) return } log.Println(\u0026#34;get ticket\u0026#34;) switch info.Type { case ALCOHOL: Alcohol(info) case COCO: SoftDrink(info) case COFFEE, TEA: Tea(info) default: log.Println(\u0026#34;unknown drink type\u0026#34;) } } } } func Alcohol(ticket TicketInfo) { var url = \u0026#34;http://localhost/unknown/prepare/hotel\u0026#34; http.DefaultClient.Get(url) return } func SoftDrink(ticket TicketInfo) { log.Printf(\u0026#34;[%s, %d] drink %d\u0026#34;, ticket.Name, ticket.Age, ticket.Type) return } func Tea(ticket TicketInfo) { var url = \u0026#34;http://localhost/unknown/prepare/club\u0026#34; http.DefaultClient.Get(url) return } func main() { defer func() { close(ticketChan) }() go HandleDrink() var r = gin.Default() r.GET(\u0026#34;/alcohol\u0026#34;, AlcoholH) r.GET(\u0026#34;/tea\u0026#34;, TeaH) var srv = \u0026amp;http.Server{ Addr: \u0026#34;127.0.0.1:1423\u0026#34;, Handler: r, } if srv.ListenAndServe() != nil { log.Println(\u0026#34;failed to handle service listen\u0026#34;) return } } 对于这样的一个服务，希望达到示例中的追踪效果，对应的方案为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 #define OFF_TASK_THRD 4992 #define OFF_THRD_FSBASE 40 #define GOID_OFFSET 152 uprobe:./drink-srv:\u0026#34;runtime.runqput\u0026#34; { $prob_mark = \u0026#34;runqput\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; if (@new_go[tid, pid] == 0){ return; } $p_goid = @new_go[tid, pid]; $g = (uint64)(reg(\u0026#34;bx\u0026#34;)); $goid = *(uint64*)($g+GOID_OFFSET); @caller_addr[$goid] = @caller_addr[$p_goid]; @caller_len[$goid] = @caller_len[$p_goid]; } uprobe:./drink-srv:\u0026#34;runtime.newproc1\u0026#34; { $prob_mark = \u0026#34;newproc1\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $g = (uint64)(reg(\u0026#34;bx\u0026#34;)); $goid = *(uint64*)($g+GOID_OFFSET); if (@caller_addr[$goid] == 0){ return; } @new_go[tid, pid] = $goid; } // 这里，将 caller 信息和写入 channel 信息的 key 关联起来 uprobe:./drink-srv:\u0026#34;runtime.chansend\u0026#34; { $prob_mark = \u0026#34;chansend\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $cur = (uint64)curtask; $fsbase = *(uint64*)($cur+OFF_TASK_THRD+OFF_THRD_FSBASE); $g = *(uint64*)($fsbase-8); $goid = *(uint64*)($g+GOID_OFFSET); // 如果当前执行goroutine中没有caller，跳过 if(@caller_addr[$goid] == 0){ return; } $chan = (uint64)reg(\u0026#34;ax\u0026#34;); $qcount = *(uint32*)($chan + 0); $buf = *(uint64*)($chan+16); @send_addr[$chan, $qcount] = @caller_addr[$goid]; @send_len[$chan, $qcount] = @caller_len[$goid]; return; } uprobe:./drink-srv:\u0026#34;runtime.chanrecv\u0026#34; { $prob_mark = \u0026#34;chanrecv\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $cur = (uint64)curtask; $fsbase = *(uint64*)($cur+OFF_TASK_THRD+OFF_THRD_FSBASE); $g = *(uint64*)($fsbase-8); $goid = *(uint64*)($g+GOID_OFFSET); $chan = (uint64)reg(\u0026#34;ax\u0026#34;); $qcount = *(uint32*)($chan + 0); $buf = *(uint64*)($chan+16); if (@send_addr[$chan, $qcount] == 0){ return; } @caller_addr[$goid] = @send_addr[$chan, $qcount]; @caller_len[$goid] = @send_len[$chan, $qcount]; return; } uprobe:./drink-srv:\u0026#34;runtime.send\u0026#34; { $prob_mark = \u0026#34;send\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $chan = (uint64)reg(\u0026#34;ax\u0026#34;); $sg = (uint64)reg(\u0026#34;bx\u0026#34;); $g = *(uint64*)($sg+0); $goid = *(uint64*)($g+GOID_OFFSET); $qcount = *(uint32*)($chan+0); @caller_addr[$goid] = @send_addr[$chan, $qcount]; @caller_len[$goid] = @send_len[$chan, $qcount]; return; } /* type serverHandler struct { srv *Server } func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { */ uprobe:./drink-srv:\u0026#34;net/http.serverHandler.ServeHTTP\u0026#34; { $prob_mark = \u0026#34;ServeHTTP\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $cur = (uint64)curtask; $fsbase = *(uint64*)($cur+OFF_TASK_THRD+OFF_THRD_FSBASE); $g = *(uint64*)($fsbase-8); $goid = *(uint64*)($g+GOID_OFFSET); $req_addr = reg(\u0026#34;di\u0026#34;); // offset(Request.URL) = 16 $url_addr = *(uint64*)($req_addr+16); // offset(URL.Path) = 56 $path_addr = *(uint64*)($url_addr+56); $path_len = *(uint64*)($url_addr+64); @caller_addr[$goid] = $path_addr; @caller_len[$goid] = $path_len; printf(\u0026#34;serve HTTP: %s \u0026#34;, str($path_addr, $path_len)); return; } /* func (c *Client) do(req *Request) (retres *Response, reterr error) { */ uprobe:./drink-srv:\u0026#34;net/http.(*Client).do\u0026#34; { $prob_mark = \u0026#34;do\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $cur = (uint64)curtask; $fsbase = *(uint64*)($cur+OFF_TASK_THRD+OFF_THRD_FSBASE); $g = *(uint64*)($fsbase-8); $goid = *(uint64*)($g+GOID_OFFSET); if (@caller_addr[$goid] == 0){ printf(\u0026#34;%d: has no caller. \u0026#34;, $goid); return; } $req_addr = reg(\u0026#34;bx\u0026#34;); // offset(Request.URL) = 16 $url_addr = *(uint64*)($req_addr+16); // offset(URL.Host) = 40 $host_addr = *(uint64*)($req_addr+40); $host_len = *(uint64*)($req_addr+48); // offset(URL.Path) = 56 $path_addr = *(uint64*)($url_addr+56); $path_len = *(uint64*)($url_addr+64); $c_addr = @caller_addr[$goid]; $c_len = @caller_len[$goid]; printf(\u0026#34;caller: %s, callee: %s:%s \u0026#34;, str($c_addr, $c_len), str($host_addr, $host_len), str($path_addr, $path_len)); } # 四、追踪的风险 至此，看起来golang channel是可以追踪的。但是实际上并非如此。比如如下这个示例：\n1 2 3 4 5 6 7 8 9 10 func HandleDrink() { for { select { case info, ok := \u0026lt;-ticketChan: ... default: // 注意这个 stop // no stop here } } } 这段逻辑在代码编写、编译阶段均无问题，是一段完全合理的逻辑。当我们试图追踪这段代码时：\n1 2 3 4 $ sudo bpftrace ./drink.bt Attaching 7 probes... ^C // 直接停止，没有请求 @prob[chanrecv]: 908571 注意，此时并没有做任何的操作，但是这个chanrecv这个hook点已经触发了数十万次。而我们知道，BPF hook点的触发并非没有开销的。因此，目标的代码在完全合理的情况下，我们的追踪程序会给系统带来很大的负载。这显然是我们需要避免的。\n以上，周末愉快～\n","date":"2023-12-08T19:43:00Z","permalink":"http://localhost:1313/p/%E5%A6%82%E4%BD%95%E8%BF%BD%E8%B8%AAgolang-channel/","title":"如何追踪golang channel?"},{"content":" 不出意外的，之前提到的 ELF 文件解析内容又拖延了。目前还不知道什么时候有时间能够把希望完成的几篇文章给搞完。翻一翻目前的博客，已经有很久没有更新了。那就水一篇文章吧。目前算是项目里的低谷期，希望能够重拾程序员的意义。\n在bpftrace 无侵入遍历golang链表里，笔者展示了使用bpftrace来遍历golang链表的方法。由于go-17和go-16的函数调用规约存在不同，因此bpftrace 无侵入遍历golang链表并不适用于go-17。其实这个问题在go-1.17+ 调用规约已经提到了解决方案。本文给一个实例，算是更进一步的延伸这个话题，希望能够起到一些效果。\n# 一、执行效果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ sudo bpftrace ./link.bt Attaching 1 probe... // 在触发目标程序前，停止在这里 // 触发目标程序后，输出 == enter main.showNode name: Alice, age: 11 name: Bob, age: 12 name: Claire, age: 13 == end // 目标程序执行结果 $ ./link name: Alice, age: 11 name: Bob, age: 12 name: Claire, age: 13 需要注意的是，笔者的验证环境为：\n1 2 3 Linux 4.18.0-193.el8.x86_64 go version go1.17 linux/amd64 bpftrace v0.14.0-72-g6761-dirty 由于不同的CPU架构下，寄存器的信息会有所不同。本文中所涉及的代码示例仅在amd64里有效。\n# 二、代码 本文涉及两部分代码：目标的go代码以及bpftrace代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // link/main.go package main import \u0026#34;fmt\u0026#34; type Node struct { Name string Age int64 Next *Node } //go:noinline func showNode(head *Node) { var cur = head for cur != nil { fmt.Printf(\u0026#34;name: %s, age: %d \u0026#34;, cur.Name, cur.Age) cur = cur.Next } return } func main() { var node = \u0026amp;Node{ Name: \u0026#34;Alice\u0026#34;, Age: 11, Next: \u0026amp;Node{ Name: \u0026#34;Bob\u0026#34;, Age: 12, Next: \u0026amp;Node{ Name: \u0026#34;Claire\u0026#34;, Age: 13, Next: nil, }, }, } showNode(node) } bpftrace代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // link/link.bt // 这里，符号使用双引号包裹起来是个好习惯 uprobe:./link:\u0026#34;main.showNode\u0026#34; { printf(\u0026#34;== enter main.showNode \u0026#34;); $head_ptr = reg(\u0026#34;ax\u0026#34;); unroll(10){ $name_ptr = *(uint64*)($head_ptr+0); $name_len = *(uint64*)($head_ptr+8); $age_v = *(int64*)($head_ptr+16); printf(\u0026#34;name: %s, age: %d \u0026#34;, str($name_ptr, $name_len), $age_v); // set head = next $head_ptr = *(uint64*)($head_ptr+24); if ($head_ptr == 0){ printf(\u0026#34;== end \u0026#34;); return; } } } 以上。周末愉快。\n","date":"2023-11-18T15:36:00Z","permalink":"http://localhost:1313/p/bpftrace-%E9%81%8D%E5%8E%86-golang-%E9%93%BE%E8%A1%A8go17-/","title":"bpftrace 遍历 golang 链表（go17+）"},{"content":" 最近在整理一些技术文章。本来希望把涉及ELF的内容整理出来，结果发现太难了。ELF涉及的内容要多很多，如果要把希望整理的内容表述清楚，还需要做一些准备的工作。刚好最近完成了tail-calls 的调研，先把关于eBPF的tail-calls的功能整理下吧。\neBPF程序是事件驱动的，这就意味着当目标事件触发后，程序才能执行。考虑这样一个场景：有几个不同的BPF程序均挂载在相同的hook点上，而执行需要保持一定的顺序。这时就需要借助tail calls的功能来实现。\n# 一、tail calls 与 bpf2bpf calls的对比 首先要说明的是，将不同的逻辑分支都放到一个bpf程序里是很难进行的，因为bpf程序存在严格的限制：比如512B的执行栈。处理逻辑复杂，往往意味着需要使用的结构体就多，很容易就超出了512B的限制，编译时会报类似如下的错误：\n1 2 3 4 5 cd uretprobe \u0026amp;\u0026amp; go generate ./uretprobe.c:24:15: error: Looks like the BPF stack limit of 512 bytes is exceeded. Please move large on stack variables into BPF per-cpu array map. struct event event = {}; ^ ./uretprobe.c:24:15: error: Looks like the BPF stack limit of 512 bytes is exceeded. Please move large on stack variables into BPF per-cpu array map. 对于使用而言，tail calls从一定程度上规避这个问题：使用bpf_tail_call跳转（注意，跳转callee函数执行完成后，不会继续执行caller剩余的逻辑，而是直接退出）的目标函数，函数内部的栈资源限制计算是独立的，会覆盖调用caller的栈帧。而常规的bpf2bpf call，调用的callee执行完成后，会继续执行caller里的代码。而且，512B的限制会对caller callee整体生效。如，下述的bpf2bpf call是会报错的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 struct event { u32 pid; // 4B u8 line[256]; // 256B }; // linux-4.16以前，需要这样声明。4.16新增了真正意义上的函数调用而非inline处理。 // static __always_inline void send_event(ctx) { static void send_event(struct pt_regs *ctx) { struct event event = {}; event.pid = bpf_get_current_pid_tgid(); event.line[0] = 49; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); } SEC(\u0026#34;uretprobe/bash_readline\u0026#34;) int uretprobe_bash_readline(struct pt_regs *ctx) { struct event event = {}; event.pid = bpf_get_current_pid_tgid(); event.line[0] = 49; send_event(ctx); // 这里发起了一个bpf2bpf call // 如果将line的长度调小，程序能够正常执行。send_event后会继续执行。 bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } 这里算是笔者目前感知到的主要差异。tail calls的特性在linux-4.2的版本就上线了。在centos-8版本的系统上运行没有问题。\n# 二、tail calls 的一个示例 这里附上执行效果和一段示例。笔者构建的场景是使用uretprobe/bash_readline作为hook点，依据返回字符串长度的奇偶性来触发不同的bpf function，分别输出不同的事件。实现效果如下。\n1 2 3 4 5 6 $ sudo ./uretprobe 2023/08/26 14:34:39 Listening for events.. 2023/08/26 14:34:45 /bin/bash:readline return value: ll 2023/08/26 14:34:45 get even event 2023/08/26 14:35:01 /bin/bash:readline return value: ls -l 2023/08/26 14:35:01 get odd event bpf代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 char __license[] SEC(\u0026#34;license\u0026#34;) = \u0026#34;Dual MIT/GPL\u0026#34;; struct event { u32 pid; u8 line[256]; u8 mark; }; struct { __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY); } events SEC(\u0026#34;.maps\u0026#34;); // Force emitting struct event into the ELF. const struct event *unused __attribute__((unused)); // 通过bpf-tail-call只能调用同类型的bpf函数 SEC(\u0026#34;uretprobe/bash_readline_odd\u0026#34;) int uretprobe_bash_readline_odd(struct pt_regs *ctx){ struct event event = {}; event.pid = bpf_get_current_pid_tgid(); event.line[0] = 49; event.mark = 5; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } // 通过bpf-tail-call只能调用同类型的bpf函数 SEC(\u0026#34;uretprobe/bash_readline_even\u0026#34;) int uretprobe_bash_readline_even(struct pt_regs *ctx){ struct event event = {}; event.pid = bpf_get_current_pid_tgid(); event.mark = 8; event.line[0] = 50; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } struct{ __uint(type, BPF_MAP_TYPE_PROG_ARRAY); __uint(key_size, sizeof(u32)); __uint(value_size, sizeof(u32)); __uint(max_entries, 1024); __array(values, int (void*)); } tail_jmp_table SEC(\u0026#34;.maps\u0026#34;) = { .values = { // 这里的id是可以在用户态通过map update来更新的。由此可以延伸出其他有意思的功能。这里从实际需求直接固定值了。 [135] = (void*)\u0026amp;uretprobe_bash_readline_odd, [146] = (void*)\u0026amp;uretprobe_bash_readline_even, }, }; SEC(\u0026#34;uretprobe/bash_readline\u0026#34;) int uretprobe_bash_readline(struct pt_regs *ctx) { struct event event = {}; event.pid = bpf_get_current_pid_tgid(); bpf_probe_read(\u0026amp;event.line, sizeof(event.line), (void *)PT_REGS_RC(ctx)); event.mark = 3; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); u8 line_length=0; for(line_length=0; line_length\u0026lt;80; line_length++){ if(event.line[line_length] == 0){ break; } } if (line_length % 2 == 0){ // 偶数调用 uretprobe_bash_readline_even bpf_tail_call(ctx, \u0026amp;tail_jmp_table, 146); }else{ // 奇数调用 uretprobe_bash_readline_odd bpf_tail_call(ctx, \u0026amp;tail_jmp_table, 135); } return 0; } 以上。周末愉快～\n# 三、参考文章 [1] BPF Architecture\n[2] bpf-helpers\n[3] 在 ebpf/libbpf 程序中使用尾调用（tail calls）\n[4] kernel version\n","date":"2023-08-26T12:30:00Z","permalink":"http://localhost:1313/p/ebpf-tail-calls%E7%A4%BA%E4%BE%8B/","title":"eBPF tail-calls示例"},{"content":" 原文地址Challenges of BPF Tracing Go。翻译不尽如人意，继续努力。\n# BPF追踪Go程序的挑战 当大家对Go 1.17语言调用规约(function calling convention)调整带来的性能优化感到兴奋时，我却遗憾的看到Go 1.17并没有让BPF uretprobe变得可行。事实证明，我还没有完全意识到Go的可调整的栈空间会让事情变得多复杂。\nGo极短的编译时间使得“输出调试”变得非常便捷。当你知道问题处在一个特定的变量时，往往会随手塞入一个fmt.Printf或者log.Debug或者spew.Dump来观察感兴趣的点。但是我经常工作在一个有状态的系统中，在这样的环境下“输出调试”变 得非常受限。重新编入一个log语句并且重启系统，往往意味着丢失掉可能导致异常的状态，并且日志输出可能会带来性能开销并掩盖掉bug。在这种背景下，我选择BPF工具，比如bpftrace，来定位问题。\n对应用程序开发者而言，BPF的一大强力功能是用户态的动态程序观测，在uprobe及uretprobe的基础上构建起来。uprobe会嵌入一个BPF探针在函数被调用的地方，uretprobe则会嵌入一个探针在函数返回的地方。\n比如，这里是一个使用C语言写的程序：\n1 2 3 int sum(int a, int b){ return a+b; } 使用如下的bpftrace程序可以输出上述程序的参数及返回值。\n1 2 3 4 5 6 7 8 9 10 11 #!/usr/bin/env bpftrace uprobe:./sum:\u0026#34;sum\u0026#34; { printf(\u0026#34;args: %d + %d\\n\u0026#34;, arg0, arg1); } uretprobe:./sum:\u0026#34;sum\u0026#34; { printf(\u0026#34;result: %d\\n\u0026#34;, reg(\u0026#34;ax\u0026#34;)); } 当我们运行这个bptrace脚本是，它会等待我们在另一个终端运行目标C程序，然后输出如下内容：\n1 2 3 4 5 $ sudo ./sum.bt Attaching 2 probes... args: 2 + 3 result: 5 ^C 对于一个有状态的服务来说是这是一种不可思议的强力功能，因为你可以将这些探针附加在一个运行中的程序而不需重新编译它，并且几乎不会带来性能损失。这种思想诞生在DTrace，而后由BPF将这种观测能力 移植到Linux中。\n但是Go在1.17之前的调用规约(calling convention)使得Go的追踪变得复杂。在System V AMD64调用规约中，函数入参及返回值均通 寄存器传递。BPF的工具也假定编译器会遵循这一规约，但是Go没有。不同的是，Go遵循Plan9的调用规约，即通过栈来传递参数。返回值也会通过出栈来返回。\n对于uprobe而言这意味着我们不能遵循AMD64调用规约，使用arg参数来将寄存器里的参数读出。与此相对应的是，我们需要从栈里将参数读出来。从栈里读参会比较繁琐，因为你需要获取栈帧(stack pointer)，从中读取参数地址，然后读取地址里 的参数。在bpftrace-0.9.3里，这些操作被封装成了sargx，所以还不算特别糟。\n但是对于uretprobe就不一样了。不同于每个goroutine使用一个线程，Go的是多个goroutine对应多个线程的（\u0026ldquo;M:N调度\u0026rdquo;）。所以不同于每个线程拥有2MB的栈空间，每个goroutine只有被goroutine自己维护而非操作系统维护的，短短的 2KB的栈空间。当程序需要为一个goroutine增加栈空间并且当前空间内没有足够多的空余时，运行时会将整个goroutine的栈拷贝到另外一个有足够多空间用来扩展的内存空间中。\n当你配置uretprobe时，内核也会创建一个拥有返回探针处理的uprobe。当这个uprobe触发时，它会劫持返回地址并且使用一个中断 的“跳转地址”(tramponline)来替代它。\n如果这个地址在uprobe触发时被移动了，返回地址将不再有效，所以一个uretprobe将会读取其他地方的内存。这将会使得程序崩溃。\n为了解决这个问题，你需要从程序的入口处使用uprobe来追踪程序调用，然后记录函数每个return点的偏移信息。这显得格外的粗暴并且涉及二进制信息的反汇编。\n你大概不会花费一整天来学习汇编，我当然也不会。所以让我们快速的来看下如何读取go反汇编后的内容。假设这是我们的程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func swap(x, y string) (string, string) { return y, x } func main() { args := os.Args if len(args) \u0026lt; 3 { panic(\u0026#34;needs 2 args\u0026#34;) } a, b := swap(args[1], args[2]) fmt.Println(a, b) } 由于这段程序比较简短，Go可能会把swap函数进行内联。为了能够说明问题，我们将会使用go build -gcflags '-l' -o swapper .进行编译以防止内联。\n首先我们使用GDB来反汇编程序。你当然也可以使用objdump来进行，但是这里我们希望能够多获取些内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 $ gdb --args ./swapper hello go ... Reading symbols from ./swapper... Loading Go Runtime support. (gdb) b main.swap Breakpoint 1 at 0x497800: file /home/tim/swapper/main.go, line 9 . (gdb) run Starting program: /home/tim/swapper/swapper hello world [New LWP 3413956] [New LWP 3413957] [New LWP 3413958] [New LWP 3413959] [New LWP 3413960] Thread 1 \u0026#34;swapper\u0026#34; hit Breakpoint 1, main.swap (x=..., y=..., ~r2=..., ~r3=...) at /home/tim/swapper/main.go:9 9 return y, x (gdb) disas Dump of assembler code for function main.swap: =\u0026gt; 0x0000000000497800 \u0026lt;+0\u0026gt;: mov rax,QWORD PTR [rsp+0x18] 0x0000000000497805 \u0026lt;+5\u0026gt;: mov QWORD PTR [rsp+0x28],rax 0x000000000049780a \u0026lt;+10\u0026gt;: mov rax,QWORD PTR [rsp+0x20] 0x000000000049780f \u0026lt;+15\u0026gt;: mov QWORD PTR [rsp+0x30],rax 0x0000000000497814 \u0026lt;+20\u0026gt;: mov rax,QWORD PTR [rsp+0x8] 0x0000000000497819 \u0026lt;+25\u0026gt;: mov QWORD PTR [rsp+0x38],rax 0x000000000049781e \u0026lt;+30\u0026gt;: mov rax,QWORD PTR [rsp+0x10] 0x0000000000497823 \u0026lt;+35\u0026gt;: mov QWORD PTR [rsp+0x40],rax 0x0000000000497828 \u0026lt;+40\u0026gt;: ret End of assembler dump. 总的来看，我们有4个指针需要移动：每个string都有一个长度以及一段字节码，并且我们有两个string。函数将指针重新排列在栈上，并且当函数返回时，这些值会从栈上弹出。\n第一个指令是将栈帧上偏移量为0x18的值移动到暂存寄存器rax。让我们查看下这个地址，然后看看它是否是一个可读的string：\n1 2 3 4 (gdb) x/a $rsp+0x18 0xc00011af18: 0x7fffffffddcd (gdb) x/s 0x7fffffffddcd 0x7fffffffddcd: \u0026#34;go\u0026#34; 妙啊！所以第一个指令的意思是，我们将值喜庆string的64-bit的指针(QWORD PTR)赋给了暂存寄存器。下一个指令是将同一个指针从暂存区移动到栈顶(rsp+0x28)。\n下一个指令是将0x20上的任意值移动到暂存区。这是个整数：我们字符串的长度！\n1 2 (gdb) x/a $rsp+0x20 0xc00011af20: 0x2 然后这个整数就被从暂存区移动到栈顶(rsp+0x30)。接下来的四个指令对另外两个参数做了相同的事情：\n1 2 3 4 5 6 7 (gdb) x/a $rsp+0x8 0xc00011af08: 0x7fffffffddc7 (gdb) x/s 0x7fffffffddc7 0x7fffffffddc7: \u0026#34;hello\u0026#34; (gdb) x/a $rsp+0x10 0xc00011af10: 0x5 我们单步执行(si)8次，直到来到ret指令处：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... (gdb) si 0x0000000000497828 in main.swap (x=..., y=..., ~r2=..., ~r3=...) at /home/tim/swapper/main.go:9 9 return y, x (gdb) disas Dump of assembler code for function main.swap: 0x0000000000497800 \u0026lt;+0\u0026gt;: mov rax,QWORD PTR [rsp+0x18] 0x0000000000497805 \u0026lt;+5\u0026gt;: mov QWORD PTR [rsp+0x28],rax 0x000000000049780a \u0026lt;+10\u0026gt;: mov rax,QWORD PTR [rsp+0x20] 0x000000000049780f \u0026lt;+15\u0026gt;: mov QWORD PTR [rsp+0x30],rax 0x0000000000497814 \u0026lt;+20\u0026gt;: mov rax,QWORD PTR [rsp+0x8] 0x0000000000497819 \u0026lt;+25\u0026gt;: mov QWORD PTR [rsp+0x38],rax 0x000000000049781e \u0026lt;+30\u0026gt;: mov rax,QWORD PTR [rsp+0x10] 0x0000000000497823 \u0026lt;+35\u0026gt;: mov QWORD PTR [rsp+0x40],rax =\u0026gt; 0x0000000000497828 \u0026lt;+40\u0026gt;: ret End of assembler dump. 函数已经完成了所有的功能，并且我们来到了这个函数将会返回给调用者的地方。现在我们可以确认下栈顶的内存地址：\n1 2 3 4 5 6 (gdb) x/a $rsp+0x40 0xc00011af40: 0x5 (gdb) x/a $rsp+0x38 0xc00011af38: 0x7fffffffddc7 (gdb) x/s 0x7fffffffddc7 0x7fffffffddc7: \u0026#34;hello\u0026#34; 此时，我们可以看到我们已经将返回值移动到距离栈顶一定偏移量的指针上，而指针指向字符串。因为是在栈上，所以是“后进先出”的。这里可能会有些困惑因为函数的主要功能是交换这两个字符串。\n如果你跟上了我的思路，自然的就能画出这样的分布： 如何将我们所学的内容应用到BPF呢？\n首先，我们知道了尽管Go函数仅定义了两个参数，但实际上栈上有四个参数。所以我们需要定义两组栈上的参数。我们可以将它们正确的通过bpftrace里的str函数：bpftrace:str(sarg0, sarg1)来输出x，str(sarg2, sarg3)来 输出y。\n然后，尽管uretprobe无法工作，我们可以通过添加一个指向return指令偏移量的uprobe来模拟它。如果你再看下汇编指令，就能看到这个偏移地址是+40。所以uprobe最终看起来 是：uprobe:./bin/swapper:\u0026quot;main.swap\u0026quot;+40。当我们触发这个探针时，我们仅查看返回值寄存器无法满足目标。我们需要检查上述发现的每个返回值的偏移地址。最终的bpftrace程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #!/usr/bin/env bpftrace uprobe:./swapper:\u0026#34;main.swap\u0026#34; { printf(\u0026#34;swapping \\\u0026#34;%s\\\u0026#34; and \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(sarg0, sarg1), str(sarg2, sarg3)); } uprobe:./swapper:\u0026#34;main.swap\u0026#34;+40 { printf(\u0026#34;results: \\\u0026#34;%s\\\u0026#34; and \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(*(reg(\u0026#34;sp\u0026#34;)+0x28), *(reg(\u0026#34;sp\u0026#34;)+0x30)), str(*(reg(\u0026#34;sp\u0026#34;)+0x38), *(reg(\u0026#34;sp\u0026#34;)+0x40)) ) } 我们在一个终端运行这段代码，在另一个终端运行./swapper hello world：\n1 2 3 4 5 $ sudo ./swapper.bt Attaching 2 probes... swapping \u0026#34;hello\u0026#34; and \u0026#34;go\u0026#34; results: \u0026#34;go\u0026#34; and \u0026#34;hello\u0026#34; ^C 如你所见，仅一个return probe就需要做很多的准备。如果我们的程序有很多的返回点，我们不得不为每个返回点都做一次相同的事情。\n对于一些复杂的函数，如Nomad的FSM Apply方法，我不得不采用如下方式生成bpftrace代码的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/usr/bin/env bash cat \u0026lt;\u0026lt;EOF #!/usr/bin/env bpftrace /* Get Nomad FSM.Apply latency Note: using sarg with offsets isn\u0026#39;t really concurrency safe and emits a warning */ EOF base=$(objdump --disassemble=\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34; \\ -Mintel -S ./bin/nomad \\ | awk \u0026#39;/hashicorp/{print $1}\u0026#39; \\ | head -1) objdump --disassemble=\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34; \\ -Mintel -S ./bin/nomad \\ | awk -F\u0026#39; |:\u0026#39; \u0026#39;/ret/{print $2}\u0026#39; \\ | xargs -I % \\ python3 -c \u0026#34;print(\u0026#39;uprobe:./bin/nomad:\\\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\\\u0026#34;+\u0026#39; + hex(0x% - 0x$base)) print(\u0026#39;{\u0026#39;) print(\u0026#39; @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000);\u0026#39;) print(\u0026#39; delete(@start[str(*sarg1)]);\u0026#39;) print(\u0026#39;}\u0026#39;) print(\u0026#39;\u0026#39;) \u0026#34; 这样就得到了下面近300行的庞然大物：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 #!/usr/bin/env bpftrace /* Get Nomad FSM.Apply latency Note: using sarg with offsets isn\u0026#39;t really concurrency safe and emits a warning */ uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1d3 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x257 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x2f3 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x377 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x3fb { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x49b { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x51b { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x5a0 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x634 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x6b4 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x738 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x7e7 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x86e { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x8ee { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x982 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xa06 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xa8e { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xb27 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xbae { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xc2e { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xcc2 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xd46 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xdce { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xe77 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xefb { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xf80 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1014 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1098 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x111c { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x11b7 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x123b { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x12c0 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1350 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x13d0 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1450 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x14f7 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1577 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x15f7 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x168f { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x170f { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x178f { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x18ca { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1948 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x19ce { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1a52 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1a6d { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1b07 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1b87 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1c0e { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } Go 1.17引入的新的调用规约使得这种情况得到改善，但是仍没有解决uretprobe的问题。相同的swapper代码在Go 1.17上将会反汇编成如下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 (gdb) disas Dump of assembler code for function main.swap: =\u0026gt; 0x000000000047e260 \u0026lt;+0\u0026gt;: mov QWORD PTR [rsp+0x8],rax 0x000000000047e265 \u0026lt;+5\u0026gt;: mov QWORD PTR [rsp+0x18],rcx 0x000000000047e26a \u0026lt;+10\u0026gt;: mov rdx,rax 0x000000000047e26d \u0026lt;+13\u0026gt;: mov rax,rcx 0x000000000047e270 \u0026lt;+16\u0026gt;: mov rsi,rbx 0x000000000047e273 \u0026lt;+19\u0026gt;: mov rbx,rdi 0x000000000047e276 \u0026lt;+22\u0026gt;: mov rcx,rdx 0x000000000047e279 \u0026lt;+25\u0026gt;: mov rdi,rsi 0x000000000047e27c \u0026lt;+28\u0026gt;: ret End of assembler dump. 所有的值传递操作都通过寄存器进行了，减少了指针寻址的内容：\n1 2 3 4 5 6 7 8 (gdb) x/s $rax 0x7fffffffddca: \u0026#34;hello\u0026#34; (gdb) i r $rbx rbx 0x5 5 (gdb) x/s $rcx 0x7fffffffddd0: \u0026#34;go\u0026#34; (gdb) i r $rdi rdi 0x2 2 （我确实不知道为什么第二个参数的长度存储在rdi而非rdx，如果你知道的话，我很乐意知晓下）（译者按：参见golang-1.17参数调用规约）。\n返回值也放到了寄存器里，这意味着我们可以通过uretprobe来直接获取。我们的bpftrace程序变得简洁了许多：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/usr/bin/env bpftrace uprobe:./swapper:\u0026#34;main.swap\u0026#34; { printf(\u0026#34;swapping \\\u0026#34;%s\\\u0026#34; and \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(reg(\u0026#34;ax\u0026#34;)), str(reg(\u0026#34;cx\u0026#34;))); } uretprobe:./swapper:\u0026#34;main.swap\u0026#34; { printf(\u0026#34;results: \\\u0026#34;%s\\\u0026#34; and \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(reg(\u0026#34;ax\u0026#34;)), str(reg(\u0026#34;cx\u0026#34;))); } $ sudo ./swapper.bt Attaching 2 probes... swapping \u0026#34;hello\u0026#34; and \u0026#34;go\u0026#34; results: \u0026#34;go\u0026#34; and \u0026#34;hello\u0026#34; ^C 所以问题是什么？这样不是很好么？目前为止，我们关注的示例都没有需要很多栈空间以至于运行时需要对栈进行调整。而运行时的调整是uretprobe失败的原因。\n看下下面的示例。temp变量从没有逃逸到对上（我们可以通过添加-gcflags -m进行编译以验证这一点），所以我们需要在goroutine栈上申请sizeof(Example)*count大小的空间。如果我们执行./stacker 1000000，将会申请 多余能够提供的空闲内存，Go的运行时将不得不移动栈空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; ) type Example struct { ID int Name string } func stacker(count int) string { var result int for i := 0; i \u0026lt; count; i++ { temp := Example{ID: i * 2, Name: fmt.Sprintf(\u0026#34;%d\u0026#34;, result)} result += temp.ID } s := fmt.Sprintf(\u0026#34;hello: %d\u0026#34;, result) return s } func main() { args := os.Args if len(args) \u0026lt; 2 { panic(\u0026#34;needs 1 arg\u0026#34;) } count, err := strconv.Atoi(args[1]) if err != nil { panic(\u0026#34;arg needs to be a number\u0026#34;) } s := stacker(count) fmt.Println(s) } 这是我们的bpftrace程序：\n1 2 3 4 5 6 #!/usr/bin/env bpftrace uretprobe:./stacker:\u0026#34;main.stacker\u0026#34; { printf(\u0026#34;result: \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(reg(\u0026#34;ax\u0026#34;))); } 如果我们在uretprobe加载的同时，给stacker一个巨大的参数count，程序将会崩溃！\n1 2 3 4 $ ./stacker 1000000 runtime: unexpected return pc for main.stacker called from 0x7fffffffe000 stack: frame={sp:0xc000074ef0, fp:0xc000074f48} stack=[0xc000074000,0xc000075000) ... 这里是崩溃时完整的信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 $ ./stacker 1000000 runtime: unexpected return pc for main.stacker called from 0x7fffffffe000 stack: frame={sp:0xc000074ef0, fp:0xc000074f48} stack=[0xc000074000,0xc000075000) 0x000000c000074df0: 0x0000000000000002 0x000000c000508100 0x000000c000074e00: 0x000000c000508000 0x00000000004672e0 \u0026lt;sync.(*Pool).pinSlow·dwrap·3+0x0000000000000000\u0026gt; 0x000000c000074e10: 0x0000000000557f58 0x000000c000074e08 0x000000c000074e20: 0x0000000000419860 \u0026lt;runtime.gcAssistAlloc.func1+0x0000000000000000\u0026gt; 0x000000c0000001a0 0x000000c000074e30: 0x0000000000010000 0x000000c000074eb8 0x000000c000074e40: 0x000000000040b305 \u0026lt;runtime.mallocgc+0x0000000000000125\u0026gt; 0x000000c0000001a0 0x000000c000074e50: 0x0000000000000002 0x000000c000074e88 0x000000c000074e60: 0x000000c000074e88 0x000000000047a06a \u0026lt;fmt.(*pp).free+0x00000000000000ca\u0026gt; 0x000000c000074e70: 0x0000000000522100 0x00000000004938e0 0x000000c000074e80: 0x000000c00007a820 0x000000c000074ee0 0x000000c000074e90: 0x000000000047a245 \u0026lt;fmt.Sprintf+0x0000000000000085\u0026gt; 0x000000c00007a820 0x000000c000074ea0: 0x000000c00012b230 0x000000000000000b 0x000000c000074eb0: 0x000000c0000001a0 0x000000c000074ee0 0x000000c000074ec0: 0x00000000004095e5 \u0026lt;runtime.convT64+0x0000000000000045\u0026gt; 0x0000000000000008 0x000000c000074ed0: 0x0000000000487ee0 0x000000c00007a800 0x000000c000074ee0: 0x000000c000074f38 0x0000000000480d7b \u0026lt;main.stacker+0x000000000000003b\u0026gt; 0x000000c000074ef0: \u0026lt;0x0000000644e0732a 0x0000000000000002 0x000000c000074f00: 0x000000c000074f28 0x0000000000000001 0x000000c000074f10: 0x0000000000000001 0x0000000644e0732a 0x000000c000074f20: 0x00000000000280fa 0x0000000000000000 0x000000c000074f30: 0x0000000000000000 0x000000c000074f70 0x000000c000074f40: !0x00007fffffffe000 \u0026gt;0x00000000000f4240 0x000000c000074f50: 0x0000000000000007 0x0000000000415d45 \u0026lt;runtime.gcenable+0x0000000000000085\u0026gt; 0x000000c000074f60: 0x00000000004873a0 0x000000c0000001a0 0x000000c000074f70: 0x000000c000074fd0 0x0000000000432047 \u0026lt;runtime.main+0x0000000000000227\u0026gt; 0x000000c000074f80: 0x000000c000022060 0x0000000000000000 0x000000c000074f90: 0x0000000000000000 0x0000000000000000 0x000000c000074fa0: 0x0100000000000000 0x0000000000000000 0x000000c000074fb0: 0x000000c0000001a0 0x0000000000432180 \u0026lt;runtime.main.func2+0x0000000000000000\u0026gt; 0x000000c000074fc0: 0x000000c000074fa6 0x000000c000074fb8 0x000000c000074fd0: 0x0000000000000000 0x000000000045ab01 \u0026lt;runtime.goexit+0x0000000000000001\u0026gt; 0x000000c000074fe0: 0x0000000000000000 0x0000000000000000 0x000000c000074ff0: 0x0000000000000000 0x0000000000000000 fatal error: unknown caller pc runtime stack: runtime.throw({0x4988ba, 0x516760}) /usr/local/go/src/runtime/panic.go:1198 +0x71 runtime.gentraceback(0x400, 0x400, 0x80, 0x7f73bbffafff, 0x0, 0x0, 0x7fffffff, 0x7ffc46fe0e28, 0x7f73bbe23200, 0x0) /usr/local/go/src/runtime/traceback.go:274 +0x1956 runtime.scanstack(0xc0000001a0, 0xc000030698) /usr/local/go/src/runtime/mgcmark.go:748 +0x197 runtime.markroot.func1() /usr/local/go/src/runtime/mgcmark.go:232 +0xb1 runtime.markroot(0xc000030698, 0x14) /usr/local/go/src/runtime/mgcmark.go:205 +0x170 runtime.gcDrainN(0xc000030698, 0x10000) /usr/local/go/src/runtime/mgcmark.go:1134 +0x14b runtime.gcAssistAlloc1(0xc0000001a0, 0xc000074b58) /usr/local/go/src/runtime/mgcmark.go:537 +0xef runtime.gcAssistAlloc.func1() /usr/local/go/src/runtime/mgcmark.go:448 +0x25 runtime.systemstack() /usr/local/go/src/runtime/asm_amd64.s:383 +0x49 goroutine 1 [GC assist marking (scan)]: runtime.systemstack_switch() /usr/local/go/src/runtime/asm_amd64.s:350 fp=0xc000074de8 sp=0xc000074de0 pc=0x458a20 runtime.gcAssistAlloc(0xc0000001a0) /usr/local/go/src/runtime/mgcmark.go:447 +0x18b fp=0xc000074e48 sp=0xc000074de8 pc=0x41974b runtime.mallocgc(0x8, 0x487ee0, 0x0) /usr/local/go/src/runtime/malloc.go:959 +0x125 fp=0xc000074ec8 sp=0xc000074e48 pc=0x40b305 runtime.convT64(0x644e0732a) /usr/local/go/src/runtime/iface.go:364 +0x45 fp=0xc000074ef0 sp=0xc000074ec8 pc=0x4095e5 runtime: unexpected return pc for main.stacker called from 0x7fffffffe000 stack: frame={sp:0xc000074ef0, fp:0xc000074f48} stack=[0xc000074000,0xc000075000) 0x000000c000074df0: 0x0000000000000002 0x000000c000508100 0x000000c000074e00: 0x000000c000508000 0x00000000004672e0 \u0026lt;sync.(*Pool).pinSlow·dwrap·3+0x0000000000000000\u0026gt; 0x000000c000074e10: 0x0000000000557f58 0x000000c000074e08 0x000000c000074e20: 0x0000000000419860 \u0026lt;runtime.gcAssistAlloc.func1+0x0000000000000000\u0026gt; 0x000000c0000001a0 0x000000c000074e30: 0x0000000000010000 0x000000c000074eb8 0x000000c000074e40: 0x000000000040b305 \u0026lt;runtime.mallocgc+0x0000000000000125\u0026gt; 0x000000c0000001a0 0x000000c000074e50: 0x0000000000000002 0x000000c000074e88 0x000000c000074e60: 0x000000c000074e88 0x000000000047a06a \u0026lt;fmt.(*pp).free+0x00000000000000ca\u0026gt; 0x000000c000074e70: 0x0000000000522100 0x00000000004938e0 0x000000c000074e80: 0x000000c00007a820 0x000000c000074ee0 0x000000c000074e90: 0x000000000047a245 \u0026lt;fmt.Sprintf+0x0000000000000085\u0026gt; 0x000000c00007a820 0x000000c000074ea0: 0x000000c00012b230 0x000000000000000b 0x000000c000074eb0: 0x000000c0000001a0 0x000000c000074ee0 0x000000c000074ec0: 0x00000000004095e5 \u0026lt;runtime.convT64+0x0000000000000045\u0026gt; 0x0000000000000008 0x000000c000074ed0: 0x0000000000487ee0 0x000000c00007a800 0x000000c000074ee0: 0x000000c000074f38 0x0000000000480d7b \u0026lt;main.stacker+0x000000000000003b\u0026gt; 0x000000c000074ef0: \u0026lt;0x0000000644e0732a 0x0000000000000002 0x000000c000074f00: 0x000000c000074f28 0x0000000000000001 0x000000c000074f10: 0x0000000000000001 0x0000000644e0732a 0x000000c000074f20: 0x00000000000280fa 0x0000000000000000 0x000000c000074f30: 0x0000000000000000 0x000000c000074f70 0x000000c000074f40: !0x00007fffffffe000 \u0026gt;0x00000000000f4240 0x000000c000074f50: 0x0000000000000007 0x0000000000415d45 \u0026lt;runtime.gcenable+0x0000000000000085\u0026gt; 0x000000c000074f60: 0x00000000004873a0 0x000000c0000001a0 0x000000c000074f70: 0x000000c000074fd0 0x0000000000432047 \u0026lt;runtime.main+0x0000000000000227\u0026gt; 0x000000c000074f80: 0x000000c000022060 0x0000000000000000 0x000000c000074f90: 0x0000000000000000 0x0000000000000000 0x000000c000074fa0: 0x0100000000000000 0x0000000000000000 0x000000c000074fb0: 0x000000c0000001a0 0x0000000000432180 \u0026lt;runtime.main.func2+0x0000000000000000\u0026gt; 0x000000c000074fc0: 0x000000c000074fa6 0x000000c000074fb8 0x000000c000074fd0: 0x0000000000000000 0x000000000045ab01 \u0026lt;runtime.goexit+0x0000000000000001\u0026gt; 0x000000c000074fe0: 0x0000000000000000 0x0000000000000000 0x000000c000074ff0: 0x0000000000000000 0x0000000000000000 main.stacker(0xf4240) /home/tim/stacker/main.go:17 +0x3b fp=0xc000074f48 sp=0xc000074ef0 pc=0x480d7b 这样，我们仍然不得不使用之前实践的uprobe+offset的方式来进行uretprobe的实现。bpftrace程序会正常工作，但是地址的偏移量将很大程度上取决于使用的Go版本：\n1 2 3 4 5 6 #!/usr/bin/env bpftrace uprobe:./stacker:\u0026#34;main.stacker\u0026#34;+213 { printf(\u0026#34;result: \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(reg(\u0026#34;ax\u0026#34;))); } 这个问题看起来不会在Go的运行时侧修复，因为可重新分配的栈空间是整个goroutine内存模型的基础。但是通过uprobe以及一点小小的调整，你可以实现uretprobe的功能。\n","date":"2023-06-25T17:08:00Z","permalink":"http://localhost:1313/p/bpf%E8%BF%BD%E8%B8%AAgo%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%8C%91%E6%88%98/","title":"BPF追踪Go程序的挑战"},{"content":" 笔者一直都是文本编辑器教派的忠实拥趸：期望将所有的任务都通过文本编辑，而非鼠标/触摸板等，进行实现。从早年的Vim，到现而今的Emacs，对文本化完成需求是越来越习惯，也越来越依赖了。最近刚好有了些时间，把最近的一些实践整理下。\n在之前的文章，emacs org-mode 绘制思维导图，中，笔者有提到在探索不跳出Emacs这一文本编辑器的情况下，完成思维导图绘制的需求。在翻了一些文章后，找到了一款神器：PlantUML。其完美的匹配了笔者的需求：\n不仅是思维导图，工程、文档常用的UML图像也能全部支持文本化表示； 功能强大，颜色、文本等格式均能支持； Emacs友好，而且可以集成到Org-mode里使用。 而且，PlantUML支持在线使用，意味着能够很方便的获取、使用。这里做下介绍。\n# 一、依赖内容 这里先列一下笔者使用时的配置：\nplantuml.jar，安装在本地后，可以通过配置，在本地进行文本-\u0026gt;多格式输出的编译。plantuml.jar 下载； plantuml 配置。由于笔者还是使用的Emacs，这里列一下参照官网配置的Emacs设置。 1 2 3 4 5 6 7 8 9 ;; plantuml ;; 安装 plantuml-mode (ensure-package-installed \u0026#39;plantuml-mode) ;; 设置 plantuml.jar 的本地路径 (setq org-plantuml-jar-path (expand-file-name \u0026#34;~/.emacs.d/tools/plantuml.jar\u0026#34;)) ;; 将 .plantuml 后缀文件默认以 plantuml-mode 打开。非必需，后面都在 org-mode 里使用了 (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\.plantuml\\\u0026#39;\u0026#34; . plantuml-mode)) ;; 比较重要，在 org-mode 里声明 plantuml (org-babel-do-load-languages \u0026#39;org-babel-load-languages \u0026#39;((plantuml . t))) 配置很简单。下面就可以愉快的使用了。\n# 二、plantuml 介绍 plantuml官网，目前支持的部分图标类型：\nUML 图 时序图 用例图 状态图 活动图 类图 用例图 等等 非UML图 思维导图 甘特图 工作分解结构图 等等 在官网中，对每种图都给出了教程及示例，可以通过在线生成 进行感受。\nPlantUML的输入是文本，输出可以是ASCII, PNG, SVG等等格式。满足日常工作的需求。\n# 三、思维导图 # 3.1 一个简单的思维导图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #+begin_src plantuml :file mindmap.png @startmindmap \u0026lt;style\u0026gt; mindmapDiagram { .green { BackgroundColor lightgreen } .yellow { BackgroundColor yellow } .rose{ BackgroundColor #FFBBCC } } \u0026lt;/style\u0026gt; * emacs planuml 介绍 \u0026lt;\u0026lt;rose\u0026gt;\u0026gt; left side ** 依赖内容 \u0026lt;\u0026lt;yellow\u0026gt;\u0026gt; ***_ plantuml.jar 安装 ***_ plantuml 配置 ** plantuml 介绍 \u0026lt;\u0026lt;yellow\u0026gt;\u0026gt; ***_ 支持多种UML文本化编辑 \\ 多种格式文件输出的组件 ***_ 在线体验 right side ** 思维导图 \u0026lt;\u0026lt;green\u0026gt;\u0026gt; ***_ 一个简单的思维导图 ***_ 编译输出 ** 时序图 \u0026lt;\u0026lt;green\u0026gt;\u0026gt; ***_ 一个简单的时序图 ***_ 编译输出 @endmindmap #+end_src 由于笔者已经在Org-mode里配置了plantuml，因此只要在begin_src后声明plantuml即可。通过:file mindmap.png指定了输出的文件为png格式内容。C-c C-e或者org-export-dispatch即可通过org-mode的输出界面触发编译、输出。\n# 3.2 编译输出 输出结果： mindmap.png # 四、时序图 # 4.1 一个简单的时序图 这里来一点展示内容更丰富的UML时序图实际使用示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #+begin_src plantuml :file ngx_request.png @startuml title: nginx+php请求处理示例 [-\u0026gt;nginx: \u0026lt;font color=blue\u0026gt;/caller_path note right of nginx nginx 视角: caller=nginx, caller_func=/caller_path, callee=php, callee_func=/index.php/caller_path end note activate nginx #yellow nginx-\u0026gt;php: \u0026lt;font color=red\u0026gt;/index.php/caller_path activate php #yellow note right of php #gray laravel end note php-\u0026gt;callee: \u0026lt;font color=blue\u0026gt;/callee_path note right of php php 视角: caller=php, caller_func=/index.php/caller_path, callee=callee, callee_func=callee_path end note activate callee callee-\u0026gt;php: response deactivate callee php-\u0026gt;nginx: response deactivate php nginx-\u0026gt;[: response deactivate nginx note over nginx, php #aqua: 实际四元组: \\ caller=nginx caller_func=/caller_path, callee=callee, callee_func=callee_path, @enduml #+end_src # 4.2 编译输出 输出结果如下： ngx_request.png 可以看到，基本上能够满足一般工程文档使用的需求。\n以上是本次介绍的内容。周末愉快～\n","date":"2023-04-21T20:51:00Z","permalink":"http://localhost:1313/p/plantuml-%E6%96%87%E6%9C%AC%E5%8C%96%E7%BB%98%E5%88%B6uml%E5%A4%9A%E7%B1%BB%E5%9B%BE%E8%A1%A8/","title":"PlantUML-文本化绘制UML多类图表"},{"content":" 最近有了些时间，继续整理下之前的项目。服务四元组的信息对于故障处置、根因定位等都有重要意义。使用eBPF可以做到无侵入用户代码获取服务四元组信息的功能。这一点在工程应用上很有意义。笔者在这方面投入了一些精力，这里做一下简单的总结。\n服务四元组指的是[caller, caller_func, callee, callee_func]四元组。如下图是一个调用示例，站在服务A的角度，就存在如下两个四元组: [A, /a, B, /b]，[A, /a, C, /c]。站在服务B, C的角度，也存在两个四元组（可能有不同的理解）: [B, /b, none, none], [C, /c, none, none]。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 service call ,-------. ,-. ,-. ,-. |outisde| |A| |B| |C| `---+---\u0026#39; `+\u0026#39; `+\u0026#39; `+\u0026#39; | /a | | | |--------------\u0026gt;| | | | | | | | | /b | | | |-----------\u0026gt;| | | | | | | | /c | | |------------------------\u0026gt;| ,---+---. ,+. ,+. ,+. |outisde| |A| |B| |C| `-------\u0026#39; `-\u0026#39; `-\u0026#39; `-\u0026#39; 在弄清楚四元组是什么之后，下面进入今天的话题：如何使用BPF来采集四元组。需要说明的是，笔者这里的语言使用的是golang-1.16。golang不同语言版本间的区别，见：golang-1.17+调用规约。\n值得注意的是，关于观测服务数据，是有很多解决方案的。本文仅是笔者实践的一种解决方案，在文末会简单提到这种方案的优缺点。\n按照惯例，先看下效果吧：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 启动采集 bpftrace ./http.bt Attaching 2 probes... # 未触发请求前，停止在这里 caller: # 触发请求后，输出 caller_path: /handle callee: method: GET host: 0.0.0.0:9932 url: /echo caller: caller_path: /echo callee: none # 开始服务 ./http_demo \u0026amp; # 触发请求 curl http://0.0.0.0:9932/handle # 一段golang代码示例 下面是一段golang的http服务的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) type Resp struct { Errno int `json:\u0026#34;errno\u0026#34;` Errmsg string `json:\u0026#34;errmsg\u0026#34;` } //go:noinline func echo(c *gin.Context) { c.JSON(http.StatusOK, \u0026amp;Resp{ Errno: 0, Errmsg: \u0026#34;ok\u0026#34;, }) return } //go:noinline func handle(c *gin.Context) { client := http.Client{} req, _ := http.NewRequest(http.MethodGet, \u0026#34;http://0.0.0.0:9932/echo\u0026#34;, nil) resp, err := client.Do(req) if err != nil { fmt.Println(\u0026#34;failed to request\u0026#34;, err.Error()) c.JSON(http.StatusOK, \u0026amp;Resp{ Errno: 1, Errmsg: \u0026#34;failed to request\u0026#34;, }) return } respB, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;read resp failed\u0026#34;) c.JSON(http.StatusOK, \u0026amp;Resp{ Errno: 2, Errmsg: \u0026#34;failed to read request\u0026#34;, }) return } defer resp.Body.Close() fmt.Println(\u0026#34;resp: \u0026#34;, string(respB)) c.JSON(http.StatusOK, \u0026amp;Resp{ Errno: 0, Errmsg: \u0026#34;request okay\u0026#34;, }) return } func main() { s := http.Server{ Addr: \u0026#34;0.0.0.0:9932\u0026#34;, } r := gin.Default() r.GET(\u0026#34;/echo\u0026#34;, echo) r.GET(\u0026#34;/handle\u0026#34;, handle) s.Handler = r if err := s.ListenAndServe(); err != nil { fmt.Println(\u0026#34;error, \u0026#34;, err.Error()) } } 这是一段比较简单的golang代码。需要注意的是，这里的四元组是：[local, /handle, local, /echo]。为了便于示例说明，这里的handle的逻辑和请求下游的逻辑是串行的，没有开新的goroutine。这一点很重要，后面会说明。\n# 采集的逻辑 下面是采集的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 /* func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { ... } type Request struct { Method string URL *url.URL } type URL struct { Scheme string Opaque string // encoded opaque data User *Userinfo // username and password information Host string // host or host:port Path string // path (relative paths may omit leading slash) RawPath string // encoded path hint (see EscapedPath method) ForceQuery bool // append a query (\u0026#39;?\u0026#39;) even if RawQuery is empty RawQuery string // encoded query values, without \u0026#39;?\u0026#39; Fragment string // fragment for references, without \u0026#39;#\u0026#39; RawFragment string // encoded fragment hint (see EscapedFragment method) } */ uprobe:./http_demo:net/http.serverHandler.ServeHTTP { $req_addr = sarg3; $url_addr = *(uint64*)($req_addr+16); $path_addr = *(uint64*)($url_addr+56); $path_len = *(uint64*)($url_addr+64); // 在http请求触发处，依据pid将caller_func存储起来 @caller_path_addr[pid] = $path_addr; @caller_path_len[pid] = $path_len; @callee_set[pid] = 0; } /* type Request struct { Method string URL *url.URL } func (c *Client) do(req *Request) (retres *Response, reterr error) { ... } */ uprobe:./http_demo:\u0026#34;net/http.(*Client).do\u0026#34; { // 依据 pid 获取 caller 信息 printf(\u0026#34;caller: caller_path: %s \u0026#34;, str(@caller_path_addr[pid], @caller_path_len[pid])); $req_addr = sarg1; // 获取 callee 信息 $addr = *(uint64*)($req_addr); $len = *(uint64*)($req_addr + 8); printf(\u0026#34;callee: method: %s \u0026#34;, str($addr, $len)); $url_addr = *(uint64*)($req_addr + 16); $addr = *(uint64*)($url_addr + 40); $len = *(uint64*)($url_addr + 48); printf(\u0026#34; host: %s \u0026#34;, str($addr, $len)); $addr = *(uint64*)($url_addr + 56); $len = *(uint64*)($url_addr + 64); printf(\u0026#34; url: %s \u0026#34;, str($addr, $len)); @callee_set[pid] = 1 } uprobe:./http_demo:\u0026#34;net/http.(*response).finishRequest\u0026#34; { // 如果没有下游请求，单独输出 if (@callee_set[pid] == 0){ printf(\u0026#34;caller: caller_path: %s \u0026#34;, str(@caller_path_addr[pid], @caller_path_len[pid])); printf(\u0026#34;callee: none \u0026#34;); @callee_set[pid] = 1; } } 到这里就基本上把主要思路介绍清楚了。需要说明的是，示例里使用的是pid作为caller_map里的key，当存在并发时，pid肯定是不够的。对于golang语言，可以使用goid作为caller_map的key。目前对于使用golang常规的使用来说，就足够了。引入goid的另一个问题是，业务代码里可能使用新的goroutine来进行callee的请求、处理。这里就需要引入goroutine的派生关系维护，或者session trace。关于session trace，可以参见基于ebpf实现的gls这部分的逻辑，思路都是一致的。\n但是session trace能够覆盖所有的场景么？看一下下面的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 var( info = make(chan interface{}, 1000) ) func handle(info chan interface{}){ for{ select{ case inf,ok \u0026lt;- info: // do some request ... } } } type Resp struct{ Code int `json:\u0026#34;code\u0026#34;` Msg string `json:\u0026#34;msg\u0026#34;` } func Handler(ctx *gin.Context){ info \u0026lt;- ctx c.JSON(http.StatusOk, \u0026amp;Resp{Code: 0, Msg: \u0026#34;okay\u0026#34;}) } func main(){ go handle(info) // normal http register and start ... } 以上是一种http请求的处理方式，大抵的意思是对于每个请求，handleFunc并没有立即有效响应，而是通过channel将一部分的请求信息传递到其他goroutine里处理。这样虽然callerFunc的响应客观上触发了callee的请求，但是handle()所在的goroutine并不是handleFunc派生的。这种场景下，trace也就断掉了。同理，如果是开了goroutine pool来处理，也会丢失。\n# 方案的优缺点 优点。一如笔者在示例及demo中介绍的，对于方案trace能够覆盖的通信类型，callerFunc, callee, calleeFunc等的获取可以直接通过解析函数的参数来获取。对比基于kprobe的报文解析方案，即通过hook tcp_send tcp_rcv等来获取传输层报文，不需要进行复杂的报文解析。这就使得整个解析的触发次数接近O(n)，即一次http交互，一次probe的触发。此外，hook kprobe显然会对机器上所有会调用这个kprobe的进程造成影响，因为其他进程也会等待着调用kprobe。但是本方案里涉及的还仅是目标程序启动后的进程受到影响，并不会从调用角度来影响其他进程（但是CPU的抢占等是会产生轻微影响的）。 缺点。本方案的缺点同样很明显：它把语言及框架的依赖引入进来了。相对于kprobe可以直接面向协议进行解析，本方案需要考虑各种语言。同时，如果同一个语言中存在多种http的实现，也需要进行逐个适配。从这一角度而言，golang天然贴合本方案：其拥有官方统一维护的net/http库，同时，下游的请求方式也一并维护了。 以上是本次介绍的全部内容。在ebpf落地上，笔者还有很多内容需要探索，期望将来能够落地更多有价值的场景。周末愉快～\n","date":"2023-03-29T19:42:00Z","permalink":"http://localhost:1313/p/%E6%97%A0%E4%BE%B5%E5%85%A5%E8%A7%82%E6%B5%8B%E6%9C%8D%E5%8A%A1%E6%8B%93%E6%89%91%E5%9B%9B%E5%85%83%E7%BB%84%E7%9A%84%E4%B8%80%E7%A7%8D%E5%AE%9E%E7%8E%B0/","title":"无侵入观测服务拓扑四元组的一种实现"},{"content":" go-1.17是一个很不友好的版本，这里我指的是函数调用规约的变更。在此之前，虽然栈传参比较奇怪，但是在掌握了规律后，参数信息很好获取。升级到go-1.17之后，笔者发现变更后的寄存器传值方式并不是系统的调用规约，至少和C/C++的是完全不一致的。这个问题使得笔者在处理ebpf方案时，始终无法覆盖go-1.17+的版本。虽然短期不会造成影响，线上服务使用的大多还在go-1.16以下，但是这始终是一个绕不过去的问题。近期通过查阅资料和参考其他开源项目里对这部分内容的处理，整理了一下go-1.17+的调用规约。\ngo在1.17之前使用的是内存栈来传递参数，这种传参的方式使得golang的语言设计很灵活：golang函数的多返回值能够很容易的实现。同样的，由于golang需要这样灵活的能力，是的系统默认的调用规约方式并不适用。在Proposal: Register-based Go calling convention文章里对这个问题进行了详细的讨论，总结起来是golang的特性使得使用系统默认规约并不能带来多语言交互上的收益，且golang希望保持独特。\n本文下面会给出总结的调用规约，并且给出验证程序。本文档的整理所基于的平台是x86_64的centos8系统。其他架构下，寄存器名称可能不同。\n# 调用规约 入参：\n参数序号 标准规约 golang规约 1 rdi rax 2 rsi rbx 3 rdx rcx 4 rcx rdi 5 r8 rsi 6 r9 r8 7 栈传值 r9 8 栈传值 r10 9 栈传值 r11 10 栈传值 栈传值 返回值：\n参数序号 标准规约 golang规约 1 rax rax 2 - rbx 3 - rcx 4 - rdi 5 - rsi 6 - r8 7 - r9 8 - r10 9 - r11 10 - 栈传值 # 验证规约 这个条件是比较好验证的，看下验证代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // go version 1.18 // ./go_18/arg/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func longArgs(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11 uint64) (r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11 uint64) { return a1 + 1, a2 + 2, a3 + 3, a4 + 4, a5 + 5, a6 + 6, a7 + 7, a8 + 8, a9 + 9, a10 + 10, a11 + 11 } func main() { a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11 := longArgs(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11) fmt.Println(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11) } 先生成plan9代码以说明参数传入和参数返回均是使用的寄存器，并且寄存器顺序是一致的（内存传参时也是）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 go build -gcflags \u0026#34;-N -S -l\u0026#34; \u0026gt;\u0026gt; arg.info # 然后截取部分生成 plan9 汇编 # go_18/arg \u0026#34;\u0026#34;.longArgs STEXT nosplit size=411 args=0x68 locals=0x50 funcid=0x0 align=0x0 0x0000 00000 TEXT\t\u0026#34;\u0026#34;.longArgs(SB), NOSPLIT|ABIInternal, $80-104 0x0000 00000 SUBQ\t$80, SP 0x0004 00004 MOVQ\tBP, 72(SP) 0x0009 00009 LEAQ\t72(SP), BP 0x000e 00014 FUNCDATA\t$0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x000e 00014 FUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x000e 00014 FUNCDATA\t$5, \u0026#34;\u0026#34;.longArgs.arginfo1(SB) 0x000e 00014 MOVQ\tAX, \u0026#34;\u0026#34;.a1+120(SP) # 注意这里的读取参数寄存器 0x0013 00019 MOVQ\tBX, \u0026#34;\u0026#34;.a2+128(SP) 0x001b 00027 MOVQ\tCX, \u0026#34;\u0026#34;.a3+136(SP) 0x0023 00035 MOVQ\tDI, \u0026#34;\u0026#34;.a4+144(SP) 0x002b 00043 MOVQ\tSI, \u0026#34;\u0026#34;.a5+152(SP) 0x0033 00051 MOVQ\tR8, \u0026#34;\u0026#34;.a6+160(SP) 0x003b 00059 MOVQ\tR9, \u0026#34;\u0026#34;.a7+168(SP) 0x0043 00067 MOVQ\tR10, \u0026#34;\u0026#34;.a8+176(SP) 0x004b 00075 MOVQ\tR11, \u0026#34;\u0026#34;.a9+184(SP) 0x0053 00083 MOVQ\t$0, \u0026#34;\u0026#34;.r1+64(SP) 0x005c 00092 MOVQ\t$0, \u0026#34;\u0026#34;.r2+56(SP) 0x0065 00101 MOVQ\t$0, \u0026#34;\u0026#34;.r3+48(SP) 0x006e 00110 MOVQ\t$0, \u0026#34;\u0026#34;.r4+40(SP) 0x0077 00119 MOVQ\t$0, \u0026#34;\u0026#34;.r5+32(SP) 0x0080 00128 MOVQ\t$0, \u0026#34;\u0026#34;.r6+24(SP) 0x0089 00137 MOVQ\t$0, \u0026#34;\u0026#34;.r7+16(SP) 0x0092 00146 MOVQ\t$0, \u0026#34;\u0026#34;.r8+8(SP) 0x009b 00155 MOVQ\t$0, \u0026#34;\u0026#34;.r9(SP) 0x00a3 00163 MOVQ\t$0, \u0026#34;\u0026#34;.r10+104(SP) 0x00ac 00172 MOVQ\t$0, \u0026#34;\u0026#34;.r11+112(SP) 0x00b5 00181 MOVQ\t\u0026#34;\u0026#34;.a1+120(SP), DX 0x00ba 00186 INCQ\tDX 0x00bd 00189 MOVQ\tDX, \u0026#34;\u0026#34;.r1+64(SP) 0x00c2 00194 MOVQ\t\u0026#34;\u0026#34;.a2+128(SP), DX 0x00ca 00202 ADDQ\t$2, DX 0x00ce 00206 MOVQ\tDX, \u0026#34;\u0026#34;.r2+56(SP) 0x00d3 00211 MOVQ\t\u0026#34;\u0026#34;.a3+136(SP), DX 0x00db 00219 ADDQ\t$3, DX 0x00df 00223 MOVQ\tDX, \u0026#34;\u0026#34;.r3+48(SP) 0x00e4 00228 MOVQ\t\u0026#34;\u0026#34;.a4+144(SP), DX 0x00ec 00236 ADDQ\t$4, DX 0x00f0 00240 MOVQ\tDX, \u0026#34;\u0026#34;.r4+40(SP) 0x00f5 00245 MOVQ\t\u0026#34;\u0026#34;.a5+152(SP), DX 0x00fd 00253 ADDQ\t$5, DX 0x0101 00257 MOVQ\tDX, \u0026#34;\u0026#34;.r5+32(SP) 0x0106 00262 MOVQ\t\u0026#34;\u0026#34;.a6+160(SP), DX 0x010e 00270 ADDQ\t$6, DX 0x0112 00274 MOVQ\tDX, \u0026#34;\u0026#34;.r6+24(SP) 0x0117 00279 MOVQ\t\u0026#34;\u0026#34;.a7+168(SP), DX 0x011f 00287 ADDQ\t$7, DX 0x0123 00291 MOVQ\tDX, \u0026#34;\u0026#34;.r7+16(SP) 0x0128 00296 MOVQ\t\u0026#34;\u0026#34;.a8+176(SP), DX 0x0130 00304 ADDQ\t$8, DX 0x0134 00308 MOVQ\tDX, \u0026#34;\u0026#34;.r8+8(SP) 0x0139 00313 MOVQ\t\u0026#34;\u0026#34;.a9+184(SP), DX 0x0141 00321 ADDQ\t$9, DX 0x0145 00325 MOVQ\tDX, \u0026#34;\u0026#34;.r9(SP) 0x0149 00329 MOVQ\t\u0026#34;\u0026#34;.a10+88(SP), DX # 这里使用栈传递a10 0x014e 00334 ADDQ\t$10, DX 0x0152 00338 MOVQ\tDX, \u0026#34;\u0026#34;.r10+104(SP) 0x0157 00343 MOVQ\t\u0026#34;\u0026#34;.a11+96(SP), DX 0x015c 00348 ADDQ\t$11, DX 0x0160 00352 MOVQ\tDX, \u0026#34;\u0026#34;.r11+112(SP) # 这里使用栈传递 a11 0x0165 00357 MOVQ\t\u0026#34;\u0026#34;.r1+64(SP), AX # 注意这里返回参数的寄存器 0x016a 00362 MOVQ\t\u0026#34;\u0026#34;.r2+56(SP), BX 0x016f 00367 MOVQ\t\u0026#34;\u0026#34;.r3+48(SP), CX 0x0174 00372 MOVQ\t\u0026#34;\u0026#34;.r4+40(SP), DI 0x0179 00377 MOVQ\t\u0026#34;\u0026#34;.r5+32(SP), SI 0x017e 00382 MOVQ\t\u0026#34;\u0026#34;.r6+24(SP), R8 0x0183 00387 MOVQ\t\u0026#34;\u0026#34;.r7+16(SP), R9 0x0188 00392 MOVQ\t\u0026#34;\u0026#34;.r8+8(SP), R10 0x018d 00397 MOVQ\t\u0026#34;\u0026#34;.r9(SP), R11 0x0191 00401 MOVQ\t72(SP), BP 0x0196 00406 ADDQ\t$80, SP 0x019a 00410 RET 从上面的plan9可以看出来，函数入参和返回值确实是使用寄存器传递的，且寄存器信息是一致的。实际上到这里就足够了。但是笔者还需要确定下使用的寄存器名称并进行验证，因为这些参数是在做ebpf逻辑处理的时候使用的。\n# 使用ebpf获取入参并输出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // 这里表述下依据plan9寄存器符号推测的实际寄存器名称： #define GO_PARAM1(x) ((x)-\u0026gt;rax) #define GO_PARAM2(x) ((x)-\u0026gt;rbx) #define GO_PARAM3(x) ((x)-\u0026gt;rcx) #define GO_PARAM4(x) ((x)-\u0026gt;rdi) #define GO_PARAM5(x) ((x)-\u0026gt;rsi) #define GO_PARAM6(x) ((x)-\u0026gt;r8) #define GO_PARAM7(x) ((x)-\u0026gt;r9) #define GO_PARAM8(x) ((x)-\u0026gt;r10) #define GO_PARAM9(x) ((x)-\u0026gt;r11) struct event { u32 pid; u8 comm[64]; // args u64 arg0; u64 arg1; u64 arg2; u64 arg3; u64 arg4; u64 arg5; u64 arg6; u64 arg7; u64 arg8; u64 arg9; u64 arg10; }; SEC(\u0026#34;uprobe/main.longArgs\u0026#34;) int uprobe__main_long_args(struct pt_regs *ctx) { struct event args={}; args.pid = bpf_get_current_pid_tgid(); bpf_get_current_comm(\u0026amp;args.comm, sizeof(args.comm)); // read args 0-8，从寄存器中获取 args.arg0 = GO_PARAM1(ctx); args.arg1 = GO_PARAM2(ctx); args.arg2 = GO_PARAM3(ctx); args.arg3 = GO_PARAM4(ctx); args.arg4 = GO_PARAM5(ctx); args.arg5 = GO_PARAM6(ctx); args.arg6 = GO_PARAM7(ctx); args.arg7 = GO_PARAM8(ctx); args.arg8 = GO_PARAM9(ctx); // read args 9-10，从栈上获取 bpf_probe_read(\u0026amp;args.arg9, sizeof(args.arg9), (void*)(PT_REGS_SP(ctx))+8); bpf_probe_read(\u0026amp;args.arg10, sizeof(args.arg10), (void*)(PT_REGS_SP(ctx))+16); bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;args, sizeof(args)); return 0; } 编译完成后，启动这部分ebpf监听任务：\n1 2 3 4 5 6 7 8 9 10 # 启动监听 ./go_18 -bin_path ./arg/arg -uprobe main.longArgs 2023/03/03 22:07:32 Listening for events.. # 触发 ./arg/arg 执行 2023/03/03 22:07:46 pid: 756309, comm: arg 2023/03/03 22:07:46 /home/odin/pdliyan/blog/go_18/arg/arg: main.longArgs value: {Pid:756309 Comm:[97 114 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] _:[0 0 0 0] Arg0:1 Arg1:2 Arg2:3 Arg3:4 Arg4:5 Arg5:6 Arg6:7 Arg7:8 Arg8:9 Arg9:10 Arg10:11} # 请注意这里的参数是和我们的代码一致的。 2023/03/03 22:07:46 event info: {Pid:756309 Comm:[97 114 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] _:[0 0 0 0] Arg0:1 Arg1:2 Arg2:3 Arg3:4 Arg4:5 Arg5:6 Arg6:7 Arg7:8 Arg8:9 Arg9:10 Arg10:11} # 退出 2023/03/03 22:08:38 Received signal, exiting program... 从上面的输出可以确定plan9的寄存器符号和实际寄存器的对应关系是正确的。\n以上就验证了困扰笔者的go-17+参数调用规约的问题。可以看到，依旧十分的奇葩。\n周末愉快。\n","date":"2023-03-03T20:59:00Z","permalink":"http://localhost:1313/p/go-1.17-%E8%B0%83%E7%94%A8%E8%A7%84%E7%BA%A6/","title":"go-1.17+ 调用规约"},{"content":" 在这里对文章题目作一些说明。笔者想了很长时间也无法给这篇文章想个恰当的表意题目。实际上使用ebpf来进行服务观测是有在进行的，比如获取目前l1s上的常见的四元组。但是本文不是介绍这部分可观测实践的。文章希望阐述的场景是：采集请求触发里的一些信息（诸如trace及其他header等）并和服务请求下游的传输层五元组(protocol, src-ip, src-port, dst-ip, dst-port)进行关联。这也是最近工作中实际遇到的问题。\n基于ebpf的丰富的特性能够获取服务很多的信息，不同特性的组合更是可以达到极强的数据整合能力。比如通过uprobe便捷的获取业务信息后，结合kprobe来获取系统调用里的内容，可以获取一般侵入式可观测代码无法获取的内容。笔者最近遇到的一个实际问题是：获取服务A的接口/a响应后，向下游B发起的请求时，所使用的传输层五元组，同时带上结合一些/a触发时的一些内容，比如caller_fun或者traceId。\n这里值得说明的是，用户态请求的是一个域名。域名的解析是在golang的http里完成的。但是请注意，golang发起tcp请求时，local port设置的是0，然后由内核态的tpc处理来选择一个空闲的port作为socket里的lport。这部分的信息通过代码的埋点显然是无法获取的（详情可参考TCP连接中客户端的端口号是如何确定的？）。\n下面介绍下实现效果及思路。\n关于bpftrace使用的介绍，可以参见：bpftrace 无侵入遍历golang链表，关于ebpf来进行数据采集的实践，可以参见ebpf采集mysql请求信息及ebpf对应用安全的思考。\n# 实现效果 服务端启动、触发的效果：\n1 2 3 4 5 6 7 8 9 10 11 # 启动目标服务 ./caller_tuple [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \u0026#34;debug\u0026#34; mode. Switch to \u0026#34;release\u0026#34; mode in production. - using env:\texport GIN_MODE=release - using code:\tgin.SetMode(gin.ReleaseMode) [GIN-debug] GET /echo --\u0026gt; main.Echo (3 handlers) # 这里触发一次接口调用 [GIN] 2023/02/24 - 22:05:29 | 200 | 85.618975ms | 127.0.0.1 | GET \u0026#34;/echo\u0026#34; bpftrace 采集端的效果：\n1 2 3 4 5 6 7 8 # 启动采集 bpftrace ./caller.bt Attaching 3 probes... start to gather caller info. get caller path: /echo # 将 caller_path 和 传输层五元组结合起来（本机的IP实际上是输出的，但是为了信息安全，就使用 0.0.0.0 来代替了） caller info: /echo 3326691 caller_tuple 0.0.0.0 38610 110.242.68.66 80 # 代码实现 这里分别上一下目标服务caller_func以及采集脚本caller.bt的代码，来说明下实现思路。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 // ./caller_tuple/main.go package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) type Resp struct { Errno int64 `json:\u0026#34;errno\u0026#34;` Msg string `json:\u0026#34;msg\u0026#34;` } func Echo(c *gin.Context) { req, _ := http.NewRequest(http.MethodGet, \u0026#34;http://baidu.com\u0026#34;, nil) client := http.Client{} resp, err := client.Do(req) if err != nil { c.JSON(http.StatusOK, \u0026amp;Resp{Errno: 1, Msg: \u0026#34;request error\u0026#34;}) return } defer resp.Body.Close() c.JSON(http.StatusOK, \u0026amp;Resp{Errno: 0, Msg: \u0026#34;ok\u0026#34;}) return } func main() { r := gin.Default() srv := \u0026amp;http.Server{ Addr: \u0026#34;0.0.0.0:3344\u0026#34;, } r.GET(\u0026#34;/echo\u0026#34;, Echo) srv.Handler = r srv.ListenAndServe() } // caller_tuple/caller.bt #!/usr/bin/env bpftrace #define AF_INET 2 struct sock_common { union { struct { __be32 skc_daddr; __be32 skc_rcv_saddr; }; }; union { unsigned int skc_hash; __u16 skc_u16hashes[2]; }; union { struct { __be16 skc_dport; __u16 skc_num; }; }; short unsigned int skc_family; }; struct sock { struct sock_common __sk_common; }; BEGIN{ printf(\u0026#34;start to gather caller info. \u0026#34;); @caller[pid] = \u0026#34;none\u0026#34;; } // 这里通过 uprobe 来便捷的获取会话信息。同时将信息写入bpf_map uprobe:./caller_tuple:\u0026#34;net/http.serverHandler.ServeHTTP\u0026#34;{ $req_ptr = sarg3; $method_ptr = *(uint64*)($req_ptr); $method_len = *(uint64*)($req_ptr+8); /* read request.url.Path */ $url_ptr = *(uint64*)($req_ptr + 16); $path_ptr = *(uint64*)($url_ptr+56); $path_len = *(uint64*)($url_ptr+64); printf(\u0026#34;get caller path: %s \u0026#34;, str($path_ptr, $path_len)); // 这里使用 pid 来作为 key 只是为了实现方便。实际可以采取其他更有区分性的内容。 @caller_ptr[pid]=$path_ptr; @caller_len[pid]=$path_len; } // 通过 kprobe 来获取用户态无法获取的内容。同时通过 bpf_map 来控制生效及内容的交互。 kprobe:tcp_connect { if (@caller_ptr[pid] == 0){ return; } $ptr = @caller_ptr[pid]; $len = @caller_len[pid]; printf(\u0026#34;caller info: %s \u0026#34;, str($ptr, $len)); @caller_ptr[pid] = 0; @caller_len[pid] = 0; $sk = ((struct sock *) arg0); $inet_family = $sk-\u0026gt;__sk_common.skc_family; if ($inet_family == AF_INET) { $daddr = ntop($sk-\u0026gt;__sk_common.skc_daddr); $saddr = ntop($sk-\u0026gt;__sk_common.skc_rcv_saddr); $lport = $sk-\u0026gt;__sk_common.skc_num; $dport = $sk-\u0026gt;__sk_common.skc_dport; $dport = (((($dport) \u0026gt;\u0026gt; 8) \u0026amp; 0xff) | ((($dport) \u0026amp; 0xff) \u0026lt;\u0026lt; 8)); printf(\u0026#34;%-8d %-16s \u0026#34;, pid, comm); printf(\u0026#34;%-39s %-6d %-39s %-6d \u0026#34;, $saddr, $lport, $daddr, $dport); } } 这样就达到了笔者的目标。这只是ebpf应用的一个简单的场景，更多的metric采集内容仍在进行。\n以上，周末愉快！\n","date":"2023-02-24T21:44:49Z","permalink":"http://localhost:1313/p/ebpf-%E9%87%87%E9%9B%86ebpf-%E9%87%87%E9%9B%86tag-tcp%E4%BA%94%E5%85%83%E7%BB%84/","title":"ebpf 采集ebpf 采集tag+tcp五元组"},{"content":" 工作中难免会搞一些思维导图，一些小的需求又不希望切换窗口到另外一个界面去特地绘制。使用 emacs 来整理思维导图可以提升一些的效率，在当前窗口（文本编辑器）里即可完成简单思维导图的绘制。同时可以便于对工作内容进行归档（比如把相关的文本都放到一起）。live in emacs.\n# 依赖内容 org-contrib 扩展文件。用来将 org-mode 格式的文本转换成 freemind mm 文件。 freemind 软件。用来查看生成的 mm 文件。 笔者试了一下，Xmind思维导图看起来无法打开mm文件，freemind工作正常。也可能是我操作有问题。\n此外，生成的思维导图展现样式肯定没有目前专业的思维导图工具丰富，如果有正式的使用需求，还是首先考虑下专业的思维导图工具。\n# org-contrib 安装 笔者使用的emacs发布版本默认没有org-contrib，需要自行安装。安装过程也比较简单，从github里把org-contrib拉下来，在emacs init.el里配置加载路径，然后主动加载需要的ox-freemind.el即可。\ngithub org-contrib地址为git@github.com:emacsmirror/org-contrib.git。目录地址可以视自己的需求确定。笔者的emacs配置都放到了.emacs.d里，org-contrib的本地目录也就放到了~/.emacs.d/org-contrib这里。扩展下载后，在init.el里做如下配置即可：\n1 2 3 4 5 ;; ox-fremind ;; 这里改成本地的 org-contrib 地址 (add-to-list \u0026#39;load-path \u0026#34;~/.emacs.d/org-contrib/lisp\u0026#34;) ;; 目前只需要 ox-freemind，因此仅加载这个插件。 (load-file \u0026#34;~/.emacs.d/org-contrib/lisp/ox-freemind.el\u0026#34;) 安装结束后，需要重新加载一下emacs的配置文件，ox-freemind才能可用。\n# 使用 org-mode 整理文档并转换 这里直接贴一个示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #+TITLE: emacs org-mode 绘制思维导图 #+OPTIONS: H:1000 * org-contrib 安装 org-contrib 可以直接从 github 下载，然后在 emacs 配置文件里加载。 ** org-contrib github 地址 *** git@github.com:emacsmirror/org-contrib.git ** emacs 本地配置 *** (add-to-list \u0026#39;load-path \u0026#34;~/.emacs.d/org-contrib/lisp\u0026#34;)(load-file \u0026#34;~/.emacs.d/org-contrib/lisp/ox-freemind.el\u0026#34;) * org-mode 下文档编写 ** org-mode 是 emacs 下的神器 *** 打开 freemind.org 文件，输入这个文本 ** 转换文本文件到 freemind mm 文件 *** M-x org-freemind-export-to-freemind * 查看 mm 文件 ** 使用 freemind 查看生成的 freemind.mm 用emacs打开一个freemind.org，笔者这里直接触发了org-mode。如果没有触发org-mode的话，需要手动执行下M-x org-mode。然后执行org-freemind-export-to-freemind。如果没有这个函数，需要看下之前org-contrib的安装是否有问题，或者加载路径是否正常，加载是否有报错。如果函数执行异常，则需要查下原因。笔者安装后即可直接执行，因此没有报错处置的经验可供参考。\n# 使用freemind查看及导出 mac可以直接brew install --cask freemind。或者到其他下载源下载，如freemind sourceforge 下载。\n最后使用freemind打开freemind.org同级目录生成的freemind.mm。展示效果如下： 最后，可以使用emacs查看导出的freemind.png（🐶，笔者还在探索如何在不打开freemind的情况下把mm文件转换成png)。\n","date":"2023-02-10T19:46:21Z","permalink":"http://localhost:1313/p/emacs-org-mode-%E7%BB%98%E5%88%B6%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/","title":"emacs org-mode 绘制思维导图"},{"content":" 即将过去的2022年，笔者相当比例的精力都投入在了eBPF上。最初的时候，写了一篇golang 常见类型字节数 ，开启了eBPF+golang的总结性工作。此后陆续整理了一些关于ebpf的使用文章，同时项目也在逐步的推进。eBPF的实际落地有很大的挑战，但是最终还是找到了一些落地的场景。年底了，结合最近的调研工作，笔者整理了这篇文章。既算是对之前文章的呼应，也是对今年整理内容的总结。\neBPF能够提供一种切入服务细节的独特视角。本文即通过实例，对golang常见类型作为函数参数时进行解析，期望读者能够感受这一视角。需要说明的是，本文是基于golang-1.16来整理的。\n# 数值类型 目前golang支持的数值类型大概有int, int8, int16, int32, int64及相对应的无符号类型。无符号类型在传递时和对应的有符号类型是一致的，这里不再赘述。int在不同平台上大小会不同，64位操作系统时，sizeof(int)=sizeof(int64)。作为参数传递时，数值类型会直接传递值。\n一般来说，int8, int16, int32在作为参数传递时，基于内存对齐的原则，会使用8B的空间来传递。但是并不绝对，笔者在准备本篇文章时，就找到了这样的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // type/main.go package main import \u0026#34;fmt\u0026#34; // 如果严格按照\u0026#34;内存对齐\u0026#34;来推算，int_p 的参数大小应为 8B*5 //go:noinline func int_p(a int8, b int16, c int32, d int64, e int) { fmt.Println(a, b, c, d, e) } func main() { int_p(1, 2, 3, 4, 5) } /* 从输出结果来看，int_p 参数列表带大小为 3*8B，其中第一个 8B 的分布为： |int8|--|int16|int32| | 1B |1B| 2B | 4B | type/type.bt */ uprobe:./type:\u0026#34;main.int_p\u0026#34; { printf(\u0026#34;int8: %d \u0026#34;, (int8)(sarg0)); printf(\u0026#34;int16: %d \u0026#34;, (int16)(sarg0\u0026gt;\u0026gt;16)); printf(\u0026#34;int32: %d \u0026#34;, (int32)(sarg0\u0026gt;\u0026gt;32)); printf(\u0026#34;int64: %d \u0026#34;, sarg1); printf(\u0026#34;int: %d \u0026#34;, sarg2); } // 运行结果 Attaching 1 probe... int8: 1 int16: 2 int32: 3 int64: 4 int: 5 由此可知，当数值类型作为函数参数时，需要结合前后参数来判断是否触发了内存对齐，进而判断数值类型参数的具体位置。\n# string string是由8B addr + 8B length来描述的。作为函数参数传递时，亦通过这样的方式来解析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // type/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func string_p(name string) { fmt.Println(name) } func main() { name := string(\u0026#34;didi\u0026#34;) string_p(name) } // type/type.bt uprobe:./type:\u0026#34;main.string_p\u0026#34; { printf(\u0026#34;addr: %d \u0026#34;, sarg0); printf(\u0026#34;length: %d \u0026#34;, sarg1); printf(\u0026#34;name: %s \u0026#34;, str(sarg0, sarg1)); } bpftrace ./type.bt Attaching 1 probe... addr: 4958864 // 所谓的地址，就是这么个东西 @V@ length: 4 name: didi 由于string的地址和长度都是8B，所以不会触发内存对齐。\n# slice slice是由8B addr + 8B length + 8B cap来描述的。作为函数值来传递时，需要关注地址及长度，以防止出现过解析的情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // type/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func slice_p(slices []int64) { fmt.Println(slices) } func main() { slices := []int64{1, 2, 3} slice_p(slices) } // type/type.bt uprobe:./type:\u0026#34;main.slice_p\u0026#34; { printf(\u0026#34;addr: %d \u0026#34;, sarg0); printf(\u0026#34;length: %d \u0026#34;, sarg1); printf(\u0026#34;cap: %d \u0026#34;, sarg2); $pos = 0; $offset = 0; unroll(10){ if ($pos \u0026gt;= sarg1){ return; } $value = *(int64*)(sarg0+$offset); printf(\u0026#34;%d: %d \u0026#34;, $pos, $value); $offset = $offset+8; $pos = $pos + 1; } return; } bpftrace ./type.bt Attaching 1 probe... addr: 1310720 length: 3 cap: 3 0: 1 1: 2 2: 3 由于eBPF对循环的长度是有限制的，所以通过循环来读取数据会麻烦。一般可以直接将所有的数据都读出来，记录长度并将其传递到用户空间处理。\n# 定长数组 golang的定长数组在传递时，会直接将数据拷贝上去。所以一般是不建议使用定长数组作为函数参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // type/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func array_p(slices [4]int64) { fmt.Println(slices) } func main() { arrays := [4]int64{1, 2, 3, 4} array_p(arrays) } // type/type.bt uprobe:./type:\u0026#34;main.array_p\u0026#34; { printf(\u0026#34;arr[0]: %d \u0026#34;, sarg0); printf(\u0026#34;arr[1]: %d \u0026#34;, sarg1); printf(\u0026#34;arr[2]: %d \u0026#34;, sarg2); printf(\u0026#34;arr[3]: %d \u0026#34;, sarg3); return; } bpftrace ./type.bt Attaching 1 probe... arr[0]: 1 arr[1]: 2 arr[2]: 3 arr[3]: 4 需要注意的是，定长数组作为结构体参数时，也是直接将参数堆积的，而不是类似slice的由指针及长度组成。\n# 结构体 golang结构体作为函数参数传递时，会直接将结构体内的成员逐个传递。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // type/main.go package main import ( \u0026#34;fmt\u0026#34; ) type S struct { X int64 Y int64 Z [3]int64 A int64 } // 请注意 other 参数，虽然其作为函数的第二个参数，但其在函数列表中的偏移量是 48B //go:noinline func struct_p(s S, other int64) { fmt.Println(s, other) } func main() { s := S{ X: 1, Y: 2, Z: [3]int64{3, 4, 5}, A: 6, } struct_p(s, 7) } // type/type.bt uprobe:./type:\u0026#34;main.struct_p\u0026#34; { printf(\u0026#34;X: %d \u0026#34;, sarg0); printf(\u0026#34;Y: %d \u0026#34;, sarg1); printf(\u0026#34;A: %d \u0026#34;, sarg5); printf(\u0026#34;other: %d \u0026#34;, sarg6); return; } bpftrace ./type.bt Attaching 1 probe... X: 1 Y: 2 A: 6 other: 7 结构体作为函数参数，往往会涉及到内存对齐的问题。需要逐个分析了。\n# 指针 golang指针作为函数参数时，会直接传递指针数值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // type/main.go package main import ( \u0026#34;fmt\u0026#34; ) type P struct { X int64 Y int64 Z [3]int64 A int64 } //go:noinline func pointer_p(p *P) { fmt.Println(*p) } func main() { p := \u0026amp;P{ X: 1, Y: 2, Z: [3]int64{3, 4, 5}, A: 6, } pointer_p(p) } // type/type.bt uprobe:./type:\u0026#34;main.pointer_p\u0026#34; { $p = sarg0; printf(\u0026#34;X: %d \u0026#34;, *(int64*)($p+0)); printf(\u0026#34;Y: %d \u0026#34;, *(int64*)($p+8)); printf(\u0026#34;A: %d \u0026#34;, *(int64*)($p+40)); return; } bpftrace ./type.bt Attaching 1 probe... X: 1 Y: 2 A: 6 解析golang指针成员的时候，需要提前知晓指针结构体的内容。\n# map golang的map实现比较复杂，详细的介绍可以看下这篇文章：golang map。map作为参数传递时，实际上传递的是hmap的指针。\n由于golang的map实际的结构及具体结构体的大小会受到map key, map value的影响，这对使用eBPF来解析golang map带来了额外的挑战。所幸本文并不期望提供一个golang map解析的通用方法，我们可以提前定义所需要解析的map为map[int64]int64，在这个条件下，bmap的结构就为：\n1 2 3 4 5 6 7 8 // sizeof(bmap) = 144B type bmap struct { topbits [8]uint8 // 8B keys [8]int64 // 64B values [8]int64 // 64B //pad uintptr //不需要添加内存对齐参数 overflow uintptr } 确定了bmap的信息后，可以看到，keys及values的偏移信息就确定了，可以直接读取。但是由于key实际映射时是通过hash来决定其位置的，完整的读取map显然是很困难的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // type/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func map_p(m map[int64]int64) { fmt.Println(m) } func main() { m := map[int64]int64{} for i := int64(1); i \u0026lt;= int64(10); i++ { m[i] = i } map_p(m) } // type/type.bt uprobe:./type:\u0026#34;main.map_p\u0026#34; { $hmap_addr = sarg0; $bucket_addr = *(uint64*)($hmap_addr+16); $bucket_offset = 0; unroll(2){ // 尝试读取两个 bmap $bmap_addr = $bucket_addr + $bucket_offset; $key_addr = $bmap_addr + 8; $value_addr = $bmap_addr + 72; $offset = 0; unroll(8){ // 读取每个 bmap 的所有 key-value $key = *(int64*)($key_addr+$offset); $value = *(int64*)($value_addr+$offset); printf(\u0026#34;key: %d, value: %d \u0026#34;, $key, $value); $offset = $offset + 8; } $bucket_offset = $bucket_offset + 144; } return; } // 笔者的这次运行，把[1,10]所有的key都输出了 bpftrace ./type.bt Attaching 1 probe... key: 2, value: 2 key: 3, value: 3 key: 5, value: 5 key: 6, value: 6 key: 7, value: 7 key: 8, value: 8 key: 9, value: 9 key: 10, value: 10 key: 1, value: 1 key: 4, value: 4 key: 0, value: 0 key: 0, value: 0 key: 0, value: 0 key: 0, value: 0 key: 0, value: 0 key: 0, value: 0 使用eBPF来读取map，不得不预设一个确定的大小。至于是否能够读取所有的map值，就不好说了。\n# interface golang的interface是由8B type pointer+8B struct pointer组成的。当解析interface的时候，需要的往往是struct pointer。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // type/main.go package main import ( \u0026#34;fmt\u0026#34; ) type Inter interface{} type S struct { X int64 Y int64 Z [3]int64 A int64 } //go:noinline func struct_p(i Inter, other int64) { s, _ := i.(S) fmt.Println(s, other) } func main() { s := S{ X: 1, Y: 2, Z: [3]int64{3, 4, 5}, A: 6, } struct_p(s, 7) } // type/type.bt uprobe:./type:\u0026#34;main.struct_p\u0026#34; { $addr = sarg1; printf(\u0026#34;X: %d \u0026#34;, *(int64*)($addr+0)); printf(\u0026#34;Y: %d \u0026#34;, *(int64*)($addr+8)); printf(\u0026#34;A: %d \u0026#34;, *(int64*)($addr+40)); printf(\u0026#34;other: %d \u0026#34;, sarg2); return; } bpftrace ./type.bt Attaching 1 probe... X: 1 Y: 2 A: 6 other: 7 从示例中可以看出，当解析interface时，interface具体的结构体成员对我们而言更加重要。在实际的工程里，往往会出现多个结构体实现同一个interface，并且均可以作为该interface来传递值的情况。这时就需要依据所实际期望解析的结构体来进行实际采集的过滤或者适配了。\n# 写在最后 本文编写的文章超过了笔者的估计时间 :)。anyway，这篇文章最终整理完成了。期望有读者能够籍此对eBPF有直观的认识，同时体会到其观察golang的独特视角。\n周末愉快，新年快乐！\n","date":"2022-12-30T19:24:18Z","permalink":"http://localhost:1313/p/golang%E5%B8%B8%E8%A7%81%E7%B1%BB%E5%9E%8B%E4%BD%9C%E4%B8%BA%E5%8F%82%E6%95%B0%E7%9A%84ebpf%E8%A7%A3%E6%9E%90/","title":"golang常见类型作为参数的eBPF解析"},{"content":" 虽然golang并不推荐使用goid来构建gls(goroutine local storage)，仍然有着很多的实现gls并使用的尝试。github-gls这里是一个常见的实现，基本表述了golang里gls的实现思路：获取goid，基于goid构建一个存储。本文中笔者尝试基于ebpf来构建一个golang的gls。\n# 基本功能 本文中基于ebpf实现的gls具有如下功能：\n基于goid的存储。即map[goid]=value； 基于goroutine派生关系设置的value缺省值。即map[goid=1]=121，且goid=1派生goid=2，则map[goid=2]=map[goid=1]=121；\n本文建议参照黑魔法-ebpf-对用户空间数据的写入进行理解。 # 用户态代码及效果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) var Len = 5 // 当 info 为空时，使用父 goid 设置的值，否则存入 info func Go1(ctx context.Context, info string, wg *sync.WaitGroup) { defer wg.Done() third := Third{} if info != \u0026#34;\u0026#34; { third.Store(info) } /* 诸多其他的逻辑 */ info1 := third.Get() fmt.Printf(\u0026#34;raw info: [%s], info get: [%s] \u0026#34;, info, info1) } //go:noinline func Set(info []byte) { if len(info) \u0026gt; Len { info = info[:Len] } if len(info) \u0026lt; Len { tmp := make([]byte, Len-len(info)) info = append(tmp, info...) } fmt.Println(\u0026#34;info: \u0026#34;, string(info)) return } //go:noinline func Get(info []byte) []byte { // alalalala, magic come return info } type Third struct { Info string } func (t *Third) Store(info string) { infoByt := []byte(info) // 这里假设是个约束 infoByt = infoByt[:Len] Set(infoByt) } func (t *Third) Get() string { infoByt := make([]byte, Len, Len) infoByt = Get(infoByt) return string(infoByt) } func main() { third1 := Third{} info := \u0026#34;12345\u0026#34; third1.Store(info) wg := \u0026amp;sync.WaitGroup{} ctx := context.Background() wg.Add(1) go Go1(ctx, \u0026#34;\u0026#34;, wg) // 写入空数据，预期使用父 goid 数据，即 12345 for i := 1125; i \u0026lt; 1130; i++ { wg.Add(1) v := strconv.Itoa(i) if i%10 == 0 { v = \u0026#34;\u0026#34; } go Go1(ctx, v, wg) } wg.Wait() /* very long handle logic*/ third2 := Third{} infoGet := third2.Get() fmt.Printf(\u0026#34;in main, getInfo, [%s] \u0026#34;, infoGet) } 执行结果为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // 未开启 bpf info: 12345 info: 1129 raw info: [1129], info get: [] info: 1126 raw info: [1126], info get: [] info: 1128 raw info: [1128], info get: [] raw info: [], info get: [] info: 1125 info: 1127 raw info: [1125], info get: [] raw info: [1127], info get: [] in main, getInfo, [] // 开启 bpf info: 12345 info: 1129 raw info: [], info get: [12345] // 传入空值，使用父 goid 存入数据 raw info: [1129], info get: [1129] info: 1126 raw info: [1126], info get: [1126] info: 1127 raw info: [1127], info get: [1127] info: 1125 raw info: [1125], info get: [1125] info: 1128 raw info: [1128], info get: [1128] in main, getInfo, [12345] 上述示例对比了开启bpf前后的用户态代码输出。可以看到，当子goroutine缺少某个信息时，可以获取父goroutine的数据作为缺省值。\n# 应用 意味着我们可以在父goroutine中存入我们需要的数据，而后无论是否创建新的goroutine，均能获取该信息。维护了goroutine session的数据。\n# ebpf 逻辑 这里仍然附上了ebpf的主要逻辑以便说明实现过程。除了之前文章中涉及的ebpf向用户态写入数据，本文使用了golang创建goroutine相关的uprobe来维护goroutine session状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 struct { __uint(type, BPF_MAP_TYPE_LRU_HASH); __uint(key_size, sizeof(u64)); // pid_tgid __uint(value_size, sizeof(u64)); // parent goid __uint(max_entries, MAX_ENTRIES); } go_goid_map SEC(\u0026#34;.maps\u0026#34;); // 用来获取 goid 状态 struct { __uint(type, BPF_MAP_TYPE_HASH); __uint(key_size, sizeof(u64)); __uint(value_size, sizeof(u8) * 5); __uint(max_entries, 100); } info_map SEC(\u0026#34;.maps\u0026#34;); // 用来存储 goid-\u0026gt;info struct { __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY); } events SEC(\u0026#34;.maps\u0026#34;); static __always_inline u64 get_goid(u32 tgid, u32 pid) { unsigned long task_addr = (unsigned long)bpf_get_current_task(); unsigned long fsbase = 0; unsigned long g = 0; u64 goid = 0; // 直接基于 偏移量进行处理了 // offset(task_struct, thread) = 4992 // offset(thread_struct, fsbase) = 40 bpf_probe_read(\u0026amp;fsbase, sizeof(fsbase), (void *)(task_addr + OFF_TASK_THRD + OFF_THRD_FSBASE)); bpf_probe_read(\u0026amp;g, sizeof(g), (void *)(fsbase - 8)); bpf_probe_read(\u0026amp;goid, sizeof(goid), (void *)(g + GOID_OFFSET)); return goid; } SEC(\u0026#34;uprobe/main_set\u0026#34;) int uprobe__main_set(struct pt_regs *ctx) { uintptr_t info_p = 0; u8 info[5]; u64 pid_tgid = bpf_get_current_pid_tgid(); u32 pid = (u32)(pid_tgid \u0026amp; 0x00FF); u32 tgid = (u32)(pid_tgid \u0026gt;\u0026gt; 32); u64 goid = 0; goid = get_goid(tgid, pid); SARG(ctx, 0, info_p); bpf_probe_read(\u0026amp;info, sizeof(info), (const void *)info_p); bpf_map_update_elem(\u0026amp;info_map, \u0026amp;goid, \u0026amp;info, BPF_ANY); event_t event = {}; event.pid_tgid = pid_tgid; memcpy(event.info, info, sizeof(info)); bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } SEC(\u0026#34;uprobe/main_get\u0026#34;) int uprobe__main_get(struct pt_regs *ctx) { uintptr_t info_p = 0; u64 pid_tgid = bpf_get_current_pid_tgid(); u32 pid = (u32)(pid_tgid \u0026amp; 0x00FF); u32 tgid = (u32)(pid_tgid \u0026gt;\u0026gt; 32); u64 goid = 0; goid = get_goid(tgid, pid); void *r_info_p = NULL; r_info_p = bpf_map_lookup_elem(\u0026amp;info_map, \u0026amp;goid); if (r_info_p == NULL) { return 0; } event_t event = {}; event.pid_tgid = pid_tgid; SARG(ctx, 0, info_p); u8 info[5]; memcpy(info, r_info_p, sizeof(info)); memcpy(event.info, info, sizeof(event.info)); event.res = bpf_probe_write_user((u8 *)info_p, info, sizeof(info)); event.addr = info_p; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } /* golang_runtime_newproc1 func newproc1(fn *funcval, argp unsafe.Pointer, narg int32, callergp *g, callerpc uintptr) *g { */ SEC(\u0026#34;uprobe/golang_runtime_newproc1\u0026#34;) int uprobe__golang_runtime_newproc1(struct pt_regs *ctx) { u64 pid_tgid = bpf_get_current_pid_tgid(); uintptr_t g_addr = 0; u64 cur_goid = 0; SARG(ctx, 3, g_addr); bpf_probe_read(\u0026amp;cur_goid, sizeof(cur_goid), (void *)(g_addr + GOID_OFFSET)); bpf_map_update_elem(\u0026amp;go_goid_map, \u0026amp;pid_tgid, \u0026amp;cur_goid, BPF_ANY); return 0; } SEC(\u0026#34;uprobe/golang_runtime_runqput\u0026#34;) int uprobe__golang_runtime_runqput(struct pt_regs *ctx) { u64 pid_tgid = bpf_get_current_pid_tgid(); uintptr_t g_addr = 0; u64 *parent_goid = NULL; u64 child_goid = 0; void *v_p = NULL; parent_goid = bpf_map_lookup_elem(\u0026amp;go_goid_map, \u0026amp;pid_tgid); if (parent_goid == NULL) { return 0; } // 1. 获取新 goroutine 的 goid SARG(ctx, 1, g_addr); bpf_probe_read(\u0026amp;child_goid, sizeof(child_goid), (void *)(g_addr + GOID_OFFSET)); // 2. 设置新 goid 绑定的 caller 信息 v_p = bpf_map_lookup_elem(\u0026amp;info_map, parent_goid); if (v_p == NULL) { return 0; } // 设置子 goid 绑定 caller 为 父 goid 信息 bpf_map_update_elem(\u0026amp;info_map, \u0026amp;child_goid, v_p, BPF_ANY); bpf_map_delete_elem(\u0026amp;go_goid_map, \u0026amp;pid_tgid); return 0; } 以上。\n","date":"2022-11-25T01:14:00Z","permalink":"http://localhost:1313/p/%E5%9F%BA%E4%BA%8Eebpf%E5%AE%9E%E7%8E%B0%E7%9A%84gls/","title":"基于ebpf实现的gls"},{"content":"在之前的示例中，仅涉及到ebpf对用户空间数据的读取。工程性较强的如：ebpf采集mysql请求信息及ebpf对应用安全的思考也仅是通过urpobe采集用户空间的数据。本文介绍点ebpf的“黑魔法”：将用户空间数据的读取、用户空间数据的写入结合起来，成为用户空间数据交互的桥梁。\n# 运行效果 在看运行效果之前，需要先看下目标示例的代码以便更好的理解本文介绍的功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // user/obj/obj.go package main import ( \u0026#34;fmt\u0026#34; ) var Len = 5 // 预设的 uprobe //go:noinline func Set(info []byte) { fmt.Println(\u0026#34;info: \u0026#34;, string(info)) return } // 预设的 uprobe //go:noinline func Get(info []byte) []byte { fmt.Printf(\u0026#34;info addr: %p \u0026#34;, info) fmt.Println(string(info)) // 请注意这里的输出操作 return info } type Third struct { Info string } func (t *Third) SetSomething(info string) { infoByt := []byte(info) // 这里假设是个约束 infoByt = infoByt[:Len] Set(infoByt) // 在这里调用预设的处理函数 } func (t *Third) GetSomething() string { infoByt := make([]byte, Len, Len) infoByt = Get(infoByt) // 在这里调用预设的处理函数 return string(infoByt) } func main() { third1 := Third{} info := \u0026#34;12345\u0026#34; third1.SetSomething(info) // 请注意，这里进行写入的对象 /* very long handle logic, many goroutines or proces happend here */ third2 := Third{} // 请注意，这里读取的对象和上述执行写入的对象是完全没有关系的 infoGet := third2.GetSomething() fmt.Printf(\u0026#34;after getInfo, [%s] \u0026#34;, infoGet) } 这段代码非常简单，下面进行了两次执行来说明ebpf达到的效果：\n1 2 3 4 5 6 7 8 9 10 11 $ ./obj // 第一次，没有使用 ebpf 生效。代码的正常输出结果 info: 12345 info addr: 0xc0000180f0 // 请注意这里 after getInfo, [] $ ./obj // 第二次，开始执行前开启 ebpf 监听 info: 12345 info addr: 0xc0000180f0 12345 // 请注意这里 after getInfo, [12345] 请关注上述示例里的注释。通过ebpf的attach，实现了数据从用户空间-\u0026gt;ebpf空间-\u0026gt;用户空间，这个过程并不关心用户代码里发生了什么，ebpf只关注预设的uprobe是怎么被调用的。\n# 应用及思考 ebpf的这个功能显然具有很广泛的应用，但是具体的应用就需要结合业务的应用来说明了（颇有一些拿着锤子找钉子的感觉），比如：结合调用了特定埋点sdk的使用，能够用来对traceId信息的补全。\n事物自然都有两面性，ebpf提供了变更用户空间数据的潜力，自然就会带来风险：代码里的逻辑似乎不再靠谱了。而且，想象下将代码里的读操作，变更为删除操作，将会对用户空间的安全造成很大的破坏。\n# ebpf 逻辑 之前一直是使用bpftrace来进行示例演示的，但是本文涉及的功能需要使用long bpf_probe_write_user(void *dst, const void *src, u32 len)这个bpf-helper函数。笔者没有找到bpftrace里的调用方式，因此采用cilium-ebpf来进行示例演示。其中涉及的主要bpf代码附在下面，基本表述了相对原生的bpf-helper的调用方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 struct{ __uint(type, BPF_MAP_TYPE_HASH); __uint(key_size, sizeof(u32)); __uint(value_size, sizeof(u8)*5); __uint(max_entries, 100); } info_map SEC(\u0026#34;.maps\u0026#34;); struct event{ u64 pid_tgid; u8 info[5]; // 这里的成员长度，请结合 obj.go 来看 uintptr_t addr; long res; }; typedef struct event event_t; // Force emitting struct event into the ELF. const struct event *unused __attribute__((unused)); struct { __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY); } events SEC(\u0026#34;.maps\u0026#34;); SEC(\u0026#34;uprobe/main_set\u0026#34;) int uprobe__main_set(struct pt_regs *ctx){ uintptr_t info_p = 0; u8 info[5]; u64 pid_tgid = bpf_get_current_pid_tgid(); SARG(ctx, 0, info_p); bpf_probe_read(\u0026amp;info, sizeof(info), (const void*)info_p); u32 tgid = (u32)(pid_tgid \u0026gt;\u0026gt; 32); bpf_map_update_elem(\u0026amp;info_map, \u0026amp;tgid, \u0026amp;info, BPF_ANY); event_t event = {}; event.pid_tgid = pid_tgid; memcpy(event.info, info, sizeof(info)); bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } SEC(\u0026#34;uprobe/main_get\u0026#34;) int uprobe__main_get(struct pt_regs *ctx){ uintptr_t info_p = 0; u64 pid_tgid = bpf_get_current_pid_tgid(); void* r_info_p = NULL; u32 tgid = (u32)(pid_tgid \u0026gt;\u0026gt; 32); r_info_p = bpf_map_lookup_elem(\u0026amp;info_map, \u0026amp;tgid); if (r_info_p == NULL){ return 0; } event_t event = {}; event.pid_tgid = pid_tgid; SARG(ctx, 0, info_p); u8 info[5]; memcpy(info, r_info_p, sizeof(info)); memcpy(event.info, info, sizeof(event.info)); event.res = bpf_probe_write_user((u8*)info_p, info, sizeof(info)); event.addr = info_p; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } 以上，周末愉快。\n","date":"2022-11-04T18:00:00Z","permalink":"http://localhost:1313/p/%E9%BB%91%E9%AD%94%E6%B3%95--%E7%94%A8-ebpf-%E6%9E%84%E5%BB%BA%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E6%A1%A5%E6%A2%81/","title":"黑魔法--用 ebpf 构建用户空间数据的桥梁"},{"content":" 本文笔者继续介绍ebpf 的应用：使用bpftrace采集mysql连接信息，包括数据库地址、db_name、user_name。在展示采集操作的同时，附上对ebpf对云时代应用安全的一些思考。\n# 目标 使用bpftrace对一个运行中进程的mysql请求进行采集，目标采集内容包括数据库地址、db_name、user_name。\n目标进程代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 // blog/main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;xorm.io/xorm\u0026#34; ) var sqlE *xorm.Engine func init() { fmt.Println(\u0026#34;init from main\u0026#34;) var err error sqlE, err = xorm.NewEngine(\u0026#34;mysql\u0026#34;, \u0026#34;test:mysqltest@tcp(localhost:3306)/test_db?charset=utf8\u0026amp;parseTime=true\u0026#34;) // 随便写个数据库信息，假装是正确的 if err != nil { log.Printf(\u0026#34;init mysql failed: %+v \u0026#34;, err) } } type Resp struct { Code int `json:\u0026#34;code\u0026#34;` Msg string `json:\u0026#34;msg\u0026#34;` } type SqlInfo struct { Id int64 `json:\u0026#34;id\u0026#34; xorm:\u0026#34;pk bigint(20)\u0026#34;` Created time.Time `json:\u0026#34;created\u0026#34; xorm:\u0026#34;created\u0026#34;` Info string `json:\u0026#34;info\u0026#34;` } func (sql *SqlInfo) TableName() string { return \u0026#34;sql_info\u0026#34; } func Mysql(c *gin.Context) { info := c.Query(\u0026#34;info\u0026#34;) if info == \u0026#34;\u0026#34; { now := time.Now().Format(\u0026#34;2008-01-02 15:04:05\u0026#34;) info = now } sqlInfo := SqlInfo{ Info: info, } affected, err := sqlE.Insert(\u0026amp;sqlInfo) if err != nil { log.Printf(\u0026#34;insert db with error: %+v \u0026#34;, err) } else { log.Printf(\u0026#34;affect column nums: %d \u0026#34;, affected) } c.JSON(http.StatusOK, \u0026amp;Resp{Code: 0, Msg: \u0026#34;mysql req over\u0026#34;}) return } func main() { r := gin.Default() srv := \u0026amp;http.Server{ Addr: \u0026#34;0.0.0.0:9981\u0026#34;, } log.Println(\u0026#34;server start at: 0.0.0.0:9981\u0026#34;) r.GET(\u0026#34;/sql\u0026#34;, Mysql) srv.Handler = r err := srv.ListenAndServe() if err != nil { log.Fatal(\u0026#34;error with start listener\u0026#34;) } } # bpftrace 代码 直接上代码了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #! /bin/bpftrace /* 保存在 blog/blog.bt 里 这里使用的 uprobe 函数为 go-sql-driver 里的内容。源代码在： https://github.com/go-sql-driver/mysql/blob/master/connector.go#L23 定义为： func (c *connector) Connect(ctx context.Context) (driver.Conn, error) {...} */ uprobe:./blog:\u0026#34;github.com/go-sql-driver/mysql.(*connector).Connect\u0026#34; { printf(\u0026#34;Connect \u0026#34;); $cfg_addr = *(uint64*)sarg0; // 获取 c.cfg 的地址 $user_addr = *(uint64*)($cfg_addr); // 获取 c.cfg.User $user_len = *(uint64*)($cfg_addr+8); // 获取 len(c.cfg.User) //$pwd_addr = *(uint64*)($cfg_addr+16); // 请注意这里注释掉的内容 //$pwd_len = *(uint64*)($cfg_addr+24); $addr_addr = *(uint64*)($cfg_addr+48); $addr_len = *(uint64*)($cfg_addr+56); $db_addr = *(uint64*)($cfg_addr+64); $db_len = *(uint64*)($cfg_addr+72); printf(\u0026#34;user: %s \u0026#34;, str($user_addr, $user_len)); //printf(\u0026#34;pwd: %s \u0026#34;, str($pwd_addr, $pwd_len)); printf(\u0026#34;addr: %s \u0026#34;, str($addr_addr, $addr_len)); printf(\u0026#34;db: %s \u0026#34;, str($db_addr, $db_len)); } 而后启动应用程序blog，启动监听程序sudo bpftrace ./blog.bt，请求blog的/sql接口以触发blog对sql的请求。整个过程对blog程序来说没有任何的不平凡之处，但是我们已经获取了采集结果。 附上执行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 $ ./blog init from main [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \u0026#34;debug\u0026#34; mode. Switch to \u0026#34;release\u0026#34; mode in production. - using env:\texport GIN_MODE=release - using code:\tgin.SetMode(gin.ReleaseMode) 2022/10/21 20:15:38 server start at: 0.0.0.0:9981 [GIN-debug] GET /sql --\u0026gt; main.Mysql (3 handlers) 2022/10/21 20:18:52 insert db with error: dial tcp 127.0.0.1:3306: connect: connection refused [GIN] 2022/10/21 - 20:18:52 | 200 | 3.679499ms | 127.0.0.1 | GET \u0026#34;/sql\u0026#34; 此时，在采集侧：\n1 2 3 4 5 6 $ sudo ./blog.bt Attaching 1 probe... Connect user: test addr: localhost:3306 db: test_db 我们已经获取了需要的信息。\n# 对采集代码的一些说明 bpftrace语法部分，参见github-bpftrace-reference_guid。里面有ebpf的一些简单介绍以及bpftrace的使用说明。代码里的主要逻辑，则需要参见golang的语法来理解。部分简述如下：\n类里的方法，实际调用的时候，第一个参数为对象的地址； go-1.16 及之前的版本，参数存储在栈上； 剩下的内容就比较好理解了：ebpf提供的核心功能包括按需读取用户空间内的数据。结合golang-常见类型字节数可以比较快的推导出我们需要的信息在地址内的偏移量。同时，在bpftrace无侵入遍历golang链表曾经提到过，如果目标对象比较大，无法在ebpf代码里完整定义该对象（内核限制单个ebpf的hook点程序的栈空间大小在512B），我们访问对象里的成员时，使用的方法就是偏移量访问。\n# ebpf 与应用安全的一些思考 最后提一点自己的思考。\n请回到bpftrace代码里，里面的pasword信息获取的操作被注释掉了。其实我们去掉注释，仍然能够按照预期获取结果。这就意味着，如果我们拥有机器上的权限，并且机器满足我们的采集需求，应用里的核心信息（这里是数据库的密码）将被简单的获取。无论数据库密码如何存储：配置文件、源代码、通过网络配置下发等。只要有涉及数据库访问的用户态函数，有涉及数据库密码传递的内容，这些信息存在被获取的风险，只要采集人拥有root权限。\n这里引出另外一个问题：如果一个用户拥有机器上的管理员权限，TA是否应该拥有机器上所有进程信息的准入权。这里的进程信息，显然是包括机器上容器内的进程信息的，无论是公有云或者私有云。\n","date":"2022-10-21T19:48:00Z","permalink":"http://localhost:1313/p/ebpf%E9%87%87%E9%9B%86mysql%E8%AF%B7%E6%B1%82%E4%BF%A1%E6%81%AF%E5%8F%8Aebpf%E5%AF%B9%E5%BA%94%E7%94%A8%E5%AE%89%E5%85%A8%E7%9A%84%E6%80%9D%E8%80%83/","title":"ebpf采集mysql请求信息及ebpf对应用安全的思考"},{"content":" x86_64 架构下，寄存器传参时，仅 arg1-arg6 会通过寄存器进行，arg7+ 的参数，将会放到栈上进行。\n# 验证代码 1 2 3 4 # 环境 ├── arg.bt ├── arg_test └── hello.c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // hello.c, gcc -o arg_test hello.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; void print_arg(int arg1, int arg2, int arg3, int arg4, int arg5, int arg6, int arg7, int arg8){ printf(\u0026#34;%d, %d, %d, %d, %d, %d, %d, %d \u0026#34;, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8); return; } int main(){ print_arg(1,2,3,4,5,6,7,8); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // arg.bt #!/bin/bpftrace uprobe:./arg_test:print_arg { printf(\u0026#34;== enter print_arg \u0026#34;); printf(\u0026#34;arg1: %d \u0026#34;, arg0); printf(\u0026#34;arg2: %d \u0026#34;, arg1); printf(\u0026#34;arg3: %d \u0026#34;, arg2); printf(\u0026#34;arg4: %d \u0026#34;, arg3); printf(\u0026#34;arg5: %d \u0026#34;, arg4); printf(\u0026#34;arg6: %d \u0026#34;, arg5); printf(\u0026#34;arg7: %d \u0026#34;, sarg0); printf(\u0026#34;arg8: %d \u0026#34;, sarg1); } # 执行结果 1 2 3 4 5 6 7 8 9 10 11 12 13 sudo bpftrace arg.bt Attaching 1 probe... == enter print_arg arg1: 1 arg2: 2 arg3: 3 arg4: 4 arg5: 5 arg6: 6 arg7: 7 arg8: 8 ./arg_test # 参照 X86 64 Register and Instruction Quick Start\n","date":"2022-08-31T19:51:00Z","permalink":"http://localhost:1313/p/x86_64-%E5%AF%84%E5%AD%98%E5%99%A8%E4%BC%A0%E5%8F%82%E6%96%B9%E5%BC%8F/","title":"x86_64 寄存器传参方式"},{"content":" bpftrace 基于 bcc 进行开发的工具，语法简洁、功能强大。用其分析Linux 环境下的程序会很方便。本文构造了一个入参为链表头节点的函数使用场景，通过使用bpftrace无侵入遍历链表成员的方式，介绍bpftrace attach uprobe 的使用。更多使用说明见:bpftrace官网使用文档\n# 执行结果 下面直接给出执行结果。可以看到，通过bpftrace脚本输出的结果与代码中实际遍历的结果相同。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 sudo ./handle.bt // 先启动监听 Attaching 1 probe... // 启动后停止在这里 === enter main.handle. // 目标程序执行后输出 name: Alice age : 10 name: Bob age : 11 name: Claire age : 12 === total node: 3 ./demo // 再执行目标程序 cur name: Alice, cur aget: 10 cur name: Bob, cur aget: 11 cur name: Claire, cur aget: 12 # 示例说明 系统环境如下：\n1 2 3 Linux 4.18.0-193.6.3.el8_2.v1.2.x86_64 bpftrace v0.14.0-72-g6761-dirty go version go1.16.15 linux/amd64 示例环境目录：\n1 2 3 4 5 . ├── demo ├── go.mod ├── handle.bt └── main.go 其中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // main.go package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; ) type Student struct { Name string Age int64 // Comment [600]Byte 这样会使得这个问题变得很麻烦，hhh Next *Student } // 添加如下配置以防止函数被编译优化掉 //go:noinline func handle(ctx context.Context, student *Student) { for cur := student; cur != nil; cur = cur.Next { fmt.Printf(\u0026#34;cur name: %s, cur aget: %d \u0026#34;, cur.Name, cur.Age) } return } func main() { first := \u0026amp;Student{ Name: \u0026#34;Alice\u0026#34;, Age: 10, Next: \u0026amp;Student{ Name: \u0026#34;Bob\u0026#34;, Age: 11, Next: \u0026amp;Student{ Name: \u0026#34;Claire\u0026#34;, Age: 13, Next: nil, }}} handle(context.Background(), first) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // handle.bt #!/bin/bpftrace // 当目标结构体较小时(使得整体栈开销 \u0026lt; 512Byte)，可以直接构造使用 struct student{ u64 name_ptr; u64 name_length; long age; struct student *next; }; uprobe:./demo:\u0026#34;main.handle\u0026#34; { printf(\u0026#34;=== enter main.handle. \u0026#34;); $cur = (struct student *)sarg2; if ($cur == 0){ printf(\u0026#34;input param is nil. \u0026#34;); return; } $node_count = 1; unroll(10){ // 这里定义的最大节点数量为10 printf(\u0026#34;name: %s \u0026#34;, str($cur-\u0026gt;name_ptr, $cur-\u0026gt;name_length)); printf(\u0026#34;age : %d \u0026#34;, $cur-\u0026gt;age); $cur = $cur-\u0026gt;next; if ($cur == 0){ printf(\u0026#34;=== total node: %d \u0026#34;, $node_count); return; } $node_count += 1; } printf(\u0026#34;==== meet max \u0026#34;); return; } 在编译完成main.go后，通过sudo bpftrace -l \u0026quot;uprobe:./demo:*\u0026quot; \u0026gt; uprobe.info的方式，可以获取demo中所有可以attach的uprobe信息。这里说明下取student*指针值时，为什么取sarg3。bpftrace中对内存传参的参数支持是sarg0, sarg1, sarg2...，且每个参数实际只对应8Byte大小的空间。对于func handle(ctx context.Context, student *Student)函数来说，由于context.Context实际占用2*8Byte的空间（见golang常见类型字节数)，因此需要使用sarg2来取student的值，而非直觉上的sarg1。\n整个过程比较简单、明了。只要拥有root权限，基本上可以对系统内的任何进程进行详细的分析。\n","date":"2022-07-22T21:48:00Z","permalink":"http://localhost:1313/p/bpftrace-%E6%97%A0%E4%BE%B5%E5%85%A5%E9%81%8D%E5%8E%86golang%E9%93%BE%E8%A1%A8/","title":"bpftrace 无侵入遍历golang链表"},{"content":" liam同学在让 Vim 在保存文件时自动格式化代码一文中展示了保存时自动化格式代码的vim配置。作为emacs用户，自然有自己的解决方案。以下呈现。\n# 配置 emacs进行c/c++的开发，离不开支持代码自动补全、库函数联想等功能，所以本文顺带把lsp配置也一并带上了，不同于emacs-若干语言 lsp 配置备注里的eglot，这里使用的是ccls。直接上配置吧，比较简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ;; 使用国内 elpa 源来加速插件安装 (defun w-install(pkg) ;; would be a wrapper for package-install (require \u0026#39;package) (setq package-archives \u0026#39;((\u0026#34;gnu\u0026#34; . \u0026#34;http://mirrors.tuna.tsinghua.edu.cn/elpa/gnu/\u0026#34;) (\u0026#34;melpa\u0026#34; . \u0026#34;http://mirrors.tuna.tsinghua.edu.cn/elpa/melpa/\u0026#34;))) (package-initialize) (package-refresh-contents) (unless (package-installed-p pkg) (package-install pkg))) ;; 辅助判断插件安装通用函数 (defun ensure-package-installed (\u0026amp;rest packages) \u0026#34;Assure every package was installed, ask for installation if it\u0026#39;s not. a list of installed packages or nil for every skipped package.\u0026#34; (mapcar (lambda (package) (if (package-installed-p package) nil (if (y-or-n-p (format \u0026#34;Package %s is missing. Install it?\u0026#34; package)) (w-install package) package))) packages)) ;; clang-format 在文件保存时格式化代码 (ensure-package-installed \u0026#39;clang-format) (defun clang-format-on-save-hook() \u0026#34;Create a buffer local save hook.\u0026#34; (add-hook \u0026#39;before-save-hook (lambda () (when (locate-dominating-file \u0026#34;.\u0026#34; \u0026#34;.clang-format\u0026#34;) (clang-format-buffer)) ;; Continue to save nil) nil ;; Buffer local hook. t)) ;; Run this hook for c-mode-hook and c++-mode-hook (add-hook \u0026#39;c-mode-hook (lambda () (clang-format-on-save-hook))) (add-hook \u0026#39;c++-mode-hook (lambda () (clang-format-on-save-hook))) ;; create default clang-format file ;; https://releases.llvm.org/3.6.2/tools/docs/ClangFormatStyleOptions.html ;; clang-format -style=llvm -dump-config \u0026gt; .clang-format ;; 另外，这里列出使用的 lsp-language-server 配置。 ;; 服务端使用 ccls，客户端则使用 ccls.el。同时将 ccls 作为 c-mode 的hook运行 ;; https://github.com/MaskRay/ccls/wiki/Build ;; set up lsp-mode for c/c++ (ensure-package-installed \u0026#39;ccls) (use-package ccls :hook ((c-mode c++-mode objc-mode cuda-mode) . (lambda() (require \u0026#39;ccls) (lsp)))) 代码格式部分则主要由.clang-format文件控制。其配置方法可以参见官网：ClangFormat。\n","date":"2022-07-15T20:34:00Z","permalink":"http://localhost:1313/p/%E8%AE%A9emacs%E5%9C%A8%E4%BF%9D%E5%AD%98%E6%96%87%E4%BB%B6%E6%97%B6%E8%87%AA%E5%8A%A8%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81/","title":"让emacs在保存文件时自动格式化代码"},{"content":" ebpf 分析golang程序时，离不开对参数大小的判断。这里列出来一些基本类型的大小，并通过汇编对应验证函数的方式来肯定判断结果。\n# 信息 这里列出基本类型及其作为参数传递时，占用的空间大小如下表。\n类型 长度 说明 指针 8B 64位机为 8Byte, 32位机位4Byte context 16B interface 类型。其中，前8B是类型信息，后8B是对象的指针信息 interface 16B 2 个指针，详见draveness-go-interface，或者 runtime/runtime2.go iface/eface 定义 int64 8B - int 8B 64位机为 8Byte, 32位机位4Byte string 16B 8B 地址 + 8B string长度 slice 24B 8B地址 + 8B slice 成员数量 + 8B slice capability func 8B func 作为函数参数时，传递的是 func 的地址 需要注意的是，作为函数参数传递时，golang会对参数按照 8B 进行对齐。\n# 验证示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // main.go package main import \u0026#34;context\u0026#34; type A struct { p1 int64 a byte b int64 } type FuncPt func(A) type InterA interface { Echo(A) } func CheckPointer(a *A) {} func CheckCtx(ctx context.Context) {} func CheckInterface(inter InterA) {} func CheckString(s string) {} func CheckSlice(arr []string) {} func CheckFunc(fn FuncPt) {} func CheckAlign(a byte) {} func CheckStruct(a A) {} func main() {} 对该代码进行汇编:\ngo build -gcflags \u0026quot;-S\u0026quot; . \u0026gt; main.s 可以得到汇编后的结果，并验证上述类型所占大小的描述。这里推荐下曹大的plan9 汇编入门，里面对golang汇编后的plan9进行了介绍。由其介绍可知，汇编后函数签名后的$x-y指代的是该函数的栈空间以及参数大小（入参+返回参数，go-1.17及之后的版本未验证）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 # command-line-arguments \u0026#34;\u0026#34;.CheckPointer STEXT size=16 args=0x8 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:17)\tTEXT\t\u0026#34;\u0026#34;.CheckPointer(SB), LEAF|NOFRAME|ABIInternal, $0-8 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:17)\tFUNCDATA\tZR, gclocals·2a5305abe05176240e61b8620e19a815(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:17)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:17)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckCtx STEXT size=16 args=0x10 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:18)\tTEXT\t\u0026#34;\u0026#34;.CheckCtx(SB), LEAF|NOFRAME|ABIInternal, $0-16 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:18)\tFUNCDATA\tZR, gclocals·f207267fbf96a0178e8758c6e3e0ce28(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:18)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:18)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckInterface STEXT size=16 args=0x10 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:19)\tTEXT\t\u0026#34;\u0026#34;.CheckInterface(SB), LEAF|NOFRAME|ABIInternal, $0-16 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:19)\tFUNCDATA\tZR, gclocals·f207267fbf96a0178e8758c6e3e0ce28(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:19)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:19)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckString STEXT size=16 args=0x10 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:20)\tTEXT\t\u0026#34;\u0026#34;.CheckString(SB), LEAF|NOFRAME|ABIInternal, $0-16 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:20)\tFUNCDATA\tZR, gclocals·2a5305abe05176240e61b8620e19a815(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:20)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:20)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckSlice STEXT size=16 args=0x18 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:21)\tTEXT\t\u0026#34;\u0026#34;.CheckSlice(SB), LEAF|NOFRAME|ABIInternal, $0-24 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:21)\tFUNCDATA\tZR, gclocals·2a5305abe05176240e61b8620e19a815(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:21)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:21)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckFunc STEXT size=16 args=0x8 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:22)\tTEXT\t\u0026#34;\u0026#34;.CheckFunc(SB), LEAF|NOFRAME|ABIInternal, $0-8 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:22)\tFUNCDATA\tZR, gclocals·2a5305abe05176240e61b8620e19a815(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:22)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:22)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckAlign STEXT size=16 args=0x8 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:23)\tTEXT\t\u0026#34;\u0026#34;.CheckAlign(SB), LEAF|NOFRAME|ABIInternal, $0-8 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:23)\tFUNCDATA\tZR, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:23)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:23)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckStruct STEXT size=16 args=0x18 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:24)\tTEXT\t\u0026#34;\u0026#34;.CheckStruct(SB), LEAF|NOFRAME|ABIInternal, $0-24 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:24)\tFUNCDATA\tZR, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:24)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:24)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.main STEXT size=16 args=0x0 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:26)\tTEXT\t\u0026#34;\u0026#34;.main(SB), LEAF|NOFRAME|ABIInternal, $0-0 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:26)\tFUNCDATA\tZR, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:26)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:28)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. ","date":"2022-06-06T14:36:00Z","permalink":"http://localhost:1313/p/golang-%E5%B8%B8%E8%A7%81%E7%B1%BB%E5%9E%8B%E5%AD%97%E8%8A%82%E6%95%B0/","title":"golang 常见类型字节数"},{"content":" 一直都比较赞赏protocol buffer。由于其表现性强、压缩比高，可以把很多结构都写到proto文件中，同时添加很多的注释。当需要进行进行数据存储时，使用proto序列化结果替代json，可以省去很多的冗余字段。本篇找了一些golang中protocol buffer的使用示例，以及protocol对象与json对象互相转换的示例。\n# 依赖环境 这部分主要参照官网教程来：\nprotoc 安装：\ngithub-protobuf-releases 下载对应平台的 protoc 编译器即可； protoc-gen-go 安装：\ngo install google.golang.org/protobuf/cmd/protoc-gen-go@latest 需要能够安装对应语言的插件，proto 文件才被翻译为对应语言可调用的模块； # 示例代码 比较推荐将proto文件单独放入一个仓库。proto一般定义的是需要服务/模块间共享的，所以单独放在一个仓库里便于调用及约定的维护。\n1 2 3 4 . ├── main.go └── proto └── user.proto 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 // main.go package main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;proto/message\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/gogo/protobuf/jsonpb\u0026#34; jsoniter \u0026#34;github.com/json-iterator/go\u0026#34; \u0026#34;google.golang.org/protobuf/proto\u0026#34; ) func main() { msg := message.UserInfo{UserList: []*message.UserInfo_User{{Username: \u0026#34;test\u0026#34;}}} msg.UserList = append(msg.UserList, \u0026amp;message.UserInfo_User{Username: \u0026#34;test1\u0026#34;}) // go message 可以直接序列化为 json byte byt, err := jsoniter.Marshal(\u0026amp;msg) if err != nil { log.Fatal(\u0026#34;cannot parse to json\u0026#34;) } fmt.Println(\u0026#34;json result: \u0026#34;, string(byt)) // 可以将 json 对象反序列化为 go message 对象 msg1 := \u0026amp;message.UserInfo{} err = jsonpb.Unmarshal(bytes.NewReader(byt), msg1) if err != nil { log.Fatal(\u0026#34;parse failed, \u0026#34;, err) } fmt.Printf(\u0026#34;parsed: %+v \u0026#34;, msg1) // protobuf 本身的字符串表征 msg1Str := msg1.String() fmt.Println(\u0026#34;msg1 string, \u0026#34;, msg1Str) // protobuf 序列化 out, err := proto.Marshal(msg1) fmt.Println(\u0026#34;msg1 marshal result is, \u0026#34;, string(out)) msg2 := message.UserInfo{} // 将序列化后的结果，反序列化为 message 对象 proto.Unmarshal(out, \u0026amp;msg2) fmt.Printf(\u0026#34;unmarshal result msg2 is: %+v \u0026#34;, \u0026amp;msg2) engine := gin.Default() engine.GET(\u0026#34;check\u0026#34;, func(c *gin.Context) { // message 对象可以直接用来作为接口的返回值 c.JSON(http.StatusOK, \u0026amp;msg1) }) srv := \u0026amp;http.Server{} srv.Addr = \u0026#34;0.0.0.0:9988\u0026#34; srv.Handler = engine srv.ListenAndServe() } // proto/user.proto syntax = \u0026#34;proto3\u0026#34;; package user_info; // 对于 golang 的使用说，这里的 go_package 是必须的。表述的是编译后的模块名 option go_package = \u0026#34;./message\u0026#34;; message UserInfo{ message User{ string username = 1; uint32 age = 2; string graduate = 3; } repeated User user_list = 1; } 进行编译:protoc -I./proto user.proto --go_out=./，\n1 2 3 4 5 6 7 8 9 10 . ├── go.mod ├── go.sum ├── main.go ├── message │ └── user.pb.go └── proto └── user.proto 2 directories, 5 files 执行 go run main.go。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 go run main.go json result: {\u0026#34;user_list\u0026#34;:[{\u0026#34;username\u0026#34;:\u0026#34;test\u0026#34;},{\u0026#34;username\u0026#34;:\u0026#34;test1\u0026#34;}]} parsed: user_list:{username:\u0026#34;test\u0026#34;} user_list:{username:\u0026#34;test1\u0026#34;} msg1 string, user_list:{username:\u0026#34;test\u0026#34;} user_list:{username:\u0026#34;test1\u0026#34;} msg1 marshal result is, test test1 unmarshal result msg2 is: user_list:{username:\u0026#34;test\u0026#34;} user_list:{username:\u0026#34;test1\u0026#34;} [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \u0026#34;debug\u0026#34; mode. Switch to \u0026#34;release\u0026#34; mode in production. - using env:\texport GIN_MODE=release - using code:\tgin.SetMode(gin.ReleaseMode) [GIN-debug] GET /check_must --\u0026gt; main.main.func1 (3 handlers) # 总结 protocol buffer 在大多数场景下，都能兼容json对象的使用场景。其劣势为序列化相关操作时额外的性能开销。对于与外部进行交互、不会进行频繁序列化、反序列化的数据，可以考虑优先使用protocol buffer。\n","date":"2022-05-19T17:53:00Z","permalink":"http://localhost:1313/p/golang-proto3-%E4%BD%BF%E7%94%A8/","title":"golang proto3 使用"},{"content":" goroutine 开销为 2KB（最少），对比线程 2MB 的开销，有明显的优势。当goroutine 栈资源不足时，runtime 会将整个 goroutine stack 拷贝、重新分配空间。\nInstead of using a thread for every goroutine, Go multiplexes goroutines across multiple threads (\u0026ldquo;M:N scheduling\u0026rdquo;). So instead of each thread having a default 2MB stack, each goroutine has a tiny 2KB stack that\u0026rsquo;s managed by the runtime instead of the operating system. When the program needs to grow the stack for a goroutine and there\u0026rsquo;s not enough room, the runtime copies the entire goroutine\u0026rsquo;s stack to another place in memory where it has enough room to expand.\nChallenges of BPF Tracing Go\n","date":"2022-04-19T14:33:00Z","permalink":"http://localhost:1313/p/challenges-of-bpf-tracing-go/","title":"challenges of bpf tracing go"},{"content":" 工作需要（抛弃了kubectl搞一套环境的方法），需要在centos8上构建一套docker镜像并运行golang程序。这里记录下docker安装及golang程序打包镜像的过程。\n# 安装docker 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 sudo yum install -y yum-utils sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install docker-ce docker-ce-cli containerd.io \\# 这里报了一个错 \\# (try to add \u0026#39;--allowerasing\u0026#39; to command line to replace conflicting packages or \u0026#39;--skip-broken\u0026#39; to skip uninstallable packages or \u0026#39;--nobest\u0026#39; to use not only best candidate packages) \\# 重新执行 sudo yum install docker-ce docker-ce-cli containerd.io --allowerasing \\# 启动 docker sudo systemctl start docker \\# 测试 sudo docker run hello-world \\# Hello from Docker! \\# This message shows that your installation appears to be working correctly. # 构建golang服务镜像 先看下工作目录的结构：\n1 2 3 4 5 6 . ├── Dockerfile ├── gin-srv ├── go.mod ├── go.sum └── main.go 简单写一个golang的程序:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import \u0026#34;time\u0026#34; import \u0026#34;github.com/gin-gonic/gin\u0026#34; type Resp struct{ Errno int `json:\u0026#34;errno\u0026#34;` Data map[string]int64 `json:\u0026#34;data\u0026#34;` } func main(){ r := gin.Default() r.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context){ resp := \u0026amp;Resp{Errno:0, Data: map[string]int64{ \u0026#34;now\u0026#34;: time.Now().Unix(), }} c.JSON(200, \u0026amp;resp) }) r.Run(\u0026#34;0.0.0.0:8080\u0026#34;) } 构建一个Dockerfile，以centos作为base以便能够正常登陆容器进行调试：\n1 2 3 4 FROM centos:8 ADD . ./ EXPOSE 8080 ENTRYPOINT [\u0026#34;./gin-srv\u0026#34;] 启动容器：\n1 2 3 4 # 构建镜像 sudo docker build -t gin_docker . # 启动镜像 sudo docker run --name gin_docker -p 8080:8080 -d gin_docker 访问容器中的服务：\n1 2 $ curl localhost:8080/ping {\u0026#34;errno\u0026#34;:0,\u0026#34;data\u0026#34;:{\u0026#34;now\u0026#34;:1646381863}} 容器起来了。可以继续后面的性能评估及agent启动工作了。\n# 参考文献 Install Docker Engine on CentOS Golang应用打包docker镜像并运行\n","date":"2022-03-04T15:00:00Z","permalink":"http://localhost:1313/p/centos-%E5%AE%89%E8%A3%85docker%E5%B9%B6%E6%9E%84%E5%BB%BAgolang%E9%95%9C%E5%83%8F/","title":"centos 安装docker并构建golang镜像"},{"content":" 最近在做 eBPF 的技术调研。看到很多对 eBPF 的介绍。为了加强对内容的理解，笔者选择了其中的一篇尝试翻译。本着便于笔者自己理解的角度，很多内容加入了自己的一些理解，因此并不能算是严格意义上的“翻译”。文章涉及了 eBPF 的介绍、优势、不足，算是一篇 eBPF 的很好的介绍。现在把它贴上来，算是纪念自己的第一篇“译文”。\n原文地址：What Is eBPF and Why Does It Matter for Observability?\n# eBPF 及其对可观测领域的影响 当实现安全性、网络化以及可观测的特性时，在linux 内核中工作是非常理想化的。然而，它并非缺少挑战。无论是变更内核源码或者新增 内核模块，开发者通常会面对复杂的架构及难以调试的抽象层。扩展的 BPF(eBPF) 能够解决这两个问题。 伯克利包过滤器扩展技术(Extended Berkeley Packet Filter, eBPF) 是一种内核技术(自 Linux 4.x 引入)允许程序在无需变更内核源码或添加 额外的内核模块。你可以认为它是一种内核内置的轻量级的、沙箱式的虚拟机，编程人员可以通过 BPF 字节码来最大化的利用内核的资源。 使用 eBPF 消除了变更内核源码并且简化了软件利用现有层级的能力。因此，它是一种强大的技术，有可能从根本上改变网络、可观测性及安全 服务的工作方式。 这是一篇 eBPF 是什么、怎么工作以及什么时候考虑利用这种技术的文章。\n# eBPF 是怎么工作的 eBPF 是事件驱动的，并且绑定到特定的代码路径。代码路径包含特殊的触发点(triggers)，或者称为钩子(hooks)。触发时，会执行所有绑定 到上面的 eBPF 程序。一些钩子的示例包括网络事件、系统调用、函数执行以及内核跟踪点。 当被触发时，代码会首先被编译成 BPF 字节码。然后，字节码会在执行前被校验，以确保不包含任何循环。校验会确保程序不会有意或无意的 破坏内核。 当代码在一个钩子上执行后，会产生辅助调用(helper calls)。这些辅助调用是一些eBPF访问内存的函数。辅助调用需要内核提前定义，目前 调用的函数列表仍在持续增长中。 eBPF 最开始的时候是作为一种增加过滤网络包时可观测性及安全性的工具。然而，时至今日，它已经成为一种用来让用户态的程序更加安全、 便捷、表现更好的工具。\n# eBPF 的优势 eBPF 通常被用来进行追踪用户态的进程，这里列出一些它的优势：\n高速、高效。eBPF 可以将网络包从内核态移动至用户态。而且，eBPF支持一个运行时（just-in-time, JIT）的编译器。在字节码被编译出来 后即可被执行，毋需基于平台重新解释； 低侵入性。当被用作调试器时，eBPF 无需停止服务便可以观测它的状态； 安全性。程序会被高效地加载到沙盒中，意味着内核源码被保护起来不会发生变更。执行时的校验能够确保资源不会由于程序陷入死循环而 阻塞； 便捷。相对于构建并维护内核的模块，编写内核的函数钩子要简单的多； 一致追踪。eBPF能够带来一个单一、有效、可用性强的追踪程序的框架。这增加了可视化及安全性； 可编程性。使用 eBPF 在不引入额外架构层的情况下，丰富了系统的特性。而且，由于代码是直接运行在内核里的，在不同的eBPF事件间存储 数据，而非像其他追踪程序一样转存出来，是可行的； 表达丰富。eBPF极具表达能力，这通常只能在其他高级语言中能够看到； # eBPF 最佳实践 考虑到 eBPF 仍然是一项新的技术，很多使用仍待进一步开发。关于 eBPF 的最佳实践仍在随着这种技术的改进而不断增加。虽然没有已定义的 最佳实践存在，仍然有一些措施可以采纳以确保程序高效、便捷。 如果你在生态系统中使用了 eBPF，我们建议你：\n使用 LLVM Clang 来将 C 代码编辑为 eBPF 字节码。当 eBPF 刚出现时，编码及汇编均需要手动操作。然后， 开发者使用内核的汇编器生成字节码。幸运的是，现在已经不再需要这样操作了。Clang 为 C 语言编写的 eBPF 提供了前端及工具； 使用 BCC 工具集来编写 BPF 程序。BPF 编译器集合（BPF Compiler Collection, BCC） 是一个帮助 构建高效内核追踪及管理程序的工具集。针对性能分析及网络拥塞控制相关的任务尤其合适。 # eBPF 的不足 尽管很强大，eBPF 并不是适合所有项目/生态系统的万金油。eBPF 有一些显而易见的不足，这些不足会让它在一些场景下不适用。一些开发者 可能会发现在如下场景下 eBPF 不适用：\neBPF 限制在 Linux 系统及较新的内核版本。eBPF 是在 Linux 内核上发展并且完全聚焦在其上。这导致它相对于其他工具而言移植性不强。 此外，你需要一个相当新的内核。如果运行在任何早于 v4.13 的内核上，你将不能使用它。 沙盒编程是存在限制的。eBPF 通过限制应用程序可以接触的资源来提升安全性。然而，由于限制了操作系统的访问，功能上也被限制了。 # eBPF 适用哪些领域 eBPF 云原生应用 领域正迅速的获得关注。目前，eBPF 在以下两个场景中获得普遍 使用：\n需要使用内核追踪实现可观测性。在这种场景下，eBPF 表现得更加快速、高效。这里不涉及到上下文切换，并且 eBPF 程序是事件驱动的所以毋需一个特定的触发器\u0026ndash;所以你不会存在精度上的问题。 传统的安全监控不起作用。eBPF 在分布式及容器化的环境中有巨大的应用潜力，包括Kubernets。 在这些环境中，eBPF 可以缩小可见性的差距，因为他可以提供HTTP 可见性追踪。 在如下安全度量领域，你也可以发现 eBPF 被使用： 防火墙； 设备驱动； 网络性能监控； # New Relic and eBPF Pixie (acquired by New Relic), is an open source, kubernetes-native-in-cluster observability platform that provides instant visibility into Kubernetes workloads with no manual instrumentation. eBPF provides most of the magic behind the Pixie platform. As described earlier, eBPF allows you to run restricted code when an event is triggered. This event could be a function call either in kernel space(kprobes) or userspace(uprobes). Pixie uses both uprobes and kprobes to enable observability across services and applications.\nPixie automatically harvests telemetry data by leveraging eBPF, and its edge-machine intelligence connects this data with Kubernetes metadata to provide visibility while maintaining data locality. This visibility complements New Relic’s powerful Kubernetes observability solution. And starting in late May, you\u0026rsquo;ll be able to send Pixie-generated telemetry data to New Relic One, gaining scalable retention, powerful visualizations, advanced correlation, and intelligent alerting capabilities.\n# eBPF 正在可见的创造效率 eBPF 是一个提升 Linux 内核可观测、网络及安全性的新技术。它毋需变更内核源码或者添加新的模块，所以你可以在不引入复杂性的前提下， 提升系统的基础建设。 我们简要的谈到 eBPF 是什么、如何工作以及为什么它在分布式环境中如此有用。通过监控内核层，很多云上的可观测问题被解决了。你可以 享受数据中更深层次的可见性、更丰富的上下文以及更准确的信息。\n","date":"2022-03-02T16:34:00Z","permalink":"http://localhost:1313/p/ebpf%E5%8F%8A%E5%85%B6%E5%AF%B9%E5%8F%AF%E8%A7%82%E6%B5%8B%E7%9A%84%E6%84%8F%E4%B9%89%E8%AF%91%E6%96%87/","title":"eBPF及其对可观测的意义【译文】"},{"content":" 工作原因，需要安装一个 local-k8s。中间碰了很多坑，做个记录。 环境：Linux test 4.18.0-193.el8.x86_64\n# kubectl kubectl安装说明，可以直接使用包管理器安装，如：\n1 2 3 4 5 6 7 8 9 10 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF sudo yum install -y kubectl # minicube minicube安装说明 也比较方便，官网里有不同系统的安装方式。笔者使用curl的安装：\n1 2 curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube # start cluster # 安装 kvm How to Install KVM on CentOS 8\n1 2 3 4 5 # check cat /proc/cpuinfo | egrep \u0026#34;vmx|svm\u0026#34; # install sudo yum install @virt # start minikube start --driver=\u0026lt;kvm2|hyperkit\u0026gt; --cni=flannel --cpus=4 --memory=8000 -p=\u0026lt;cluster-name\u0026gt;，其中，笔者使用的centos系统使用--driver=kvm2选项。执行时存在诸多问题：\n# kvm2 错误 参照错误提示来。需要安装libvirt，笔者直接sudo yum install libvirt进行的。\n# not in libvirt group 不确定为什么需要单独搞一个libvirt group，按照issue-5617 的说明，需要将用户添加到libvirt用户组中。笔者直接进行sudo usermod -a -G libvirt ${USERNAME}。\n# virsh 报错 1 2 error: failed to connect to the hypervisor error: authentication failed: access denied by policy 需要在将当前用户添加到libvirt之后，需要配置polkit规则，确保libvirt组中的用户能够访问libvirt。\n1 2 3 4 5 6 7 # 方案参考 https://blog.csdn.net/cunjiu9486/article/details/109074019 # /etc/polkit-1/rules.d/80-libvirt.rules polkit.addRule(function(action, subject){ if (action.id == \u0026#34;org.libvirt.unix.manage\u0026#34; \u0026amp;\u0026amp; subject.local \u0026amp;\u0026amp; subject.active \u0026amp;\u0026amp; subject.isInGroup(\u0026#34;libvirt\u0026#34;)){ return polkit.Result.YES; } }); 添加规则后，还需要重启 polkitd。简单粗暴：\n1 nohup /usr/lib/polkit-1/polkitd -r \u0026gt; /dev/null \u0026amp; # Cannot find suitable emulator for x86_64 通过 sudo systemctl status libvirtd 查看，发现报错是：cannot initialize crypt，继续安装yum install libgcrypt。\n# dnsmasq: unknown user or group: dnsmasq 1 2 groupadd dnsmasq useradd dnsmasq -g dnsmasq # Failed to start host 提示建议删除刚才的cluster，不清楚为啥，提示了就搞起来：\n1 2 3 minikube delete $cluster_name # 再次执行 minikube start --driver=\u0026lt;kvm2|hyperkit\u0026gt; --cni=flannel --cpus=4 --memory=8000 -p=\u0026lt;cluster-name\u0026gt; 这次可以了！\n1 2 * Enabled addons: storage-provisioner, default-storageclass * Done! kubectl is now configured to use \u0026#34;${cluster_name}\u0026#34; cluster and \u0026#34;default\u0026#34; namespace by default ","date":"2022-02-24T17:27:00Z","permalink":"http://localhost:1313/p/centos-%E6%9E%84%E5%BB%BA-local-k8s/","title":"centos 构建 local-k8s"},{"content":"之前办公一直在Windows系统中，诸如流程图、部署图等图表使用的是visio。迁移到Mac上后，visio便不能使用了。转战到sketch 上，用着颇为顺手，无奈试用期到了之后，就无法使用了。评估了下使用需求及产品价格，只能启用。\n目前在使用draw.io 进行日常绘图，开源、跨平台、免费、使用流畅，可以在线使用或者客户端使用。基本满足日常需求。用着还是比较好的。\n","date":"2022-02-16T10:51:00Z","permalink":"http://localhost:1313/p/mac-%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/","title":"Mac 绘图工具推荐"},{"content":" # ELK docker 部署实践 本文主要对 ELK 套件中的 filebeat, logstash, elasticsearch 的安装进行实践，以及简单运行。\n# Elasticsearch 安装 这里参照官网给出的docker-compose.yml文件设置elasticsearch集群。elastisearch支持single-node及multi node cluster两种部署模式。在本文中，实际上两种方式都能达到效果。使用single-node启动的环境，查看集群状态时会出现status:yellow。将docker-compose.yml文件放置在一个单独的目录下，然后创建data01, data02, data03目录。依据实际需要，还可创建plugins目录映射。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 version: \u0026#39;2\u0026#39; services: es01: container_name: es01 image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0 ports: - 9200:9200 - 9300:9300 volumes: - ./data01:/usr/share/elasticsearch/data environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02 - cluster.initial_master_nodes=es01,es02 - bootstrap.memory_lock=true - \u0026#34;ES_JAVA_OPTS=-Xms128m -Xmx128m\u0026#34; ulimits: memlock: soft: -1 hard: -1 networks: - elastic es02: container_name: es02 image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01 - cluster.initial_master_nodes=es01,es02 - bootstrap.memory_lock=true - \u0026#34;ES_JAVA_OPTS=-Xms128m -Xmx128m\u0026#34; volumes: - ./data02:/usr/share/elasticsearch/data ulimits: memlock: soft: -1 hard: -1 networks: - elastic es03: container_name: es03 image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \u0026#34;ES_JAVA_OPTS=-Xms128m -Xmx128m\u0026#34; volumes: - data03:/usr/share/elasticsearch/data ulimits: memlock: soft: -1 hard: -1 networks: - elastic volumes: data01: driver: local data02: driver: local data03: driver: local networks: elastic: driver: bridge external: true 注意这里将集群的网络设置为external，这样后续的logstash才能找到服务节点。此外，由于笔者的机器可用存储较小，因此设置es的存储占用设置为128m。实际使用时，可以按照需求进行调整。 运行docker-compose up -d即可后台启动。启动后，curl -X GET \u0026quot;localhost:9200/_cat/nodes?v=true\u0026amp;pretty\u0026quot; 判断集群状态。\n# Logstash 安装 collect, parse transform logs\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: \u0026#39;2\u0026#39; services: logstash: image: docker.elastic.co/logstash/logstash:7.15.0 container_name: logstash user: root ports: - 5004:5004 volumes: - ./config:/usr/share/logstash/config/ - /etc/localtime:/etc/localtime command: bash -c \u0026#34;cd /usr/share/logstash \u0026amp;\u0026amp; logstash -f config/online.conf\u0026#34; networks: - elastic networks: elastic: driver: bridge external: true 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # ./config/online.conf input { # 这里支持多种 input beats { port =\u0026gt; 5004 codec =\u0026gt; \u0026#34;json\u0026#34; } } filter { # 这里基于 ruby 脚本进行过滤 ruby { path =\u0026gt; \u0026#34;./config/filter.rb\u0026#34; } } output { # 这里将过滤后的结果输出到标准输出及 es 中 stdout { codec =\u0026gt; json } elasticsearch { hosts =\u0026gt; [\u0026#34;es01:9200\u0026#34;] index =\u0026gt; \u0026#34;logstash\u0026#34; #user =\u0026gt; \u0026#34;\u0026#34; #password =\u0026gt; \u0026#34;\u0026#34; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # config/filter.rb # 按照 online.conf 中的配置，logstash 启动后，会读取 filter.rb，并使用 filter 函数作为过滤函数。 require \u0026#34;json\u0026#34; BEGIN{ puts \u0026#34;start event filter\u0026#34; } END{ puts \u0026#34;end event filter\u0026#34; } def filter(event) puts event if event.get(\u0026#34;[errno]\u0026#34;) != 0 return [] end valid_age = 0 event.get(\u0026#34;[data]\u0026#34;).each{ | info | if info[\u0026#34;age\u0026#34;] \u0026lt; 10 valid_age += info[\u0026#34;age\u0026#34;] end } event.set(\u0026#34;[data]\u0026#34;, valid_age) return [event] end logstash 启动后，会监听容器内的 5004 接口（配置于online.conf中），如果有信息传入，则会经过filter.rb中的 filter() 函数对数据进行处理。而后输出到标准输出及 es01容器5004端口的elasticsearch服务。由于elasticsearch及logstash容器使用了相同的网络，因此可以互相感知。\n# filebeat 安装 filebeat 作为轻量级的日志收集器，仅占用很少的资源，即可完成日志的采集，并且转发至配置的logstash进行后续的处理、归档等操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: \u0026#39;2\u0026#39; services: filebeat: image: docker.elastic.co/beats/filebeat:7.16.0 container_name: filebeat user: root environment: - strict.perms=false volumes: - ./filebeat.yml:/usr/share/filebeat/filebeat.yml - ./data:/usr/share/filebat/data networks: - elastic command: bash -c \u0026#34;cd /usr/share/filebeat \u0026amp;\u0026amp; filebeat -e -c ./filebeat.yml\u0026#34; networks: elastic: driver: bridge external: true 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # filebeat.yml filebeat.inputs: - type: log enabled: true paths: - /usr/share/filebeat/input.log filebeat.config: modules: path: ${path.config}/modules.d/*.yml reload.enabled: false filbeat.autodiscover: providers: - type: docker hints.enabled: true output.logstash: hosts: \u0026#34;logstash:5004\u0026#34; 容器启动后，会监听/usr/share/filebeat/input.log文件。当该文件发生变更时，filebeat会读取增量的内容并进行转发。\n# let it run 经过上述步骤，一个简单的日志监听、采集、处理、存档的流程就构建了。为了测试，可以在filebeat容器的/usr/share/filebeat/input.log中写入：\n1 {\u0026#34;errno\u0026#34;: 0,\u0026#34;data\u0026#34;: [{\u0026#34;age\u0026#34;: 9,\u0026#34;name\u0026#34;: \u0026#34;tt\u0026#34;},{\u0026#34;age\u0026#34;: 8,\u0026#34;name\u0026#34;: \u0026#34;gg\u0026#34;}]} 按照logstash:online.conf的逻辑，会向elasticsearch的logstash写入信息。\n# 参考文献 Linux-ELK日志收集 Install Elasticsearch with Docker Logstash介绍 ","date":"2022-01-04T00:06:00Z","permalink":"http://localhost:1313/p/elk-docker-%E5%AE%9E%E8%B7%B5/","title":"ELK-docker 实践"},{"content":" Quic 协议作为应用层的协议，在无线、弱网场景下的移动通信领域有广阔的应用场景。本文简单记录一些 Quic 的知识点，同时附上介绍的详细文章；\n# Quic 协议 Quic协议是应用层（5层网络模型下，由于基于传输层协议，笔者倾向于认为其是应用层协议，但是博文中多次标注其是传输层协议），对标 HTTP 协议，基于 UDP 协议构建。\n# Quic 协议优点 建立连接延时低。相对于 HTTP 协议的至少 3RTT 的建联，Quic 协议可以实现 0RTT 建联； 改进了拥塞控制。将拥塞控制算法的选择交由应用程序控制；同时抛弃了基于 TCP 的 seq 标记，改由严格递增的 package number + offset，优化了拥塞时的重传； 举例，需要传递 N,N+1,N+2 三个包，传递过程中，N 丢失了；TCP的重传会将N,N+1,N+2三个包都重传；Quic 会重传一个 N+3（即package_num+1），但是 offset 记为 0（即stream_offset不变）。这样在另一端将三个包按照 offset 重新进行组织； 基于 Connection 及 Stream 进行多路复用； 消除队头阻塞，更好的支持多路复用，处理多个会话时，不会因为其中一个会话的丢失，导致其他会话结果也重传(TCP消息重传逻辑)； 默认支持加密认证； # 总结 Quic 协议相当于在 UDP 的基础上，在更高层次协议上实现了 TCP 的大部分功能：可靠传输，拥塞控制等，同时对 TCP 的这些功能进行了优化；\n# 参考文献 技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解\n","date":"2021-11-09T21:11:00Z","permalink":"http://localhost:1313/p/quic%E5%8D%8F%E8%AE%AE/","title":"Quic协议"},{"content":" 微软推出的language server protol 确实提升了文本编辑器的使用体验。就 emacs 的使用而言，配合各个语言的 lsp 实现，能够减少配置语言开发环境的难度。这里记录一下使用 emacs 中的 rust, golang, python, c/c++ lsp 配置\n# rust 这里使用 rust-analyzer 作为 rust 的语言服务器，在安装 rust-mode后，通过绑定语言服务器信息，即可在打开由 cargo 创建的工程时，顺利进入 lsp-mode。需要关注的是，在非cargo创建的项目中，笔者的lsp-mode使用体验很差，甚至缺少代码补充、语法提示等功能。可能是rust-analyzer主要是针对cargo项目进行的设置，也可能是笔者设置的问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ;; config for rust-lsp for emacs ;; rls install address: https://github.com/rust-lang-nursery/rls (unless (package-installed-p \u0026#39;rust-mode) (w-install \u0026#39;rust-mode)) (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\.rs\\\u0026#39;\u0026#34; . rust-mode)) (add-hook \u0026#39;rust-mode-hook \u0026#39;lsp) (unless (package-installed-p \u0026#39;rustic) (w-install \u0026#39;rustic)) (unless (package-installed-p \u0026#39;cargo) (w-install \u0026#39;cargo)) (use-package rustic) ; lsp-compatible rust mode (add-hook \u0026#39;rust-mode-hook \u0026#39;rustic-mode) (add-hook \u0026#39;rustic-mode-hook (lambda () (setq rustic-lsp-server \u0026#39;rust-analyzer) ; not rls (setq lsp-rust-analyzer-server-command \u0026#39;(\u0026#34;/opt/homebrew/bin/rust-analyzer\u0026#34;)) ;(setq rustic-format-on-save t) ; has annoying bug move point to other buffer bug (setq rustic-indent-offset 4) (setq rustic-match-angle-brackets nil) ;; thought this would be better, was wrong. ;(setq rustic-compile-display-method \u0026#39;popwin:display-buffer-1) ; display if possible in popup-win )) (use-package cargo) (setq lsp-rust-server \u0026#39;rust-analyzer) # golang golang作为谷歌的亲儿子，是拥有官方维护的语言服务器的。而且gopls的使用体验非常好，完全不逊色与目前用户较多的goland及vscode。配合dlv-mode使用，在调试上笔者认为能够更加的贴合unix风格，也更加方便。\n1 2 3 4 5 6 7 8 9 10 11 12 13 ;; Go - lsp-mode ;; Set up before-save hooks to format buffer and add/delete imports. ;; go install github.com/golang/tools/cmd/gopls ;;(require \u0026#39;lsp-mode) (setq lsp-ui-mode nil) (defun lsp-go-install-save-hooks () (add-hook \u0026#39;before-save-hook #\u0026#39;lsp-format-buffer t t) (add-hook \u0026#39;before-save-hook #\u0026#39;lsp-organize-imports t t)) (add-hook \u0026#39;go-mode-hook #\u0026#39;lsp-go-install-save-hooks) ;; Start LSP Mode and YASnippet mode (add-hook \u0026#39;go-mode-hook #\u0026#39;lsp-deferred) (add-hook \u0026#39;go-mode-hook #\u0026#39;yas-minor-mode) # python python的语言服务器，笔者目前使用的是lsp-python-ms进行配置的。这个插件解决了很多python lsp的问题（实际上，在碰到这个插件之前，笔者一度要放弃安装python lsp）。由于python是解释型语言，对象的成员都较为灵活，一般编码阶段很难确认对象的成员及其确切的类型。所以在pylsp使用过程中，往往会碰到无法有效提示的情况。满足一般提示需求吧。\n1 2 3 4 5 6 7 8 9 ;;; set env for python ;; copied from ;; https://gitee.com/nutora-emacs/lsp-python-ms ;; python lsp-server use python-lsp-server ;; install as: pip3 install python-lsp-server (ensure-package-installed \u0026#39;lsp-python-ms) (require \u0026#39;lsp-python-ms) (setq lsp-python-ms-auto-install-server t) (add-hook \u0026#39;python-mode-hook #\u0026#39;lsp) # c/c++ 实际上，笔者很喜欢c/c++的语言服务器，简单、方便，安装时无比的顺畅。完全符合笔者对c语言简单、强大、靠谱的印象。\n1 2 3 4 5 6 7 8 9 ;; set up lsp-mode for c/c++ ;; brew install llvm ;; https://clangd.llvm.org/installation (unless (package-installed-p \u0026#39;eglot) (w-install \u0026#39;eglot)) (require \u0026#39;eglot) (add-to-list \u0026#39;eglot-server-programs \u0026#39;((c++-mode c-mode) \u0026#34;clangd\u0026#34;)) (add-hook \u0026#39;c-mode-hook \u0026#39;eglot-ensure) (add-hook \u0026#39;c++-mode-hook \u0026#39;eglot-ensure) # 使用的一点备注 这里唠叨一点\n# lsp 的管理单位是文件目录 这里对于golang及rust尤为明显。在使用emacs打开一个关联了有效语言服务器的文件时，底部会提示为当前文件选择一个工作目录。尤其是，当路径A已经设为工作目录时，再将A/B设为工作目录，A/B的打开状态是会出现异常的。所以尽量保持每个工作目录的独特。\n这里附上一些emacs lsp-mode中笔者常用的函数：\n指令 说明 lsp-workspace-folders-remove 将工作目录移除 lsp-workspace-folders-add 添加工作目录 lsp-workspace-restart 重启工作目录 # 其他备注 当安装了一个语言的lsp服务及对应的emacs客户端配置时，如果打开对应语言的文件发现lsp没有生效，且打开toggle-debug-on-error设置开启也没有发现任何报错，笔者建议重启emacs。似乎emacs热加载功能往往不会如人所愿。\n# 参考文献 emacs lsp mode\n及其他网络文献\n","date":"2021-10-12T20:26:00Z","permalink":"http://localhost:1313/p/emacs-%E8%8B%A5%E5%B9%B2%E8%AF%AD%E8%A8%80-lsp-%E9%85%8D%E7%BD%AE%E5%A4%87%E6%B3%A8/","title":"emacs-若干语言 lsp 配置备注"},{"content":" 记一次redisgo库使用时，连接远程redis服务写数据报错的问题。\nredis写数据时，出现报错write: broken pipe及write: connection reset by peer。看着都是网络的问题，使用redis-cli可以登陆并且执行查询等操作。经过排查，是写的数据量过大，导致写数据持续时间过长，排查的思路是猜想-\u0026gt;验证@A@。\n对于多个数据可以进行拆分。对于单个完整的数据，还没有太好的拆分思路（或许基于 pb 进行压缩，会是个好方式？）\n# 参考文章 python redis读写报错：Broken Pipe Error Redis\n","date":"2021-08-18T17:26:00Z","permalink":"http://localhost:1313/p/redisgo-%E8%BF%9E%E6%8E%A5%E6%8A%A5%E9%94%99/","title":"redisgo 连接报错"},{"content":" php作为动不动搞个大事情世界上最好的语言,经常偶尔会出现由于版本升级导致的不兼容问题。笔者在工作中遇到了php7.1升级到php7.4导致的each弃用、mcrypt库启动导致的不兼容。在这里备注下兼容方式。\n# each弃用 从php7.2开始，官方开始弃用each函数。作为一个伪码农我是很震惊的，无法想象哪天python把range弃用了，代码维护人员是否有毅力将所有的历史内容都重新适配下。php官方就是这么任性自信，直接删除，不做兼容。网上找到的兼容方案是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 function func_new_each(\u0026amp;$array){ $res = array(); $key = key($array); if($key !== null){ next($array); $res[1] = $res[\u0026#39;value\u0026#39;] = $array[$key]; $res[0] = $res[\u0026#39;key\u0026#39;] = $key; }else{ $res = false; } return $res; } // 替换前 list($scalar_type, $scalar_value) = each($methName-\u0026gt;me); // 替换后 list($scalar_type, $scalar_value) = func_new_each($methName-\u0026gt;me); # mcrpt库弃用 这个更狠了，整个库直接弃用。改为推荐openssl。好在工程不是长期维护的，后续可能还有重构的规划，所以以解决问题为优先目标吧，直接将废弃的mcrypt作为插件，重新编入php7.4:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 #! /bin/bash # any problem please contact me # used to install mcrypt.so extentions for php php_path=${1:-\u0026#34;/usr/local/php\u0026#34;}; echo \u0026#34;install php under ${php_path}\u0026#34;; function Info(){ echo `whoami`@`hostname`:`pwd`; } function check_env(){ mised=1; for i in {0}; do set -x; command -v ${php_path}/bin/php \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || break command -v ${php_path}/bin/phpize \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || break command -v ${php_path}/bin/php-config \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || break set +x; mised=0; done return ${mised}; } check_env; if [ $? -ne 0 ]; then echo \u0026#34;missing php exe file\u0026#34;; exit 233; fi # wget mcrypt wk_dir=\u0026#34;${HOME}/php_extend\u0026#34;; mkdir -p ${wk_dir}; if [ $? -ne 0 ]; then echo \u0026#34;cannot create ${wk_dir}, check permission\u0026#34;; exit 20; fi rm -rf ${wk_dir}/*; cd ${wk_dir} \u0026amp;\u0026amp; wget http://pecl.php.net/get/mcrypt-1.0.4.tgz; if [ $? -ne 0 ]; then echo \u0026#34;download mcrypt-1.0.4 failed\u0026#34;; exit 23; fi # prepare cd ${wk_dir} \u0026amp;\u0026amp; tar -xvf mcrypt-1.0.4.tgz; cd ${wk_dir}/mcrypt-1.0.4 \u0026amp;\u0026amp; ${php_path}/bin/phpize; if [ $? -ne 0 ]; then echo \u0026#34;mcrypt path init failed\u0026#34;; exit 233; fi # configure cd ${wk_dir}/mcrypt-1.0.4 \u0026amp;\u0026amp; ./configure --prefix=${wk_dir}/mcrypt --with-php-config=${php_path}/bin/php-config; if [ $? -ne 0 ]; then echo \u0026#34;=========\u0026gt; attention that, configure failed, would try to make\u0026#34;; fi # XXX: there is a sudo cd ${wk_dir}/mcrypt-1.0.4 \u0026amp;\u0026amp; make \u0026amp;\u0026amp; sudo make install # check if has output extend_dir=$(${php_path}/bin/php-config --extension-dir); if [ ! -f \u0026#34;${extend_dir}/mcrypt.so\u0026#34; ]; then echo \u0026#34;======\u0026gt; mcrypt.so generate failed\u0026#34;; exit 233; fi ini_dir=$(${php_path}/bin/php-config --ini-path); if [ ! -f \u0026#34;${ini_dir}/php.ini\u0026#34; ]; then echo \u0026#34;======\u0026gt; missing php ini file, ${ini_dir}/php.ini\u0026#34;; exit 233; fi cat \u0026lt;\u0026lt; EOF mcrypt.so is generated in ${extend_dir}/mcrypt.so, please do with sudo permission: echo \u0026#34;extension=mcrypt.so\u0026#34; \u0026gt;\u0026gt; ${ini_dir}/php.ini EOF # XXX: there is a sudo # need sudo, and should run ok #sudo echo \u0026#34;extension=mcrypt.so\u0026#34; \u0026gt;\u0026gt; ${ini_dir}/php.ini #if [ $? -ne 0 ]; then # echo \u0026#34;cannot write `extension=mcrypt.so` into ${ini_dir}/php.ini, please check permission\u0026#34;; # exit 2333; #fi # #echo \u0026#34;mcrypt.so install ok\u0026#34;; 语言的兼容性确实像噩梦一样。希望不要老是整这些幺蛾子。\n# 参考文献 php7.2 废弃each方法 php7.2 安装 mcrypt扩展 ","date":"2021-08-02T20:34:48Z","permalink":"http://localhost:1313/p/php-7.1%E5%8D%87%E7%BA%A7%E8%87%B37.4%E5%85%BC%E5%AE%B9%E6%80%A7/","title":"PHP-7.1升级至7.4兼容性"},{"content":" go-simplejson是go lang语言中操作json非常方便的开源库。最近使用simplejson进行数据插入操作时遇到了问题，经过排查后最终解决。现记录如下。\n# 问题描述 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 创建了一个json对象J，需要从其他地方获取剩余json信息后，插入到J中的data字段中。初始版本如下： import ( \u0026#34;fmt\u0026#34; simplejson \u0026#34;github.com/bitly/go-simplejson\u0026#34; ) func main() { js, _ := simplejson.NewJson([]byte(` { \u0026#34;errno\u0026#34;: 0, \u0026#34;errmsg\u0026#34;: \u0026#34;test\u0026#34; }`)) var js_2 = new(simplejson.Json) *js_2 = *js jsArr := []*simplejson.Json{} js1, _ := simplejson.NewJson([]byte(`{\u0026#34;num\u0026#34;: 1}`)) js2, _ := simplejson.NewJson([]byte(`{\u0026#34;num\u0026#34;: 2}`)) jsArr = append(jsArr, js1) jsArr = append(jsArr, js2) js.Set(\u0026#34;data\u0026#34;, jsArr) js.Get(\u0026#34;data\u0026#34;).GetIndex(0).Set(\u0026#34;test\u0026#34;, 1) jsB, _ := js.MarshalJSON() fmt.Println(string(jsB)) } // % go run js_check.go // {\u0026#34;data\u0026#34;:[{\u0026#34;num\u0026#34;:1},{\u0026#34;num\u0026#34;:2}],\u0026#34;errmsg\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;errno\u0026#34;:0} # 问题排查 经过dlv逐行调试，实际问题出在js.Get(\u0026quot;data\u0026quot;).GetIndex(0).Set(\u0026quot;test\u0026quot;, 1)中。跳转至定义，该操作实际做如下转换:\n1 2 3 4 arr, ok := js.Get(\u0026#34;data\u0026#34;).data.([]interface{}) if ok { \u0026amp;simplejson.Json(arr[index]).Set(\u0026#34;test\u0026#34;, 1) } 这里由于jsArr是[]*simplejson.Json，类型断言为[]interface{}失败。所以无法正常设置值。查看simplejson.go，其中的Json对象结构如下：\n1 2 3 type Json struct { data interface{} } 其实可以通过js.Interface()获取其中的真实数据。\n# 解决方案 变更为如下代码即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; simplejson \u0026#34;github.com/bitly/go-simplejson\u0026#34; ) func main() { js, _ := simplejson.NewJson([]byte(` { \u0026#34;errno\u0026#34;: 0, \u0026#34;errmsg\u0026#34;: \u0026#34;test\u0026#34; }`)) var js_2 = new(simplejson.Json) *js_2 = *js jsArr := []interface{}{} js1, _ := simplejson.NewJson([]byte(`{\u0026#34;num\u0026#34;: 1}`)) js2, _ := simplejson.NewJson([]byte(`{\u0026#34;num\u0026#34;: 2}`)) jsArr = append(jsArr, js1.Interface()) jsArr = append(jsArr, js2.Interface()) js.Set(\u0026#34;data\u0026#34;, jsArr) js.Get(\u0026#34;data\u0026#34;).GetIndex(0).Set(\u0026#34;test\u0026#34;, 1) jsB, _ := js.MarshalJSON() fmt.Println(string(jsB)) } // % go run js_check.go // {\u0026#34;data\u0026#34;:[{\u0026#34;num\u0026#34;:1,\u0026#34;test\u0026#34;:1},{\u0026#34;num\u0026#34;:2}],\u0026#34;errmsg\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;errno\u0026#34;:0} ","date":"2021-07-22T17:58:00Z","permalink":"http://localhost:1313/p/go-simplejson-%E6%8F%92%E5%85%A5%E6%95%B0%E7%BB%84/","title":"go-simplejson 插入数组"},{"content":" 从过往的经历中来看，使用websocket作为http协议的替代似乎是一种潮流。websocket以其小包头、全双工的优势，弥补了http协议的性能上的缺陷。对于长链接需求，完全可以在初始化时创建websocket连接，在业务交互时直接进行通信，使得通信过程更加流畅。相信在基于Quic的http3协议走向成熟应用前，websocket在性能上都具有优势。本文以golang语言为基础，构造场景进行两种协议的性能对比。\n# 场景 在服务端分别启动了http服务及websocket服务，返回所接受到的信息。构造BenchmarkHttp、BenchmarkWS进行请求，发送递增字符串。\n# 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 // server.go /* golang中使用的是http1.1协议，默认为长链接。仅第一次发送请求时进行握手。 */ package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; ) var ws_addr = flag.String(\u0026#34;ws_addr\u0026#34;, \u0026#34;localhost:9080\u0026#34;, \u0026#34;websocket http service address\u0026#34;) var http_addr = flag.String(\u0026#34;http_addr\u0026#34;, \u0026#34;localhost:9090\u0026#34;, \u0026#34;http address address\u0026#34;) var upgrader = websocket.Upgrader{} // use default options func ws_echo(w http.ResponseWriter, r *http.Request) { c, err := upgrader.Upgrade(w, r, nil) if err != nil { log.Print(\u0026#34;upgrade:\u0026#34;, err) return } defer c.Close() for { mt, message, err := c.ReadMessage() if err != nil { log.Println(\u0026#34;read:\u0026#34;, err) break } log.Printf(\u0026#34;recv: %s\u0026#34;, message) err = c.WriteMessage(mt, message) if err != nil { log.Println(\u0026#34;write:\u0026#34;, err) break } } } func http_echo(w http.ResponseWriter, req *http.Request) { req.ParseForm() echo_data := req.Form.Get(\u0026#34;echo\u0026#34;) fmt.Println(echo_data) io.WriteString(w, echo_data) return } func start_websocket() { http.HandleFunc(\u0026#34;/ws_echo\u0026#34;, ws_echo) log.Fatal(http.ListenAndServe(*ws_addr, nil)) } func start_http() { http.HandleFunc(\u0026#34;/http_echo\u0026#34;, http_echo) log.Fatal(http.ListenAndServe(*http_addr, nil)) } func main() { flag.Parse() log.SetFlags(0) wg := sync.WaitGroup{} wg.Add(2) go start_websocket() go start_http() wg.Wait() } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 // web_test.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/url\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; ) func BenchmarkHttp(b *testing.B) { client := \u0026amp;http.Client{} for i := 0; i \u0026lt; b.N; i++ { i_str := strconv.Itoa(i) req, err := http.NewRequest(http.MethodGet, \u0026#34;http://localhost:9090/http_echo?echo=\u0026#34;+i_str, nil) if err != nil { fmt.Println(\u0026#34;create new request failed\u0026#34;, err.Error()) return } //b.ResetTimer() resp, err := client.Do(req) if err != nil { fmt.Println(\u0026#34;got http request error\u0026#34;, err.Error()) return } _, _ = ioutil.ReadAll(resp.Body) //fmt.Println(string(body)) } } func BenchmarkWs(b *testing.B) { addr := \u0026#34;localhost:9080\u0026#34; u := url.URL{Scheme: \u0026#34;ws\u0026#34;, Host: addr, Path: \u0026#34;/ws_echo\u0026#34;} c, _, err := websocket.DefaultDialer.Dial(u.String(), nil) if err != nil { fmt.Println(\u0026#34;Error, create websocket connect failed\u0026#34;) return } for i := 0; i \u0026lt; b.N; i++ { err = c.WriteMessage(websocket.TextMessage, []byte(strconv.Itoa(i))) if err != nil { fmt.Println(\u0026#34;write ws message failed, \u0026#34;, err.Error()) continue } _, message, err := c.ReadMessage() if err != nil { fmt.Println(\u0026#34;Error, recv message failed\u0026#34;) fmt.Println(string(message)) continue } //fmt.Println(string(message)) } err = c.WriteMessage(websocket.CloseMessage, websocket.FormatCloseMessage(websocket.CloseNormalClosure, \u0026#34;\u0026#34;)) c.Close() } # 结果 1 2 3 4 5 go test -bench=. -benchtime=3s -run=none BenchmarkHttp-8 57764\t62737 ns/op BenchmarkWs-8 101538\t36740 ns/op PASS ok web_perf\t8.850s 从结果中可以直观的看到，websocket协议有明显的性能优势。\n# 问题结论 上次提出了两个问题，后来经过测试，有了结论。这里贴一下。\n单个goroutine 崩溃时，该进程内其他的goroutine也会崩溃。通常的做法是使用一层wrapper，进行recover获取及现场、日志等保存； golang中线程的实现，runtime中，初始化时会申请内核态线程；见runtime/proc.go； # 问题思考 http1.0, http1.1, http2.0, http3.0, websocket, quic协议的介绍； rpc调用与websocket通信之间的网络延时对比； # 文章推荐 net/http长链接\u0026amp;连接池使用时的超时陷阱 换电脑后，hexo-next 窝火的报错 golang调度器初始化\n","date":"2021-07-15T19:29:10Z","permalink":"http://localhost:1313/p/http%E5%8F%8Awebsocket%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/","title":"http及websocket性能对比"},{"content":" 写点东西还是难，果然还是搬运工来的轻松些。今天搬运点Golang的GMP模型看看。最近在准备一篇Golang的GC实践。慢慢搞吧。\n# 前言 Golang作为语言层面支持并发的语言，使用go可以让搬砖体验飞起。但是从直觉来说，事情并没有这么简单：从操作系统层面来说，进程和线程是操作系统认可的并行机制。协程以及Golang的所谓纤程是期望一堆程序员期望将操作系统的工作拿过来，以满足一些优化的效果。所以诸如Python的协程以及Golang的纤程，总是能够对应到操作系统认可的执行单元上。对于Python的协程还好理解一些，是严格运行在自己的线程里的，只是语言层面实现了线程内的上下文切换优化。所以对于CPU密集型的操作，仅使用协程是无法达到优化效果的：这种场景下Python会推荐多进程。相比起来，Golang的go野心更大一些：期望给用户以go作为接口，在语言内实现与操作系统调度单元的交互。Golang里实际的调度模型是GMP。\n# 搬运 这里搬运一些文章，介绍GMP。\n[典藏版] Golang 调度器 GMP 原理与调度全分析 从单进程开始介绍，后面的调试部分能学到一些东西\nGo语言学习 - GMP模型 G调度这块说的比较详细，可以看看\n6.5 调度器 # 日常膜拜\n# 思考 goroutine还是运行在一个进程里的。多线程想对比多进程，稳定性上会差一些：如果线程内出现了coredump等异常，整个进程可能就退出了。所以goroutine运行在一个进程内，会不会一个g出现了crash，整个程序崩溃？ Python的进程及线程，解释器层面分别使用了C的fork以及pthread(Linux)进行实现。g的实现是怎么样的。 ","date":"2021-04-15T21:39:29Z","permalink":"http://localhost:1313/p/golang-gmp/","title":"golang GMP"},{"content":" golang作为一种高级语言，实现了面向对象语言的封装、继承、多态的特性。本文简要介绍下golang面向对象的这些特性。\n# 封装 # 访问权限控制 Golang采用首字母大小写的方式控制访问权限。举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // lib/pub.go package learn type A struct{ // 定义对象 private int Public string } func NewA(private int, public string) A{ return A{private: private, Public: public} } func (a A) PrintInf(){ // 可通过a.PrintInf() 访问该函数 print(a.private, a.Public) } var ( private = 1 Public = \u0026#34;aa\u0026#34; ) // main.go package main import ( \u0026#34;go_learn/lib\u0026#34; ) func main(){ a := learn.NewA(1, \u0026#34;aa\u0026#34;) print(a.Public, a.private) // a.private不可包外访问，编译报错 print(learn.private, learn.Public) // learn.private不可包外访问，编译报错 } 和 C++/Java/Python等常见的面向对象语言不同，Golang的结构体中不支持函数的定义。某个结构体的函数，可以通过函数名前的归属生命来表示。\n# 访问结构体私有成员 这是个很有意思的话题。C++和Python都是有方法可以越过结构体的访问限制的，Golang通过unsafe.Pointer类型的转换也可以达到相同的目的。举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // learn/pub.go package learn type A struct{ private int Public string } func (a A) PrintInf(){ print(a.private, a.Public) return } func NewA(private int, public string) A{ return A{private: private, Public: public} } var ( private = 1 Public = \u0026#34;aa\u0026#34; ) // main.go /* 测试golang封装、继承、多态特性 */ package main import ( \u0026#34;unsafe\u0026#34; \u0026#34;go_learn/lib\u0026#34; ) type AA struct{ Private int Public string } func main(){ a := learn.NewA(1, \u0026#34;aa\u0026#34;) //print(a.Public, a.private) //print(learn.Public, learn.private) p := unsafe.Pointer(\u0026amp;a) aa := \u0026amp;AA{} aa = (*AA)(p) // golang unsafe.Pointer 更加接近 C/C++中指针的用法，编译器进行的校验较少； print(aa.Private, aa.Public) // 可以正常运行。 } # 总结 简单备注了下Golang封装的特性。后续再备注下继承、多态的使用吧。由于Golang采用鸭子式的继承检查思想，继承和多态的特性使用会相对较繁琐。\n","date":"2021-04-08T21:16:00Z","permalink":"http://localhost:1313/p/golang-%E5%B0%81%E8%A3%85/","title":"golang 封装"},{"content":" 在日常的工作中，固定QPS或者固定并发数是常用的两个衡量系统容量时采用的流量控制手段。本文以Go语言高级编程 服务流量限制的内容为开端，对服务流量限制进行展开描述，同时对Jmeter及golang ratelimit中的流量限制方法进行描述。\n起因 漏桶法 令牌桶法 Jmeter中流量吞吐控制 golang ratelimit # 起因 流量限制手段在系统流量控制以及系统质量评估上都有广泛的应用。对于有多个子模块/下游的系统，如果已知其中一个模块/下游是整个系统处理能力的瓶颈，从系统的入口添加流量限制并添加超量告警，不失为是保护系统的有效手段。从质量保证的手段来说，在衡量一个系统的稳定性时，需要有一个有效的手段来控制给予系统的压力并进行控制。\n固定并发数量的流量控制方式是相对容易实现的：对于系统而言，可以添加一个连接池；对于请求方而言，维护一个请求并发池即可。对于固定QPS的流量控制手段而言，则又复杂一些：由于基本指令的直接支持，所以固定QPS的流量控制手段多在基于并发的流量控制上进行二次的封装。封装的措施实际上又会影响控制的效果。笔者曾经在搜索系统上，尝试基于Jmeter，使用1000个线程来产生一个固定的100QPS的并发数。由于Jmeter固定吞吐量实现的特点，导致实际产生的效果中，100个请求多集中在1分钟的前几秒，甚至是最开始1s的前若干ms。使得服务承受的顺势并发非常大，服务出现异常也是可以预见的事情了。\n了解一些流量控制的手段还是有必要的。本文主要梳理一下Go语言高级编程提到的漏桶及令牌桶两种方法，并且进行简单的实现。\n# 漏桶法 基于Leaky_bucket的描述，目前广泛流行的漏桶法存在两种模式：度量法（the leaky bucket as a meter）及队列法（the leaky bucket as a queue）。\n度量法在处理时，单位时间内的请求如果超过了预设的数量，会将请求丢弃。比如，需要固定的流量为100QPS，我们以100ms作为一个衡量单元，即10 query/100ms。则，在单位的100ms内，如果请求数量超过了10，则将超过10的请求丢弃。对于队列法，则会将超过的请求均放在一个队列里，在下个时间单位内，按照先进先出的原则，处理队列内的请求。\n在请求数量较多且分布均匀的场景下，度量法更加适用。系统已经处于处理的极限，额外的请求存储似乎不太现实。对于流量分布不均的场景下，队列法能够抹平流量的不均匀。在队列长度可控的场景下，队列法能够兼顾请求方（尽量不丢请求）及服务方（控制流量）。至于超出的部分，应该考虑引入告警等方式来把控风险。\n# 令牌桶法 对令牌桶法的详细介绍见Token bucket。令牌桶法可以认为是更加一般的漏桶法。严格意义上的漏桶法要求每次仅有一个单位的请求被允许，令牌桶法则将其扩展为固定时间段内，产出多个令牌，被请求申请。当令牌桶法每次仅允许一个令牌时，显然就成了漏桶法。\n# Jmeter中吞吐量的控制逻辑 笔者找到的Jmeter最新版本为ConstantThroughputTimer。在该实现中，主要分为单线程、多线程、共享线程等模式下的吞吐量（Jmeter中的吞吐量为Query Per Minutes)等模式。可以看出，Jmeter在不同的限流逻辑下，计算每个线程需要的delay时间实现jmeter的请求调度，体现了漏桶法的思路。 相关代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // Calculate the delay based on the mode private long calculateDelay() { long delay; // N.B. we fetch the throughput each time, as it may vary during a test double msPerRequest = MILLISEC_PER_MIN / getThroughput(); switch (mode) { case AllActiveThreads: // Total number of threads delay = Math.round(JMeterContextService.getNumberOfThreads() * msPerRequest); break; case AllActiveThreadsInCurrentThreadGroup: // Active threads in this group delay = Math.round(JMeterContextService.getContext().getThreadGroup().getNumberOfThreads() * msPerRequest); break; case AllActiveThreads_Shared: // All threads - alternate calculation delay = calculateSharedDelay(allThreadsInfo,Math.round(msPerRequest)); break; case AllActiveThreadsInCurrentThreadGroup_Shared: //All threads in this group - alternate calculation final org.apache.jmeter.threads.AbstractThreadGroup group = JMeterContextService.getContext().getThreadGroup(); ThroughputInfo groupInfo = threadGroupsInfoMap.get(group); if (groupInfo == null) { groupInfo = new ThroughputInfo(); ThroughputInfo previous = threadGroupsInfoMap.putIfAbsent(group, groupInfo); if (previous != null) { // We did not replace the entry groupInfo = previous; // so use the existing one } } delay = calculateSharedDelay(groupInfo,Math.round(msPerRequest)); break; case ThisThreadOnly: default: // e.g. 0 delay = Math.round(msPerRequest); // i.e. * 1 break; return delay; } # golang ratelimit介绍 golang中也有很多请求控制的方法。工程中经常使用的 chan(bool)+WaitGroup池化了请求限制，可以认为是令牌桶法的思路的一种简化；golang自带的Ticker则会在固定的时间间隔内产生一个就绪的状态，可以看出漏桶法的思想。更加工程化的选择，可以看下golang ratelimituber开源的这个golang版本的ratelimit实现。水平优先，就贴一个网上找来的源码分析文章uber-go 漏桶限流器使用与原理分析。\n# 总结 本文对常用的两个限流方法漏桶法及令牌桶法进行了简单的描述。同时简单涉及了下Jmeter中的流量限制及golang中不同请求限制措施的思路。\n","date":"2021-02-07T17:30:00Z","permalink":"http://localhost:1313/p/ratelimit%E6%9C%8D%E5%8A%A1%E6%B5%81%E9%87%8F%E9%99%90%E5%88%B6/","title":"ratelimit服务流量限制"},{"content":" org-mode agenda界面变更任务状态、添加备注、添加日记（每日总结）、编辑记录\n以下操作均在org-agenda中的agenda for current week or day视图下快速编辑：\n操作 快捷键 变更任务状态 t 添加备注 z 添加日记 i 编辑note z 重建agenda r 打开日历 a 下周任务列表 f 上周任务列表 b 打开任务所在原始文件 enter ","date":"2021-01-11T21:49:00Z","permalink":"http://localhost:1313/p/org-mode%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"org-mode使用备注"},{"content":" 为了更好的live in emacs，一款合适的日程管理工具总是需要的。在挣扎了若干次后，最终还是把org-mode这一优秀的日程管理工具捡起来了。本文简单记录下使用的方法。\n# org-mode介绍 在神的编辑器emacs的传说中，往往有org-mode的身影。虽然按照(org官网)orgmode官网的描述，org-mode并不仅限于在emacs中使用，如开始使用 Org 模式吧，在没有 Emacs 的情况下这篇文章就详细讲解了在vscode中使用org-mode的方式，但是配合emacs的万物皆系于kbd之上的使用习惯，org-mode确实能够发挥最大的功能。\norg-mode的基本功能包括设置待办事项、设置待办的标签、查看日历、查看某一天的待办及进度。基本上，满足了对优秀日程管理工具的所有想象。\n这里贴一下开源世界旅行手册中涉及的org-mode与oneNote的对比，能够更加直观的了解org-mode的功能：\norg-mode vs oneNote Org-mode OneNote 标签 强大 不支持 日程表 强大 不支持 界面 字符 漂亮 TablePC 不支持 非常好 摘录 保持源格式 便捷 Emacs 内置 安装麻烦 # 基本使用流程 目前还处于探索阶段了，简单描述下org-mode的配置流程。 0. 版本 使用的是emacs-27.1版本，默认内置了org-mode(值得一提的是，当我在写一篇文章时，发现hexo#admin编辑器是支持部分emacs快捷键的，又反映了emacs影响之广)。\n设置\norg-mode在使用时，一般是在文本文档中编辑待办内容，将待办内容加入org-mode的日程表。而后通过org-agenda来查看指定日期的待办内容，并随着待办内容设置事务的进度。\n使用前，如果是使用emacs进行编辑的话，可以在emacs配置文件中作如下设置： 1 2 3 4 ;; 将.org结尾的文档，均以org-mode打开 (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\.org\\\u0026#39;\u0026#34; . org-mode)) ;; 将org-agenda绑定为Ctrl-c a 快捷键 (global-set-key (kbd \u0026#34;C-c a\u0026#34;) \u0026#39;org-agenda) 重新打开emacs使配置生效，重新载入emacs配置文件即可。 使用时，可以单独建立一个文件夹，来存储不同需求的日程文档（如，笔者在~/.org/目录下创建了2021.org,learn.org等多个文档）。以下是一个简单的待办文档内容（引用自文章3）：\n1 2 3 4 5 6 7 8 9 10 11 #+STARTUP: overview #+TAGS: { 桌面(d) 服务器(s) } 编辑器(e) 浏览器(f) 多媒体(m) 压缩(z) #+TAGS: { @Windows(w) @Linux(l) } #+TAGS: { 糟糕(1) 凑合(2) 不错(3) 很好(4) 极品(5) } #+SEQ_TODO: TODO(T) WAIT(W) | DONE(D!) CANCELED(C@) #+COLUMNS: %10ITEM %10PRIORITY %15TODO %65TAGS * 工作 \u0026lt;2021-01-10\u0026gt;-\u0026lt;2022-01-10\u0026gt; ** Emacs \u0026lt;2021-01-10 21:00 ++1d\u0026gt; 神之编辑器 *** org-mode 组织你的意念 （更多的内容可以查看下原文，本文仅简单介绍） 以#+开头的可以认为是本地设置内容。#+TAGS: 后设置的内容，是本日程中预设的日程标签，标签()中的是该标签的缩写，需要保持唯一。在下面的日程（或者标题，可以很容易的看出来，和markdown是类似的语法）上使用快捷键Ctrl-c Ctrl-c(或者说，C-c C-c)，即可给日程打上标签。每个{}内的标签是互斥的，在设置时，可以注意下。\n下面的日程中,\u0026lt;2021-01-10\u0026gt;-\u0026lt;2022-01-10\u0026gt;表示该事件时间范围为2021-01-10至2022-01-10结束。\u0026lt;2021-01-10 21:00 ++1d\u0026gt;表示这个子任务的时间开始于2021-01-10 21:00而后每天重复一次(++1w，++1m为周、月，以此类推)。\n而后，保存文件。使用Ctrl-c [将当前日程文件纳入org-mode的日程表。使用前面配置的快捷键C-c a唤出日历，会出现如下提示：\nPress key for an agenda command: a 本周事件 t 显示所有事件 m 查询标签 L 当前缓冲区时间线 s 查询关键词 T 查询带 TODO 关键词的项 M 查询带 TODO 关键词的标签 # 显示已停止事件 q 退出日程表 选择a，可以查看本周的事件。如果已经到了所设置的事件区间，即可看到我们设置的事件内容。 以上算是简单的入门了。 # 相关文章 使用org-mode 管理日常事务- 日知录 用Org-mode实现GTD 组织你的意念：Emacs org mode. ","date":"2021-01-10T20:30:00Z","permalink":"http://localhost:1313/p/emacs-start-org-mode--org-mode%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"emacs! start org-mode! --org-mode使用备注"},{"content":" 使用emacs过程中，配合evil使用，按照tab的划分，将编辑、浏览、leetcode等任务划分到不同的tab便于切换及管理。美中不足的是，模拟标签的elscreen默认将其他标签的颜色设置成:background blue :foreground black的配色，每次切换任务时，都需要重复确认需要跳转到哪个标签，就比较麻烦了。查找了一下重置face-attribute的方法，备注下。\n在初始文件的最后添加：\n1 2 3 4 5 ;; 选中标签设置为绿底黑字，其他标签为黄底黑字 (set-face-attribute \u0026#39;elscreen-tab-other-screen-face nil :background \u0026#34;yellow\u0026#34; :foreground \u0026#34;black\u0026#34;) (set-face-attribute \u0026#39;elscreen-tab-current-screen-face nil :background \u0026#34;green\u0026#34; :foreground \u0026#34;black\u0026#34;) 备注下elscreen原始代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 (defface elscreen-tab-current-screen-face \u0026#39;((((class color)) (:background \u0026#34;white\u0026#34; :foreground \u0026#34;black\u0026#34;)) (t (:underline t))) \u0026#34;Face for current screen tab.\u0026#34; :group \u0026#39;elscreen) (defface elscreen-tab-other-screen-face \u0026#39;((((type x w32 mac ns) (class color)) :background \u0026#34;Gray85\u0026#34; :foreground \u0026#34;Gray50\u0026#34;) (((class color)) (:background \u0026#34;blue\u0026#34; :foreground \u0026#34;black\u0026#34; :underline t))) \u0026#34;Face for tabs other than current screen one.\u0026#34; :group \u0026#39;elscreen) emacs defface\n","date":"2020-12-23T19:23:00Z","permalink":"http://localhost:1313/p/elscreen%E6%A0%87%E7%AD%BE%E8%83%8C%E6%99%AF%E9%A2%9C%E8%89%B2/","title":"elscreen标签背景颜色"},{"content":" 最近开始使用Mac了。在使用过程中，发现了一些Mac OS和Centos体验上不同的地方。在这里做一下备注。\n# 部分Linux指令缺失 Mac OS并没有实现所有的Linux下的指令，如realpath这里就需要单独安装一些扩展包了：\nbrew install coreutils\n# 终端Basic颜色不友好 可以单独下载一些配色方案。从尽量使用原生配色的角度来说，只需要在.bashrc下面作如下配置即可：\n# for color\nexport CLICOLOR=1\n# grep\nalias grep=\u0026lsquo;grep \u0026ndash;color=always\u0026rsquo;\n此外，配合.vimrc中配色变更食用更佳：\n\u0026quot; 设置搜索高亮\nset hlsearch\n\u0026quot; 设置语法高亮\nsyntax on\n# 启动shell配置不同 Mac OS默认使用zsh作为登陆shell。所以设置.bashrc作为启动配置时，需要在~/.zshrc中进行配置：\n[ -f ~/.bashrc ] \u0026amp;\u0026amp; source ~/.bashrc\n后面碰到再补充吧。\n","date":"2020-12-10T19:40:00Z","permalink":"http://localhost:1313/p/mac%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"Mac使用备注"},{"content":"目录内容：\n1 text text.bak 希望从中找到text.bak。使用find实现。\n错误操作：\n1 2 3 \u0026gt;find -name *.bak* . find: paths must precede expression: . Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression] -name会作为EXPRESSIONS存在。find要求的参数位置为：\n1 find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression] 所以，正确格式为：\n1 2 find . -name *.bak ./text.bak 关于正则中.会作为通配符，如需匹配text.bak需要对.进行转义的情况，也需要关注下。本例中就不涉及了。\n","date":"2020-11-12T21:44:28Z","permalink":"http://localhost:1313/p/find%E5%8C%B9%E9%85%8D%E6%96%87%E4%BB%B6%E5%90%8D/","title":"find匹配文件名"},{"content":" # sed功能介绍 先看下官方的介绍\nSed is a stream editor. A stream editor is used to perform basic text transformations on an input stream (a file or input from a pipeline).\nWhile in some ways similar to an editor which permits scripted edits (such as ed), sed works by making only one pass over the input(s), and\nis consequently more efficient. But it is sed’s ability to filter text in a pipeline which particularly distinguishes it from other types of\neditors.\n大概的意思，是面向流的文本编辑工具。一般用来对文件中的文本进行替换等操作。\n以下备注一些常用的操作方式了。\n# 使用介绍 我们以上段文字为例，使用sed进行文本的操作。\n1 2 3 4 5 6 7 8 9 10 11 12 sed -i \u0026#34;s#Sed#SED#g\u0026#34; text 使用 -i 才可以直接修改 text 里面的内容，否则无法修改（但是会将修改后的内容输出到标准输出） 这里使用#作为sed的限位符而非/，是因为一般文本中，/符号出现的频率要较#高。直接使用#就不需要频繁转义了。 sed -i \u0026#39;2,2 s#in#in_#g\u0026#39; text 将 行号 [2,2] 中的 in 全部替换为 in_，注意，input也会被替换为in_put sed -i \u0026#39;/While.*/, /.*editors/ s#in#in_#g\u0026#39; text 将 While.* .*editors 之间的 in 全部替换为 in_ sed -i \u0026#39;2,+1 s#in#in_#g\u0026#39; text 将 [2, 2+1=3] 行内的 in 全部替换为 in_ 基本上常用的一些 sed替换方式就是这些了。man文档中还有一些基于倍数的替换范围决定方式，这里就不说明了。使用的时候，还是尽量使用通俗易懂的方式。\n","date":"2020-11-12T16:36:51Z","permalink":"http://localhost:1313/p/sed%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"sed使用备注"},{"content":"最近研究了一下pluma的使用。发现官网上的简单示例对于刚入门的人来说还是麻烦了些（而且还有语法错误）。\n下面重新整理了一个例子，作为备注。\n其中，device为一个虚基类，作为接口类存在。keyboard及screen作为实现了device的子类存在，实现具体的操作。在pluma上注册后，在main中调用接口，实现keyboard及screen的调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // device.hpp #ifndef _DEVICE_HPP_ #define _DEVICE_HPP_ #include \u0026#34;Pluma/Pluma.hpp\u0026#34; class Device{ public: virtual std::string getDescription() const=0; }; // create DevicedProvider class PLUMA_PROVIDER_HEADER(Device); #endif 1 2 3 // device.cpp #include \u0026#34;device.hpp\u0026#34; PLUMA_PROVIDER_SOURCE(Device, 6, 3); 如上所示，是device的定义。其中PLUMA_PROVIDER_HEADER和PLUMA_PROVIDER_SOURCEpluma提供的宏。功能暂且不论。我们继续往下看。\n1 2 3 4 5 6 7 8 9 10 11 12 // screen.hpp #include \u0026#34;Pluma/Pluma.hpp\u0026#34; #include \u0026#34;device.hpp\u0026#34; class Screen: public Device{ public: std:: string getDescription() const{ return \u0026#34;screen\u0026#34;; } }; PLUMA_INHERIT_PROVIDER(Screen, Device); 1 2 3 4 5 6 7 8 9 10 11 12 // keyboard.hpp #include \u0026#34;Pluma/Pluma.hpp\u0026#34; #include \u0026#34;device.hpp\u0026#34; class Keyboard: public Device{ public: std:: string getDescription() const{ return \u0026#34;keyboard\u0026#34;; } }; PLUMA_INHERIT_PROVIDER(Keyboard, Device); 上面实现了screen及keyboard的逻辑。实现了之后，需要进行注册：\n1 2 3 4 5 6 7 8 9 10 11 12 // connect.cpp #include \u0026lt;Pluma/Connector.hpp\u0026gt; #include \u0026#34;keyboard.hpp\u0026#34; #include \u0026#34;screen.hpp\u0026#34; PLUMA_CONNECTOR bool connect(pluma::Host\u0026amp; host){ // add a keyboard provider to host host.add( new KeyboardProvider() ); host.add( new ScreenProvider() ); return true; } 这里在connect中进行了两个子类的注册。之所以使用connect是因为后面的pluma使用的时候，官网给出的示例代码中，会从connect入口开始调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // main.cpp #include \u0026#34;Pluma/Pluma.hpp\u0026#34; #include \u0026#34;device.hpp\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; int main() { pluma:: Pluma plugins; plugins.acceptProviderType\u0026lt;DeviceProvider\u0026gt;(); plugins.load(\u0026#34;./plugin/connect.so\u0026#34;); //plugins.load(\u0026#34;./plugin/keyboard.so\u0026#34;); std::vector\u0026lt;DeviceProvider*\u0026gt; providers; plugins.getProviders(providers); std::cout\u0026lt;\u0026lt;\u0026#34;size for providers are:\u0026#34; \u0026lt;\u0026lt; providers.size()\u0026lt;\u0026lt; std:: endl; if (!providers.empty()){ for (std::vector\u0026lt;DeviceProvider*\u0026gt;::iterator device=providers.begin(); device != providers.end(); ++ device){ Device* myDevice = (*device)-\u0026gt;create(); std::cout \u0026lt;\u0026lt; myDevice-\u0026gt;getDescription() \u0026lt;\u0026lt; std::endl; delete myDevice; } } return 0; } 这里就是主要的调用逻辑了。官网中myDevice附近的拼写有主意，这是个坑了。\n这里回顾下目录结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 . ├── connect.cpp ├── device.hpp ├── device.cpp ├── keyboard.hpp ├── main.cpp ├── plugin # 用来存储插件结果的目录 ├── Pluma # 为了方便，这里将Pluma的include及src文件均拷贝到这里 │ ├── Config.hpp │ ├── Connector.hpp │ ├── Dir.cpp │ ├── Dir.hpp │ ├── DLibrary.cpp │ ├── DLibrary.hpp │ ├── Host.cpp │ ├── Host.hpp │ ├── PluginManager.cpp │ ├── PluginManager.hpp │ ├── Pluma.hpp │ ├── Pluma.inl │ ├── Provider.cpp │ ├── Provider.hpp │ └── uce-dirent.h └── screen.hpp 看下编译过程：\n1 2 3 4 5 # 生成device.so g++ connect.cpp device.cpp Pluma/*.cpp -shared -fPIC -o plugin/connect.so -I./ # 生成main g++ main.cpp device.hpp device.cpp Pluma/*.cpp -o main -I./ -ldl 执行：\n1 2 3 4 ./main size for providers are:2 keyboard screen 以上就是实践的内容了。\n","date":"2020-10-29T21:19:00Z","permalink":"http://localhost:1313/p/c-%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86--pluma%E5%AE%9E%E8%B7%B5/","title":"c++插件管理--pluma\u003c实践\u003e"},{"content":"\u0026lt;一\u0026gt; 这里记录一些python调试的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # coding=UTF-8 \u0026#39;\u0026#39;\u0026#39; python debug method 1 use print function to get output informatino \u0026#39;\u0026#39;\u0026#39; DEBUG = True def _debug_(*args, **kwds): \u0026#39;\u0026#39;\u0026#39; depends on DEBUG value, print some function \u0026#39;\u0026#39;\u0026#39; global DEBUG if DEBUG: print(args, kwds) if __name__ == \u0026#34;__main__\u0026#34;: _debug_(\u0026#34;this is a test\u0026#34;) 最常见的调试方法了。print可以依据需求调整为其他的方式（logging输出日志或者直接输出到文件中均可）。\n1 2 # 输出结果如下： ((\u0026#39;this is a test\u0026#39;,), {}) \u0026lt;二\u0026gt;然后就是更直接一些的调试方法了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # coding=UTF-8 import pdb def test_function(): \u0026#39;\u0026#39;\u0026#39; regard it as a test funcion \u0026#39;\u0026#39;\u0026#39; try: a = 1 b = 0 c = a / b except Exception, e: pdb.set_trace() return if __name__ == \u0026#34;__main__\u0026#34;: test_function() 直接一点了，直接在代码中显式设置断点。这样，在异常发生时，就可以直接中断调试了。\npython中的pdb应该可以认为是一种阉割版的gdb了。仅对listprint及其他的python的内置函数有较好的支持。相互配合来看的话，也能发现很多问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 输出如下： \u0026gt; test_debug.py(11)test_function() -\u0026gt; return (Pdb) list 6 a = 1 7 b = 0 8 c = a / b 9 except Exception, e: 10 pdb.set_trace() 11 -\u0026gt; return 12 13 if __name__ == \u0026#34;__main__\u0026#34;: 14 test_function() [EOF] (Pdb) print(e) integer division or modulo by zero (Pdb) print(a, b, c) *** NameError: name \u0026#39;c\u0026#39; is not defined (Pdb) print(a, b) (1, 0) (Pdb) quit() 唔，先这样吧。可以考虑收集一些python的内置解析包来配合调试了。\n","date":"2019-07-17T22:51:00Z","permalink":"http://localhost:1313/p/python%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95%E5%85%B6%E4%B8%80/","title":"python调试方法（其一）"},{"content":"考虑以下场景：\n期望通过给定的变量名称var_str，打印出该名称对应的变量值${var_str}。使用指令eval可以很方便的实现：\n1 2 3 var_str=\u0026#34;1213\u0026#34;; ned_param_name=\u0026#34;var_str\u0026#34;; eval echo \u0026#39;$\u0026#39;\u0026#34;${ned_param_name}\u0026#34;; 输出结果为1213;\neval命令解释如下：\n1 2 3 4 5 6 7 eval [arg ...] The args are read and concatenated together into a single command. This command is then read and executed by the shell, and its exit status is returned as the value of eval. If there are no args, or only null arguments, eval returns 0. eval [参数 ...] 参数将会被读取并作为一个指令被读入。然后这个指令将会被shell读取并执行，执行结果 将会作为eval的结果。如果没有参数传入，或者只有空参数，eval指令将会返回0。 对于上述的例子，echo $var_str将会被读入，并被shell重新执行。输出结果为1213。该结果即作为eval的输出结果。\n","date":"2019-06-04T21:53:00Z","permalink":"http://localhost:1313/p/shell-%E8%AE%BF%E9%97%AE%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%90%8C%E5%90%8D%E5%8F%98%E9%87%8F/","title":"shell-访问字符串同名变量"},{"content":"lisp中，do循环形象如下:\n1 2 3 (do (variable-definition*) (end-test-form result-form*) statement*); 其中，(variable-definition*)是一些行日(var init next)的赋值结构。在do开始时，var会被赋值为init。并且在一次循环结束后，var会被赋值为next所表示的内容。\n形如：\n1 2 3 4 5 (do ((n 0 (+ 1 n)) (cur 0 next) (next 1 (+ cur next))) ((= 10 n) (format t \u0026#34;|end ~d\u0026#34; cur)) (format t \u0026#34;~d|\u0026#34; cur)); 输出：\n1 0|1|1|2|3|5|8|13|21|34||end 55 类似于python中的：\n1 2 3 4 5 6 cur = 0 next = 1 for i in range(10): print(\u0026#34;%d|\u0026#34; % cur) cur, next = next, cur + next print(\u0026#34;|end %d\u0026#34; % cur) ","date":"2019-06-03T22:42:00Z","permalink":"http://localhost:1313/p/lisp-do%E5%BE%AA%E7%8E%AF/","title":"lisp-do循环"},{"content":"lisp声明、使用变量的一种方法，是使用let语句。\n形如：\n1 2 3 4 5 6 7 8 9 10 11 12 ;(let ((variable declare1) (variable declare2) (...)) ; (varaible used here)); (defun foo(x) (format t \u0026#34;Parameter: ~a~%\u0026#34; x) (let ((x 2)) (format t \u0026#34;Outer LET: ~a~%\u0026#34; x) (let ((x 3)) (format t \u0026#34;Inner LET: ~a~%\u0026#34; x)) (format t \u0026#34;Outer LET: ~a~%\u0026#34; x)) (format t \u0026#34;Parameter: ~a~%\u0026#34; x)); (foo 10); 声明的作用域，和C语言很相似，存在覆盖的特点。输出：\n1 2 3 4 5 Parameter: 10 Outer LET: 2 Inner LET: 3 Outer LET: 2 Parameter: 10 使用let声明时，变量声明域内，无法使用前一个在本声明域内声明的变量：\n1 2 3 4 5 6 (defun year-day(y) (let ((m (* y 12)) (d (* m 30))) (format t \u0026#34;Year:~d~%Month:~d~%Day:~d~%\u0026#34; y m d))); (year-day 1); *** - LET: variable M has no value 使用let*可以进行如此操作：\n1 2 3 4 5 6 7 (defun year-day(y) (let* ((m (* y 12)) (d (* m 30))) (format t \u0026#34;Year:~d~%Month:~d~%Day:~d~%\u0026#34; y m d))); (year-day 1); Year:1 Month:12 Day:360 just like this.\n","date":"2019-05-30T22:51:00Z","permalink":"http://localhost:1313/p/lisp-let%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E/","title":"lisp-let变量声明"},{"content":"lisp中的lambda表达式，显然和python中的很相似。\n参照《实用common lisp编程》：\n1 2 3 4 5 6 7 8 ;按照 min max, 步长step为参数的fn计算的长度输出 * (defun plot (fn min max step) (loop for i from min to max by step do (loop repeat (funcall fn i) do (format t \u0026#34;*\u0026#34;)) (format t \u0026#34;~%\u0026#34;))) (plot #\u0026#39;exp 0 4 1/2); (plot #\u0026#39;(lambda (x) (* 2 x)) 0 10 1); 输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 * ** *** ***** ******** ************* ********************* ********************************** ******************************************************* ** **** ****** ******** ********** ************ ************** **************** ****************** ******************** #\u0026rsquo;为lisp语言的语法糖，展开表示为function。后者将会把一个函数生成为一个函数对象，后者可以通过funcall调用。\ninteresting。\n","date":"2019-05-29T23:28:00Z","permalink":"http://localhost:1313/p/lisp-lambda%E5%87%BD%E6%95%B0/","title":"lisp-lambda函数"},{"content":"目前，lisp的开发环境基本上被lispbox所垄断。所以本文来说一CLISP，C语言实现的LISP解释器的安装。\n1 2 3 4 5 wget \u0026#34;https://ftp.gnu.org/pub/gnu/clisp/latest/clisp-2.49.tar.gz\u0026#34; tar -xvf clisp-2.49.tar.gz cd clisp-2.49 ./configure --prefix=LOCAL_PATH --ignore-absence-of-libsigsegv cd src \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 这样就可以将CLISP安装到\u0026ndash;prefix指定的路径。\n然后是使用。\n1 2 cd LOCAL_PATH/bin/ ./clisp 就会出现欢迎界面：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 i i i i i i i ooooo o ooooooo ooooo ooooo I I I I I I I 8 8 8 8 8 o 8 8 I \\ `+\u0026#39; / I 8 8 8 8 8 8 \\ `-+-\u0026#39; / 8 8 8 ooooo 8oooo `-__|__-\u0026#39; 8 8 8 8 8 | 8 o 8 8 o 8 8 ------+------ ooooo 8oooooo ooo8ooo ooooo 8 Welcome to GNU CLISP 2.49 (2010-07-07) \u0026lt;http://clisp.cons.org/\u0026gt; Copyright (c) Bruno Haible, Michael Stoll 1992, 1993 Copyright (c) Bruno Haible, Marcus Daniels 1994-1997 Copyright (c) Bruno Haible, Pierpaolo Bernardi, Sam Steingold 1998 Copyright (c) Bruno Haible, Sam Steingold 1999-2000 Copyright (c) Sam Steingold, Bruno Haible 2001-2010 Type :h and hit Enter for context help. [1]\u0026gt; 尝试进行函数求值：\n1 2 3 4 5 6 7 [1]\u0026gt; (defun sum(x y) (format t \u0026#34;~d\u0026#34; (+ x y))) SUM [2]\u0026gt; (sum 1 2) 3 NIL [3]\u0026gt; (exit) Bye. 或者，将以下内容写入test.lisp文件然后执行：\n1 2 3 (defun sum(x y) (format t \u0026#34;~d\u0026#34; (+ x y))) (sum 1 2) 执行LOCAL_PATH/bin/clisp test.lisp成功输出。\n","date":"2019-05-28T22:16:00Z","permalink":"http://localhost:1313/p/clisp%E7%BC%96%E8%AF%91/","title":"clisp编译"},{"content":"lisp语言的基本表达式为S-表达式。这与受Algol语言影响的C系语言有很大的不同。显然，这很有趣：\n1 2 3 4 5 ;the bellow is hello world function in lisp (defun hello-world() \u0026#34;hello world function in lisp\u0026#34; (format t \u0026#34;hello, world!\u0026#34;));``` 由\u0026lt;code\u0026gt;()\u0026lt;/code\u0026gt;所包围的内容，为*列表*，其余内容为原子。显然，lisp表达式有很多列表表示（List Processing)。 ","date":"2019-05-28T21:52:00Z","permalink":"http://localhost:1313/p/lisp-hello-world/","title":"lisp-hello world"}]