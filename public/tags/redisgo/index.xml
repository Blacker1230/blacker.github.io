<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
    <channel>
        <title>Redisgo on 李岩</title>
        <link>http://localhost:1313/tags/redisgo/</link>
        <description>Recent content in Redisgo on 李岩</description>
        <generator>Hugo -- gohugo.io</generator>
        <language>zh-Hans</language>
        <lastBuildDate>Wed, 18 Aug 2021 17:26:00 +0000</lastBuildDate><atom:link href="http://localhost:1313/tags/redisgo/index.xml" rel="self" type="application/rss+xml" /><item>
        <title>redisgo 连接报错</title>
        <link>http://localhost:1313/p/redisgo-%E8%BF%9E%E6%8E%A5%E6%8A%A5%E9%94%99/</link>
        <pubDate>Wed, 18 Aug 2021 17:26:00 +0000</pubDate>
        
        <guid>http://localhost:1313/p/redisgo-%E8%BF%9E%E6%8E%A5%E6%8A%A5%E9%94%99/</guid>
        <description>&lt;blockquote&gt;
&lt;p&gt;记一次&lt;code&gt;redisgo&lt;/code&gt;库使用时，连接远程&lt;code&gt;redis&lt;/code&gt;服务写数据报错的问题。&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;&lt;code&gt;redis&lt;/code&gt;写数据时，出现报错&lt;code&gt;write: broken pipe&lt;/code&gt;及&lt;code&gt;write: connection reset by peer&lt;/code&gt;。看着都是网络的问题，使用&lt;code&gt;redis-cli&lt;/code&gt;可以登陆并且执行查询等操作。经过排查，是写的数据量过大，导致写数据持续时间过长，排查的思路是猜想-&amp;gt;验证&lt;code&gt;@A@&lt;/code&gt;。&lt;br&gt;
对于多个数据可以进行拆分。对于单个完整的数据，还没有太好的拆分思路（或许基于 &lt;code&gt;pb&lt;/code&gt; 进行压缩，会是个好方式？）&lt;/p&gt;
&lt;h1 id=&#34;参考文章&#34;&gt;
    &lt;a href=&#34;#%e5%8f%82%e8%80%83%e6%96%87%e7%ab%a0&#34;&gt;#&lt;/a&gt;
    参考文章
&lt;/h1&gt;&lt;p&gt;&lt;a class=&#34;link&#34; href=&#34;https://blog.csdn.net/xieganyu3460/article/details/82884346&#34;  target=&#34;_blank&#34; rel=&#34;noopener&#34;
    &gt;python redis读写报错：Broken Pipe Error Redis&lt;/a&gt;&lt;/p&gt;
</description>
        </item>
        
    </channel>
</rss>
