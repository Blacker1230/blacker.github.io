[{"content":" 最近工作中一直接触存储相关的内容，感觉对现在的存储分类及各个存储的优缺点等了解的还很少。趁着这个机会整理下相关的内容。相信会有收获。\n# 简介 存储是系统设计中不可缺少的一部分，而存储的选择又有很多种，相关的概念也很繁杂：关系型数据库、列数据库、文件型数据库等等。在为系统选择合适的数据库之前，显然需要了解这些数据库的概念及它们的优缺点。这些是笔者还不具备的能力。笔者试着在本文中对这些概念进行总结，并结合实践来论述下使用需要注意的内容。本文主要内容均整理自互联网文档。希望是个引子，后面依据实践，持续补充及修正涉及到的内容。\n从工作中的经验来看，笔者对存储系统一般关注系统的存储方式、数据一致性的保障方式、如何进行扩展。部分已确定的内容罗列在下面：\n系统 存储类型 存储方式 CAP满足 扩展方式 常见优化 价格 MySQL 关系型数据库 B+树 (InnoDB引擎) CA（同步复制），AP（异步复制、半同步复制） 一般采用主从同步的方式。通过消费binlog, redolog, undolog 来实现数据间的一致性。 加机器（CPU、内存、SSD盘）、集群同步方式修改（异步同步）、读写分离、分库分表 均衡 Elasticsearch 检索系统 索引+JSON为基础的文档 CA（设置同步配置），AP 扩展 shard 来实现水平扩展 增加 Shard，索引优化，加机器 涉及到倒排索引的构建，较为耗费 CPU # MySQL 本节期望能够回答以下问题：\nMySQL 是否一定是 B+ 树的存储结构。 InnoDB 为何选择 B+ 树数据结构。 一个 InnoDB 实例支持多少条数据记录。 InnoDB 中索引（含主键）都存储在哪里。 # 2.1 简述 MySQL 是最经典的存储系统了，作为关系型数据库中当之无愧的主流，很难找出一个后端的系统（非某个单独的服务）在运行时可以完全不使用 MySQL（笔者工作的这些年还没有遇到过）。通常认为 MySQL 是行数据库，这通常是指 InnoDB 存储引擎是行数据库。需要注意的是，MySQL 同样是有列数据库引擎1。\n# 2.2 InnoDB MySQL 支持诸多的存储引擎，一般会使用 InnoDB2（当然也支持 MyISAM，CSV，内存等方式的存储引擎）。本文中对 MySQL 的介绍也默认以 InnoDB 作为存储引擎。从分类上来看，MySQL 是典型的关系型数据库了：它的所有数据检索、查询等操作都是以关系组织操作为核心的。在此基础上有诸如外键、多表联查等操作。关系型数据库也是比较贴合实际的各种数据关系并且易于理解的，很多数据库课程中往往会通过构建一个图书管理系统的方式来学习 MySQL，这里书籍种类标签、各种借阅的关系描述也是关系型数据库所擅长的。\nInnoDB 引擎默认使用 B+ 树来存储数据3：将索引存储在内存中而将实际的数据存储在磁盘中，而且由于 B+ 树的特点，使得任意记录所在的页均可通过有限次的检索动作来定位到，并加载到内存中做进一步的检索。这一点较好的兼容了数据的查询性能及数据的存储容量。实际的记录会存放在数据页中（一般在磁盘中）。而索引页一般会在 MySQL 进程启动后加载到内存中。值的注意的是，MySQL 实例启动后，可以支持多种通信方式：TCP 连接、管道｜共享内存（需要指定参数）、UNIX 套接字等。\nInnoDB 引擎中，明确声明为主键的字段（或者在没有明确生命为主键的情况下，第一个被声明为索引的字段）会存储在聚集索引表中（B+树）。而非主键的索引则存储在辅助索引表中（同样为 B+ 树）。不同的是，与聚集索引表中会存储数据页的地址不同，辅助索引表中存储的是目标数据的聚集索引信息，即主键信息。当使用非主键索引查询数据时，需要先从辅助索引表中检索出主键的值，再到聚集索引中检索出实际数据页的内容并加载到内存中。在硬盘足够大的情况下，B+ 树中索引的设计决定了单个 InnoDB 实例能够存储多少数据4。需要注意的是， B+ 树并不是二叉树，父节点可能会有很多子节点。限制内存非叶节点中能够存储索引条数的因素包括索引字段的大小、InnoDB 自身的叶结构等。从理论上看，单个 InnoDB 实例能存储多少数据取决于单个 B+ 树能存储多少数据。\n# 2.3 待确认 一条记录的写入、同步、查询的过程。 # Elasticsearch 本节期望能够回答以下问题：\nES 的数据存储方式。 ES 的数据同步方式。 ES 的数据存储、查询过程。 # 3.1 简述 Elasticsearch，ES，也是经典的存储了，其本身基于 Lucene 进行构建。ES 强大的全文索引能力使得其经常运用在很多检索的场景中，比如视频网站或者简单的文档检索就可以直接使用 ES，从这一点看，预期说 ES 是存储系统，不如说 ES 是检索系统。因为其强大的检索能力，以 ES 为基础的 ELK 生态系统也是日志存储中可以开箱即用的解决方案。\n# 3.2 系统组成 ES 对外通过 index 提供查询能力，index 又可以通过设置 shard 数目来达到横向扩展的能力。当一个 ES 集群的读写压力很大时，可以通过调大 shard 数来使得单个 shard 的读写压力更小。当然，如果每个 node 节点启动了很多的 shard，比如已经到了机器的性能极限，此时即使扩充 shard，物理机的限制也会使得 ES 的查询效果有优化效果。除了横向扩展，ES 还通过 Replicas 备份的方式来实现容灾备份的效果。当 index 中的某个 shard 出现异常时，可以切换到备份的分片中5。值的注意的是，index 中包含了正倒排的索引，而基础数据仍然是基于 JSON 的展示结构6。\n# 3.3 数据处理过程 数据的写入动作会由 Coordinate Node 来处理，该 Node 可能是集群中的任一 Node。而后会依据文档 ID 来路由到对应的 shard 组（包含其备份）中的一个 node1 上。node1 在处理完成本节点的操作后，会将请求并行发送到其他副本中，在确认其他副本写入完成后，会将写成功的结果发送回去（可以通过参数控制，满足了 C）7。\n数据在检索时，同样会将请求发送到 Coordinating Node，并在该 Node 上进行分词等操作。而后将分词结果发送到所有的 shard 上去检索 doc 的排序字段。排序字段检索结果依旧会汇聚到该 Node 上，排序后找到所需要的 doc id 并到该 doc 的 shard 上取获取实际的 doc，返回给 Client8。\n# 3.4 待确认 完整的架构图。 完整的数据处理流程。 # ClickHouse 本节期望能够回答以下问题：\nCK 的数据存储方式，横向扩展方式。 CK 的数据同步方式。 CK 的数据存储、查询过程。 # 4.1 简述 ClickHouse 是近几年比较火的列式存储数据库。其与行式存储的区别可以认为是：列式存储是以列为单位的存储。当一行中往往仅需要读取少数几个列的情况下，列存储能够获得更好的读取效果。而且，由于每列的数据往往是相同的类型，按照列进行存储可以更方便的进行压缩。这样的特性使得列存储在 OLAP 的场景下可以获得更好的检索效果及更好的资源利用率9。\n# 4.2 系统组成 CK 同样有诸多的表引擎，使用比较广泛的是 MergeTree。一般来说，每个 Table 可以按照多个 Partition 来进行划分。\n集群部署时，一般使用 ZooKeeper 来维护集群的关系，启动多个节点并按照节点的角色划分来实现主备及横向扩展。\n# 4.3 待确认 CK 数据同步方式。 CK 数据处理过程。 # 后记 存储是一个很广大的领域。仅本文中设计到的 MySQL、ES、CK 这三种典型的存储系统就消耗了笔者两天的时间来准备文档，而且涉及的内容还很浅。而本文中未涉及到的 Druid、HDFS、Redis、RocksDB、Cassandra 等涉及的存储内容更多。感觉笔者一时怕是无法有效的整理完成。本次且这样吧。\n在本次整理的过程中，笔者同样感觉到资料的缺失：MySQL 的文档及图书资料较为丰富，到后面的 ES、CK 等就开始缺少内容了。希望笔者能够贡献若干篇有深度的文章。\nhttps://www.cnblogs.com/dhName/p/14233938.html。mysql 的存储引擎和 infobright 引擎说明。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://dev.mysql.com/doc/refman/8.4/en/innodb-introduction.html。InnoDB introduction。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://medium.com/@relieved_gold_mole_613/why-does-mysql-use-b-trees-7807ed3090bc。 why does mysql use b+ tree。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://cloud.tencent.com/developer/article/2123136。单表最大 2000 万行数据。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://zhuanlan.zhihu.com/p/32990496。从 Elasticsearch 来看分布式架构系统设计。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.knowi.com/blog/what-is-elastic-search/。what is elastic search。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.cnblogs.com/jimoer/p/15573952.html。ES 写入数据的过程是怎样的？以及是如何快速更新索引数据的？\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.cnblogs.com/liuzhihang/p/elasticsearch-4.html。ES 查询检索数据的过程。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nhttps://www.cnblogs.com/ya-qiang/p/13680283.html。ClickHouse 的特性。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-10-02T14:11:34+08:00","permalink":"https://liyan-ah.github.io/p/%E5%AD%98%E5%82%A8%E6%A6%82%E8%BF%B0/","title":"存储概述"},{"content":" “所有的公司都拥有测试环境。但只有那些幸运的公司拥有独立于测试环境的生产环境。” —— @FearlessSon\n和大多数其他的现代编程语言一样，Rust 也包含一些便于编写测试的特性。借助这些特性，你可以将单测和代码共存。而通过测试，可以提升代码运行准确性的信心。\n这并非是兜售测试重要性的文章。从测试最基本功能来说，如果代码缺少了测试，它很可能并非如我们所希望的那样运行。本条目是在你已经建立了为代码编写测试这一信念的基础上展开的。\n单元测试（unit tests）以及集成测试（integration tests）是测试领域内的两大重要成员。在接下来的两节内将会介绍。但是，Rust 工具链，也包括它的扩展，允许多种多样的测试形式。本条目将会介绍它们的基本使用流程及应用场景。\n# 单元测试 Rust 代码中最常见的测试类型是单元测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // ... (code defining `nat_subtract*` functions for natural // number subtraction) #[cfg(test)] mod tests { use super::*; #[test] fn test_nat_subtract() { assert_eq!(nat_subtract(4, 3).unwrap(), 1); assert_eq!(nat_subtract(4, 5), None); } #[should_panic] #[test] fn test_something_that_panics() { nat_subtract_unchecked(4, 5); } } 这段单测示例体现了 Rust 所有单测都会有的形式：\n使用模块对单测函数进行封装。 每个单测都会使用#[test]属性来进行标志。 用来测试的模块使用#[cfg(test)]进行声明，所以单测的代码仅会在测试时生效。 示例也展示了一些仅在特定测试中才会出现的形式：\n这里的测试代码放置在单独的模块里，模块名一般为tests或者test。这个模块可以和逻辑代码放置在一起，或者放置在单独的tests.rs文件里。放置在单独的文件里可以让人更加便捷的区分代码是用来测试的，还是用于一般的功能逻辑。 测试的模块可以使用一个通配符use super::*来将父模块的所有依赖都声明到测试模块里。这种操作可以让编写测试代码更加方便（同时依据第 23 条来说，通配符的引入是一种要规避的操作）。 在模块的一般可达性规则下，单测可以使用所有父模块里包含的内容，无论是否声明为公共的。基于单测对内部功能可访问的特点，可以对代码进行“开箱”测试。 测试代码使用expect()或者unwrap()来标志其希望的结果。显然，第 18 条中声明的规则并不适用这些单测的代码。单测中需要使用panic!来标注失败的结果。同样的，测试的代码中也会使用assert_eq!来校验期待的值，并且会在失败时抛出panic。 测试代码中使用了一个函数，该函数在一些非法的输入下会造成panic。为了校验该函数的这一功能是否生效，单测的函数中使用了#[should_panic]特性。这一特性在需要测试一个内部函数且希望保持这个函数的各校验规则不发生改变，或者测试一个公共的函数且由于一些原因需要忽略第 18 条中的建议。（这样的函数需要在它的注释文档中有“Panics”小节，就像第 27 条中描述的。） 第 27 条中建议不要对已经通过类型表述出的内容。同样的，也不需要对已经由类型进行约束的内容进行测试。如果你的enum类型派生出了不在声明列表中罗列的变量，你可能遇到了比单测失败更加严重的问题。\n然而，如果你的代码依赖了一些依赖库中的独特功能，对这些功能准备基础的单测会很有用。这里的单测目的并非是重复依赖中已经具备的功能测试，而是尽量早地暴露依赖的包依赖的这些功能发生了变更的风险 —— 尤其是公共的接口约定发生了变化，通常应当通过版本号来表明（第 21 条）。\n# 集成测试 Rust 项目中另一种常用到的测试模式是：集成测试（integration tests），测试通常被放置在tests/目录下。这个目录下的每个文件都会作为一个单独的测试程序运行，每个测试程序都会执行其包含的所有以#[test]标志的测试函数。\n集成测试没有访问包内部内容的权限，因此集成测试仅能覆盖包的公共 API。\n# 文档测试 第 27 条描述了在注释中包含一小段代码的示例，通常是为了说明特定的公共 API 的使用方式。每段这样的代码都包含在一个隐式的fn main() { ... }函数中，并且可以在cargo test时被执行。这是一种高效的代码添加测试用例的方法，一般被称为文档测试（doc tests）。每个类似的测试都可以通过cargo test --doc \u0026lt;item-name\u0026gt;的方式来选择性的执行。\n定期的通过 CI 系统（第 32 条）来执行这些测试可以确保代码不会离包中期望提供的 API 太远。\n# 代码示例 第 27 条也描述了为公共接口提供示例代码的实践。在examples/目录下的每个 Rust 文件（或者examples目录下每个子目录中的main.rs文件）都可以通过cargo run --example \u0026lt;name\u0026gt;或者cargo test --example \u0026lt;name\u0026gt;的方式来作为独立的可执行文件运行。\n这些程序仅能访问包中的公共接口，并且可以说明这些公共接口的使用方式。示例代码并非被设计为测试代码（没有#[test]，没有[cfg(test)]的标注），而且由于处于一些不起眼的角落，它们并不适合放置代码 —— 尤其是，它们并不在cargo test时默认执行。\n尽管如此，CI 系统（第 32 条）构建并且运行这些示例代码（通过cargo test --examples）仍然是一个很好的实践。通过执行这些代码，可以为那些会影响大多数用户的接口提供一个很好的回归校验机制。特别地，如果你的示例揭示了接口使用的一般方式，那么示例运行的失败往往意味着存在如下的错误：\n如果这是个高超的错误，它可能会影响很多用户 —— 示例中的代码将会被很多用户复制、粘贴或者参照。 如果公共接口发生了变更，那么这些示例也需要参照最新的接口定义来实现。接口的改变往往意味着不兼容。所以当包被发布时，版本号需要随着调整以说明这是个不兼容的升级（第 21 条）。 用户复制、粘贴测试代码的行为意味着示例代码和测试代码的形式有很大的不同。如第 18 条中描述的一样，你可以避免对 Results 进行 unwrap() 使用，从而为用户提供一个很好的参照。同样的，在每个示例代码的main()函数中返回类似Result\u0026lt;(), Box\u0026lt;dyn Error\u0026gt;\u0026gt;的结果，并且在内部使用?符号来组织代码（第 3 条）也是一种很好的行为。\n# 基准测试 [第 20 条]试图说明极致的代码性能优化并非总是必要的。尽管如此，有时性能肯定时很关键的，并且在这种情况下，衡量以及追踪代码的性能变化是很好的实践。具备定期运行的基准测试（benchmarks）（比如，作为 CI 系统的一部分，第 32 条）允许你发觉代码或者工具链的变更可以如何影响代码的性能。\n[cargo bench]命令可以运行重复执行特定操作的测试代码，并且计算出这个操作的平均耗时。在撰写本文时，Rust 对基准测试的支持还不太稳定，所以基准测试相关的指令需要通过cargo +nightly bench的方式来执行。（Rust 不稳定的特性，包括本文中使用的test特性，都描述在 Rust Unstable Book中。）\n然而，这里存在着编译器给出错误结果的风险，尤其是当你将操作约束在很简单的代码时。考虑如下一个简单的算数函数：\n1 2 3 4 5 6 pub fn factorial(n: u128) -\u0026gt; u128 { match n { 0 =\u0026gt; 1, n =\u0026gt; n * factorial(n - 1), } } 这段代码的一个简单的基准测试实现是：\n1 2 3 4 5 6 7 8 9 10 #![feature(test)] extern crate test; #[bench] fn bench_factorial(b: \u0026amp;mut test::Bencher) { b.iter(|| { let result = factorial(15); assert_eq!(result, 1_307_674_368_000); }); } 输出了一段奇妙的结果：\n1 test bench_factorial ... bench: 0 ns/iter (+/- 0) 由于在测试过程中使用固定的输入以及很少的代码指令，编译器可能会对迭代进行优化并且直接输出计算结果。这就将会导致不切实际的测试结论。\n使用 std::hint::black_box 可以解决这一问题。这是一个标志函数，编辑器识别后将不对其进行优化。\n上述基准测试可以变更为如下形式：\n1 2 3 4 5 6 7 #[bench] fn bench_factorial(b: \u0026amp;mut test::Bencher) { b.iter(|| { let result = factorial(std::hint::black_box(15)); assert_eq!(result, 1_307_674_368_000); }); } 给出了如下更加接近实际的结果：\n1 test blackboxed::bench_factorial ... bench: 16 ns/iter (+/- 3) Godbolt 编辑资源管理器也可以通过展示实际的机器码的方式来辅助测试，这样就能让实际执行的优化后的字节码变得清晰以确认是否过度优化而不能得到实际的结果。\n最后，如果你为 Rust 代码准备了基准测试，criterion包可能提供了test::bench::Bencher的替代品，而且使用起来更加便捷（可以在稳定的 Rust 工具链上运行），功能也更多（支持结果的数据统计及图表）。\n# 模糊测试 模糊测试（fuzzy testing）是将代码暴露在随机输入中以期能够发现错误，尤其导致异常的场景，的测试方法。从技术校验的角度来说它已经很重要了，而当你的输入会被其他人填充或者攻击时，它将会显得更加重要 —— 所以如果你的代码输入可能暴露给潜在的攻击者时，你应当使用模糊测试。\n从历史上来看，C/C++ 代码通过模糊测试发现的往往时内存安全问题，通常会通过结合模糊测试与内存访问模式的运行时结合来检测（比如AddressSanitizer或者ThreadSanitizer）。\nRust 对其中的一些（但并非全部）内存安全问题免疫，尤其是未引入unsafe的代码时（第 16 条）。然而，Rust 并不能杜绝全部的错误，触发panic!（第 18 条）的代码仍可能引发导致拒绝服务攻击（denial-of-service，DOS）。\n模糊测试的最佳实践是以覆盖率引导：测试的基础设施监控代码的哪些部分被执行，随机更改输入直至能够触发新的代码路径。“American fuzzy lop”（AFL）是其中的佼佼者。但是近些年来，类似的功能已经被引入了 LLVM 的工具链，比如libFuzzer。\nRust 编译器是在 LLVM 的基础上构建的，因此cargo-fuzz自然地为 Rust 引入了libFuzzer（仅在部分平台上可用）。\n模糊测试的首要要求是确定代码的入口点，该入口点需要采用（或者可以适应）任意字节的数据作为输入：\n1 2 3 4 5 6 7 8 9 10 11 12 13 /// Determine if the input starts with \u0026#34;FUZZ\u0026#34;. pub fn is_fuzz(data: \u0026amp;[u8]) -\u0026gt; bool { if data.len() \u0026gt;= 3 /* oops */ \u0026amp;\u0026amp; data[0] == b\u0026#39;F\u0026#39; \u0026amp;\u0026amp; data[1] == b\u0026#39;U\u0026#39; \u0026amp;\u0026amp; data[2] == b\u0026#39;Z\u0026#39; \u0026amp;\u0026amp; data[3] == b\u0026#39;Z\u0026#39; { true } else { false } } 当目标入口点确定后，Rust Fuzz Book给出了如何启动测试的说明。它的核心是一个小型的驱动程序，会将目标入口点连接到模糊测试的基础设施上：\n1 2 3 4 5 6 7 // fuzz/fuzz_targets/target1.rs file #![no_main] use libfuzzer_sys::fuzz_target; fuzz_target!(|data: \u0026amp;[u8]| { let _ = somecrate::is_fuzz(data); }); 运行cargo +nightly fuzz run target1将会持续使用随机数据来执行模糊测试的目标函数，直至异常出现。上述示例中，错误将被立即发现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 INFO: Running with entropic power schedule (0xFF, 100). INFO: Seed: 1607525774 INFO: Loaded 1 modules: 1624 [0x108219fa0, 0x10821a5f8), INFO: Loaded 1 PC tables (1624 PCs): 1624 [0x10821a5f8,0x108220b78), INFO: 9 files found in fuzz/corpus/target1 INFO: seed corpus: files: 9 min: 1b max: 8b total: 46b rss: 38Mb #10\tINITED cov: 26 ft: 26 corp: 6/22b exec/s: 0 rss: 39Mb thread panicked at \u0026#39;index out of bounds: the len is 3 but the index is 3\u0026#39;, testing/src/lib.rs:77:12 stack backtrace: 0: rust_begin_unwind at /rustc/f77bfb7336f2/library/std/src/panicking.rs:579:5 1: core::panicking::panic_fmt at /rustc/f77bfb7336f2/library/core/src/panicking.rs:64:14 2: core::panicking::panic_bounds_check at /rustc/f77bfb7336f2/library/core/src/panicking.rs:159:5 3: somecrate::is_fuzz 4: _rust_fuzzer_test_input 5: ___rust_try 6: _LLVMFuzzerTestOneInput 7: __ZN6fuzzer6Fuzzer15ExecuteCallbackEPKhm 8: __ZN6fuzzer6Fuzzer6RunOneEPKhmbPNS_9InputInfoEbPb 9: __ZN6fuzzer6Fuzzer16MutateAndTestOneEv 10: __ZN6fuzzer6Fuzzer4LoopERNSt3__16vectorINS_9SizedFileENS_ 16fuzzer_allocatorIS3_EEEE 11: __ZN6fuzzer12FuzzerDriverEPiPPPcPFiPKhmE 12: _main 导致上述错误的测试数据也给出了。\n一般来说，模糊测试并不能如此快地发现错误，因此将模糊测试作为 CI 流程中的一部分也是没有意义的。模糊测试的不确定性及随之而来的计算成本意味着你需要考虑如何开展以及何时开展模糊测试 —— 可能仅需要在新的发布版本或者主要变更发生时才运行，或者仅运行确定性的时间1。\n你也可以通过存储和重用先前模糊测试程序已找到用来触发新的代码路径的语料库的方式来加速模糊测试的执行。这将有助于后续的模糊测试过程将时间放在尝试新的输入上，而非重新测试以前访问过的代码路径。\n# 测试的建议 一般性的建议也适用于 Rust 项目中：\n由于测试是需要持续进行的，每次变更后都需要在 CI 中执行单测（除了模糊测试）。 当你在修复一个错误时，在修复前，准备一个能反映错误的测试用例。这样当你完成错误的修复时，就可以通过测试用例的执行来说名修复效果。并且在未来不会重新引入。 如果你的包中包含了某些功能（[第 26 条]），对所有可能的功能组合都要进行测试。 更一般性的，如果你的包中包含了任何特殊的配置，（比如，#[cfg(target_os=\u0026quot;windows\u0026quot;)]），每种包含了独特配置的平台上的测试都需要运行。 这些建议包含了很多不同类型的测试，在项目中应当选择那些最有价值的测试。\n如果你有很多测试的代码并且会将你的包推送到crates.io中，那么就需要考虑下哪些测试项发布后是有意义的。一般地，cargo项目中会包含单元测试、集成测试、基准测试以及代码示例（但是并没有包含模糊测试，因为cargo-fuzz工具会将模糊测试的内容放置在包的子目录中）等等远超一般用户使用所需要的测试项。如果某些测试项并非是必须的，你可以移除一些测试项或者将这些测试项（尤其是行为性的测试）移入单独的测试包中。\n# 需要注意的点 编写单元测试来达到全面测试的目的，包括仅包含内部代码的测试。通过cargo test来运行它们。 编写集成测试代码来测试公共的接口。通过cargo test来运行它们。 编写文档测试来校验公共接口的调用方式。通过cargo test来调用它们。 编写示例代码来完整的说明如何使用包中的公共 API。通过cargo test --exmaples或者cargo run --example \u0026lt;name\u0026gt;的方式来运行它们。 如果代码对性能有很明确的要求，编写基准测试来确认代码的性能表现。通过cargo bench来执行它们。 如果代码会暴露在未被信任的输入中，编写模糊测试来确认对输入的参数的约束。通过cargo fuzz来（持续地）运行它们。 # 注释 原文点这里查看\n如果你的代码是一个被广泛运用的开源包，Google OSS-Fuzz program可以为你的项目进行模糊测试。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-09-08T16:35:05+08:00","permalink":"https://liyan-ah.github.io/p/%E8%AF%91%E6%96%87/effective-rust%E7%AC%AC-30-%E6%9D%A1%E4%B8%8D%E4%BB%85%E4%BB%85%E6%98%AF%E5%8D%95%E6%B5%8B/","title":"【译文/effective-rust】第 30 条：不仅仅是单测"},{"content":" “看起来你在写信。需要什么帮助么？” —— Microsoft Clippit\n第 31 条会描述了 Rust 工具箱中一些很有用的工具。但是其中一个特别有用且重要的工具值的在这里进行进行单独的介绍：Clippy。\nClippy 是 Cargo 的一个附加模块（通过cargo clippy的方式调用）。它可以生成涵盖多种类别的warining信息：\n正确性：提示常见的编程错误。 风格：提示不完全符合 Rust 标准风格的代码结构。 简洁性：指出能让代码更加简洁的可行变更。 性能：提示能避免无效处理或者内存分配的可选项。 可读性：给出能让代码更易读或者更易懂的建议。 比如，如下这段代码编译是正常的：\n1 2 3 4 pub fn circle_area(radius: f64) -\u0026gt; f64 { let pi = 3.14; pi * radius * radius } 但是 Clippy 会指出这里对 π 的近似赋值是没必要且不准确的：\n1 2 3 4 5 6 7 8 9 10 error: approximate value of `f{32, 64}::consts::PI` found --\u0026gt; src/main.rs:5:18 | 5 | let pi = 3.14; | ^^^^ | = help: consider using the constant directly = help: for further information visit https://rust-lang.github.io/rust-clippy/master/index.html#approx_constant = note: `#[deny(clippy::approx_constant)]` on by default 链接中的文档解释了问题并且给出了优化代码的方式。上述示例可调整为：\n1 2 3 pub fn circle_area(radius: f64) -\u0026gt; f64 { std::f64::consts::PI * radius * radius } 正如示例中所展示的，每个 Clippy 警告都会伴随着一个网页的链接来描述问题。链接的网页中会说明为什么目标代码会被认为是不恰当的。这些说明很重要：它们的存在使得你可以自行判断采纳这些建议或者由于特殊的原因而忽略它们。有的时候，说明文本中还会描述一些校验器的已知问题，这些描述会解释一些令人困惑的误报。\n如果你认定一些警告信息和自己的代码没有关系，你可以通过添加(#[allow(clippy::some_line)])来忽略关联代码的报错，或者在包的顶层（top level）添加(#![allow(clipy::some_lint)])来忽略整个包中的警告信息。通常情况下，建议调整目标代码而非花费很多时间来确认警告关联的代码是否是一个罕见的误报。\n无论你选择了修复或者忽略掉这些警告信息，请确保你的代码中没有 Clippy-warning 的信息。\n这样，当新的警告信息出现时 —— 无论是由于代码发生了调整还是 Clippy 升级后包含了新的校验信息 —— 我们就能够及时的关注到。Clippy 也应当被纳入你的持续集成系统中（第 32 条）。\nClippy 的警告信息在你学习 Rust 时特别重要，因为它们可以揭示那些被你忽略的细节，并帮助你熟悉 Rust 的风格。\n本书中提到的很多建议，在 Clippy 中均存在相关的警告信息：\n第 1 条建议使用更具表现力的类型，而非一般的bool类型。Clippy 也指出了在函数参数以及结构体中使用多个bool类型的问题。 第 3 条包括了一些Option及Result类型的操作。Clippy 指出了一些可行的精简行为，比如： Unnecessarily converting Result to Option。 Opportunities to use unwrap_or_default。 第 3 条同样建议了应当将错误返回给调用方。Clippy [指出了应当返回的地方]。 第 5 条应当实现From特征而非Into。 第 5 条还描述了一些强制转换，而 Clippy 给出了如下的警告（对应的检查项默认是关掉的）： as casts that could be from instead。 as casts that might truncate。 as casts that might wrap。 as casts that lose precision。 as casts that might convert signed negative numbers to large positive numbers。 any use of as。 第 8 条描述了胖指针类型，并且很多 Clippy 的校验器指出了一些非必要的额外的指针间接访问： Holding a heap-allocated collection in a Box。 Holding a heap-allocated collection of Box items。 Taking a reference to a Box。 第 9 条描述了操作Iterator实例的诸多方法。Clippy 包含了诸多的可以简化迭代器方法使用的校验器1。 第 10 条描述了 Rust 的标准特性，并且包含了很多 Clippy 会校验到的实现时的要求： Ord must agree with PartialOrd。 PartialEq::ne should not need a nondefault implementation（参照 第 13 条）。 Hash and Eq must be consistent。 Clone for Copy types should match。 第 18 条提供了一些关于减少panic!或类似expect的方法，这些建议也会在 Clippy 的校验器中检查到。 第 21 条表述了引入通过通配符限定的包是不明智的。Clippy 同样对此进行了校验。 第 23 条及第 25 条涉及到一种不同版本的包出现在同一个项目的依赖中。Clippy 可以通过配置，在问题出现时给出警告信息。 第 26 条叙述了 Cargo 特性的一些相加性，而 Clippy 会将与此原则相违背特性提示为“否定”的特性。 第 26 条同样表述了一个包的可选依赖项同样是其特征集的一部分。如果存在需要明确的特性名（如：\u0026ldquo;use-crate-x\u0026quot;形式的命名）时，Clippy 将会提示直接应当使用明确的特性名，而非模糊的。 第 27 条描述了文档注释的约束，Clippy 同时有如下的提示： Missing descriptions of panic!s。 Missing descriptions of unsafe concerns。 上述的信息无疑说明了阅读 Clippy 的警告信息列表同样是一种有意义的学习方式 —— 包括那些默认被关掉校验的原因，是由于它们太严苛了还是由于它们会产生虚警？尽管你可能并不希望代码中出现这么多的警告信息，领悟这些校验规则出现的原因将会提升你对 Rust 及其风格的理解。\n# 注释 原文点这里查看\n部分校验器列举如下。explicit_counter_loop，explicit_iter_loop，explicit_into_iter_loop，filter_map_identity，from_iter_instead_of_collect，into_iter_on_ref，iter_count，iter_next_loop，iter_not_returning_iterator，manual_filter_map，manual_find_map，map_clone，needless_range_loop，search_is_some，skip_while_next，suspicious_map，unnecessary_filter_map，unnecessary_fold。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-09-08T16:30:36+08:00","permalink":"https://liyan-ah.github.io/p/%E8%AF%91%E6%96%87/effective-rust%E7%AC%AC-29-%E6%9D%A1%E9%81%B5%E5%BE%AA-clippy-%E7%9A%84%E5%BB%BA%E8%AE%AE/","title":"【译文/effective-rust】第 29 条：遵循 Clippy 的建议"},{"content":" 原文由笔者翻译并提交至 [rustx-labs/effective-rust-cn/item28]，同步转载到此处。最近一直在搞翻译了，从中看到了很多自己的不足。比如本文关于宏的内容，实际上还有很多没有弄明白的。过了这段时间再看看是否能整理下。\n“在一些场景下，我们会很容易来决定应该使用宏（macro）而非函数（function），因为只有宏才能满足我们的需求。” - Paul Graham，“On Lisp (Prentice Hall)”\nRust 的宏能够让你实现元编程（metaprogramming）：在项目中使用代码来生成代码。这一特性在需要编写很多确定性、重复性都很强的“样板代码”时会很有用，不借助宏的话我们就只能手动维护这些代码了。\n程序员接触 Rust 之前可能已经预先了解了 C/C++ 中通过预处理（preprocessor）来实现的宏，这种方式是在预处理阶段通过文本替换来展开宏定义。而 Rust 的宏则有一些不同，它是在符号流（parsed tokens of the program）或者在抽象语法树（abstract syntax tree, AST）的基础上实现的宏，而非在文本处理阶段。\n这就意味着 Rust 的宏是能够理解代码结构并且规避掉一系列的文本替换方式实现的宏所存在的意外情况。比如说，在接下来的内容中，我们可以看到 Rust 所声明的宏是卫生的 —— 在宏里不会意外引用（或者捕获）宏所嵌入代码中的变量信息。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 /* 这段内容较为晦涩。引用一段维基百科上的内容来说明文本替换方式实现的宏所带来的问题。*/ #define INCI(i) { int a=0; ++i; } int main(void) { int a = 4, b = 8; INCI(a); INCI(b); printf(\u0026#34;a is now %d, b is now %d\\n\u0026#34;, a, b); return 0; } /* 以上代码中的 INCI 宏期望分别对 a, b 进行加一操作。文本替换后的结果如下所示。*/ int main(void) { int a = 4, b = 8; { int a = 0; ++a; }; // 注意这里对 a 进行了重新声明，实际上是对声明的这个 a 进行了自增。 { int a = 0; ++b; }; printf(\u0026#34;a is now %d, b is now %d\\n\u0026#34;, a, b); return 0; } /* 最终的结果会输出如下。 * * a is now 4, b is now 9 * * 这显然是不符合预期的。产生这一结果的原因是由于文本替换过于粗暴，而无法进行实际语意上的理解。 * * 本注释内容为译者添加。 */ 一种理解宏的方法是将其视为代码的不同抽象方式。函数也是代码的一种简单抽象：它将同一类型的不同值的不同抽象出来，实现了针对这一类型，而非特定的值，会做的操作及方法。而宏中的生成则是另外一个层面的抽象：宏是对符合同一特性的不同类型进行抽象，使用针对这些不同类型所具备的相同特性，而非特性的类型，进行代码的实现。\n宏可以对不同程序中扮演相同角色（类型、标记、表达式等）的代码抽象出来，然后这些程序就可以以同一种方式来使用抽象出的逻辑。\nRust 提供了两种方式来定义宏：\n声明宏，也被成为“示例宏”。声明宏允许将输入到宏中任意的 Rust 程序，基于抽象语法树中的结果，集成到代码中。 过程宏。过程宏同样可以将任意的 Rust 程序集成到代码中，不过是基于源码中的解析符号。derive宏就是常见的过程宏。derive宏可以基于代码的结构定义来展开代码。 # 声明宏 虽然这篇文章不是为了重复声明宏的内容，但还是有必要来提醒下声明宏中需要关注的内容。\n首先，需要注意的是声明宏的作用域范围和直觉上的理解的是不同的（对比 C 里的预处理宏）。如果一个声明宏在源代码中被定义了，就只有跟在宏里的代码能够使用：\n1 2 3 4 5 6 7 8 9 10 11 12 fn before() { println!(\u0026#34;[before] square {} is {}\u0026#34;, 2, square!(2)); } /// Macro that squares its argument. macro_rules! square { { $e:expr } =\u0026gt; { $e * $e } } fn after() { println!(\u0026#34;[after] square {} is {}\u0026#34;, 2, square!(2)); } 1 2 3 4 5 6 7 error: cannot find macro `square` in this scope --\u0026gt; src/main.rs:4:45 | 4 | println!(\u0026#34;[before] square {} is {}\u0026#34;, 2, square!(2)); | ^^^^^^ | = help: have you added the `#[macro_use]` on the module/import? #[macro_export]特性让宏可以访问更多的数据，但是也存在一些奇怪的事情：尽管宏并没有在模块中定义，它还是出现在了模块的顶层。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 mod submod { #[macro_export] macro_rules! cube { { $e:expr } =\u0026gt; { $e * $e * $e } } } mod user { pub fn use_macro() { // Note: *not* `crate::submod::cube!` let cubed = crate::cube!(3); println!(\u0026#34;cube {} is {}\u0026#34;, 3, cubed); } } Rust 的声明宏是卫生（hygienic）的：宏内部展开的代码无法使用所在作用域的局部变量。比如，宏内部使用了局部变量 x 时：\n1 2 3 4 // Create a macro that assumes the existence of a local `x`. macro_rules! increment_x { {} =\u0026gt; { x += 1; }; } 这样的用法将会造成编译错误：\n1 2 3 let mut x = 2; increment_x!(); println!(\u0026#34;x = {}\u0026#34;, x); 1 2 3 4 5 6 7 8 9 10 error[E0425]: cannot find value `x` in this scope --\u0026gt; src/main.rs:55:13 | 55 | {} =\u0026gt; { x += 1; }; | ^ not found in this scope ... 314 | increment_x!(); | -------------- in this macro invocation | = note: this error originates in the macro `increment_x` 这种“卫生”的特性意味着 Rust 的宏比 C 的基于预处理替换的宏要安全很多。然而，仍有一些需要在使用时注意的内容。\n第一，尽管一个宏看起来很像是函数的声明，它并不是。宏将会在调用的地方进行代码展开，而且可以随着传入参数的不同进行不同形式的展开：\n1 2 3 macro_rules! inc_item { { $x:ident } =\u0026gt; { $x.contents += 1; } } 这就意味着常规意义上的参数被移动（moved）或者 \u0026amp; （被引用）的情形没有发生：\n1 2 3 4 5 6 7 let mut x = Item { contents: 42 }; // type is not `Copy` // Item is *not* moved, despite the (x) syntax, // but the body of the macro *can* modify `x`. inc_item!(x); println!(\u0026#34;x is {x:?}\u0026#34;); 1 x is Item { contents: 43 } 如果我们还记得宏只是在调用它的地方进行展开的话，上述示例就会变得清楚了 —— 在这个示例中，调用宏的地方只相当于添加了一行增加x.contents值的代码。借助cargo-expand可以很清晰地看到编译器将宏进行展开后的代码：\n1 2 3 4 5 let mut x = Item { contents: 42 }; x.contents += 1; { ::std::io::_print(format_args!(\u0026#34;x is {0:?}\\n\u0026#34;, x)); }; 展开的代码中可以看到直接使用了变量本身，而非其引用。（一个有意思的事情是，我们可以看到println!的展开中，依赖了format_args!宏1。）\n所以，宏里的!起到了一个警示的作用：展开的代码可能会对参数做一些任性的事情。\n展开的代码也可能会包含一些在调用代码中无法访问的控制流，可能包括循环、判断、返回值甚至使用?操作符。显然，这里会和[最小惊讶原则]相冲突，所以在使用宏时，应当考虑封装常规的 Rust 语句。（另一方面，如果使用宏的目的是实现一些奇怪的控制流，请确保这些控制流在文档中都给用户提供了！）\n举例来说，考虑这样一个宏（用来校验 HTTP 状态码）包含了一个return语句：\n1 2 3 4 5 6 7 8 /// Check that an HTTP status is successful; exit function if not. macro_rules! check_successful { { $e:expr } =\u0026gt; { if $e.group() != Group::Successful { return Err(MyError(\u0026#34;HTTP operation failed\u0026#34;)); } } } 用这段宏来校验一些 HTTP 行为的代码可能会以一些很晦涩的控制流来结束：\n1 2 3 4 let rc = perform_http_operation(); check_successful!(rc); // may silently exit the function // ... 另一种可以实现上述功能的宏是产生一个Result：\n1 2 3 4 5 6 7 8 9 /// Convert an HTTP status into a `Result\u0026lt;(), MyError\u0026gt;` indicating success. macro_rules! check_success { { $e:expr } =\u0026gt; { match $e.group() { Group::Successful =\u0026gt; Ok(()), _ =\u0026gt; Err(MyError(\u0026#34;HTTP operation failed\u0026#34;)), } } } 而这样依赖，代码就很好理解了：\n1 2 3 4 let rc = perform_http_operation(); check_success!(rc)?; // error flow is visible via `?` // ... 对于声明宏来说，第二件需要注意的事情是和 C 的预编译宏同样的问题：如果宏的参数是一个存在副作用的表达式，当心在宏里多次使用的情况。比如我们在早先定义的square!宏输入了较为随意的表达式来作为参数，然后使用两次，这将会造成奇怪的结果：\n1 2 3 4 5 6 7 let mut x = 1; let y = square!({ x += 1; x }); println!(\u0026#34;x = {x}, y = {y}\u0026#34;); // output: x = 3, y = 6 假设这种行为并非有意的，一种修复的方法是尝试仅执行给定的表达式一次，然后将结果赋值给一个本地的变量：\n1 2 3 4 5 6 7 8 9 macro_rules! square_once { { $e:expr } =\u0026gt; { { let x = $e; x*x // Note: there\u0026#39;s a detail here to be explained later... } } } // output now: x = 2, y = 4 另一种可选的方案是不允许将表达式作为宏的输入。如果将[expr]替换为indent，那么这个宏就仅会接受标志符作为入参，而使用类似任意的表达式将不再能编译通过。\n# 格式化参数 声明宏的一种常见的使用模式将多个值汇聚成一个消息。比如，标准库中的format!用来拼接一个字符串，println!用来输出到标准输出，eprintln!用来输出到标准错误输出。fmt 文档中阐述了format!的语法，和C中的printf使用几乎是相同的。当然，Rust 中的format!参数是类型安全并且会在编译时进行检查的，并且format!宏实现时使用了Display以及Debug特性用来约束宏的参数。Display以及Debug宏的使用参见[第 10 条]2。\n你可以（同时也建议）在项目中的宏中使用相同的格式化语法。比如，一个log库中的logging宏就可以使用和format!相同的语法。在实践中，使用format_args!来实现参数的格式化而不是重复造轮子。\n1 2 3 4 5 6 7 /// Log an error including code location, with `format!`-like arguments. /// Real code would probably use the `log` crate. macro_rules! my_log { { $($arg:tt)+ } =\u0026gt; { eprintln!(\u0026#34;{}:{}: {}\u0026#34;, file!(), line!(), format_args!($($arg)+)); } } 1 2 3 4 5 6 7 let x = 10u8; // Format specifiers: // - `x` says print as hex // - `#` says prefix with \u0026#39;0x\u0026#39; // - `04` says add leading zeroes so width is at least 4 // (this includes the \u0026#39;0x\u0026#39; prefix). my_log!(\u0026#34;x = {:#04x}\u0026#34;, x); 1 src/main.rs:331: x = 0x0a # 过程宏 Rust 也支持了过程宏，也被称为proc macros。和声明宏类似，过程宏能够任意的 Rust 代码插入到程序的源代码中。不同的时，过程宏的输入不再仅限制在特定的传入参数。过程宏可以访问一些源代码中的解析符号（parsed tokens）。这就过程宏一定程度上类似动态语言，比如 Lisp，的非常富有表达力的能力 —— 但是仍然在编译时进行检查。这也帮助缓解了 Rust 中反射的局限，这在第 19 条中讨论了。\n过程宏需要和其被使用的代码定义在不同的包中（并且包需要被声明为proc_macro），并且包中往往需要引入[proc-macro]（官方工具链中提供）或者[proc-macro2]（由 David Tolnay 提供）的依赖，这两个依赖可以宏能够操作输入的符号。\n实际上，有三种不同的过程宏：\n类函数宏（Function-like macros）：通过传入的参数调用。 类属性宏（Attribute macros）：附加到程序中的某些特定语法的代码中。 派生宏（Derive macros）：附加到特定的数据结构中。 # 类函数宏 函数式的宏会通过传递参数来调用，宏的实现中可以访问参数的解析符号（parsed tokens），并且返回任意的符号。注意在先前的表述中，我们使用的是单数的参数， —— 即使函数式的宏调用的时候看起来传入了很多参数：\n1 my_func_macro!(15, x + y, f32::consts::PI); 但是宏本身只接收到了一个解析后的符号流。一个将符号流输出（在编译时）的宏实现示例如下：\n1 2 3 4 5 6 7 8 9 10 11 12 use proc_macro::TokenStream; // Function-like macro that just prints (at compile time) its input stream. #[proc_macro] pub fn my_func_macro(args: TokenStream) -\u0026gt; TokenStream { println!(\u0026#34;Input TokenStream is:\u0026#34;); for tt in args { println!(\u0026#34; {tt:?}\u0026#34;); } // Return an empty token stream to replace the macro invocation with. TokenStream::new() } 其运行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 Input TokenStream is: Literal { kind: Integer, symbol: \u0026#34;15\u0026#34;, suffix: None, span: #0 bytes(10976..10978) } Punct { ch: \u0026#39;,\u0026#39;, spacing: Alone, span: #0 bytes(10978..10979) } Ident { ident: \u0026#34;x\u0026#34;, span: #0 bytes(10980..10981) } Punct { ch: \u0026#39;+\u0026#39;, spacing: Alone, span: #0 bytes(10982..10983) } Ident { ident: \u0026#34;y\u0026#34;, span: #0 bytes(10984..10985) } Punct { ch: \u0026#39;,\u0026#39;, spacing: Alone, span: #0 bytes(10985..10986) } Ident { ident: \u0026#34;f32\u0026#34;, span: #0 bytes(10987..10990) } Punct { ch: \u0026#39;:\u0026#39;, spacing: Joint, span: #0 bytes(10990..10991) } Punct { ch: \u0026#39;:\u0026#39;, spacing: Alone, span: #0 bytes(10991..10992) } Ident { ident: \u0026#34;consts\u0026#34;, span: #0 bytes(10992..10998) } Punct { ch: \u0026#39;:\u0026#39;, spacing: Joint, span: #0 bytes(10998..10999) } Punct { ch: \u0026#39;:\u0026#39;, spacing: Alone, span: #0 bytes(10999..11000) } Ident { ident: \u0026#34;PI\u0026#34;, span: #0 bytes(11000..11002) } 由于输入流涉及到的底层特性式的这段宏在实现时必须要能够解析所传入的参数。比如，宏中分隔那些需要分隔的参数需要使用TokenTree:Punct。syn 包（David Tolnay开发）提供了一个解析的库来辅助这些事情，下一节会进行介绍。\n正因为这些解析的工作，使用声明宏往往比函数式的过程宏要简单，因为声明宏所处理的是匹配所定义的结构。\n这种需要手动处理繁杂的另一面是函数是的宏可以更加灵活的接受那些无法像一般 Rust 代码解析的输入。这种特性并非经常需要的，所以函数式的宏相对较少出现。\n# 类属性宏 类属性宏通过将其放置在程序的一些片段前调用的，而这些片段的解析符号会被传入到宏的内部进行处理。类属性宏也可以将任意的结果作为返回值，但是一般返回值是对输出的一些转换处理。\n比如，下面是一个用来封装函数体的类属性宏：\n1 2 3 4 #[log_invocation] fn add_three(x: u32) -\u0026gt; u32 { x + 3 } 之后，在调用这个被封装的函数时，就会有日志输出：\n1 2 3 let x = 2; let y = add_three(x); println!(\u0026#34;add_three({x}) = {y}\u0026#34;); 1 2 3 log: calling function \u0026#39;add_three\u0026#39; log: called function \u0026#39;add_three\u0026#39; =\u0026gt; 5 add_three(2) = 5 这个宏的实现是极为复杂的，这里并不打算将其细节附上。在实现时，需要校验输入符号的结构以便构建新的输出符号。当然，这一过程仍然可以使用syn包来辅助实现。\n# 派生宏 最后一种过程宏是派生宏。派生宏可以为其修饰的数据（struct, enum 或者 union 均可）自动地生成代码。这一点和类属性宏有些像，但是会多一些派生的操作 —— 请注意理解这里的派生概念。\n首先，派生宏会附加到输入的符号中，而非将其替换。这就意味着原始的数据结构的定义会被保留，而派生宏将在原始数据结构的基础上附加代码。\n其次，派生宏可以用来声明一些辅助性的特征。当数据需要用作一些特殊的处理时，可以使用派生宏来辅助标注。比如，[serde 库]的Deserialize派生宏有一个serde的辅助特性，用户可以使用派生宏来声明这些结构体符合某种特性：\n1 2 3 4 5 6 7 8 9 10 11 fn generate_value() -\u0026gt; String { \u0026#34;unknown\u0026#34;.to_string() } #[derive(Debug, Deserialize)] struct MyData { // If `value` is missing when deserializing, invoke // `generate_value()` to populate the field instead. #[serde(default = \u0026#34;generate_value\u0026#34;)] value: String, } 关于派生宏的最后一个概念是，syn 包可以完成将输入符号解析到相应的语法树的工作。syn::parse_macro_input!宏可以将符号转换成syn::DeriveInput数据结构，这种结构描述被修饰对象的主要内容，并且DeriveInput操作起来远比原始的符号流要好处理。\n特别地，derive宏是所有过程宏中最常使用的宏 —— 这种逐字段或逐变量操作的能力能够让程序员最简单地实现最多的功能 —— 比如，仅通过添加一行类似#[derive(Debug, Clone, PartialEq, Eq)]的代码，即可实现预期的目的。\n由于派生宏的代码插入是自动实现地，这也意味着这些插入的代码可以同时和结构体的实现保持一致。比如，如果你向struct中插入了一个新的字段，如果采用手动实现Debug特征的话，你就需要在插入后对结构体进行更新以使其满足特征的需求。而对于自动插入代码的派生宏来说，你并不需要做任何调整（当然了，如果插入的字段不满足派生宏的实现要求，编译时会报错）。\n# 什么时候使用宏 使用宏的首要原因当然是避免重复的代码 —— 尤其是那些需要人工确保和其他代码关联正确性的重复代码。从这一点来说，使用宏仅是编程常用的封装抽象的扩展：\n如果需要重复一段处理同一类型的不同值的代码，将其封装为一个函数并在所有需要这段逻辑的地方使用它。 如果需要重复一段处理不同类型的代码，构建一个trait并且使用该trait来封装逻辑并在所有满足该特性的要求的地方进行使用。 如果需要重复一段结构相同的代码，将其封装成一个宏并且在所有满足类似结构的代码中进行使用。 举例如下：如果希望规避重复处理不同enum的代码，使用宏即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 enum Multi { Byte(u8), Int(i32), Str(String), } /// Extract copies of all the values of a specific enum variant. #[macro_export] macro_rules! values_of_type { { $values:expr, $variant:ident } =\u0026gt; { { let mut result = Vec::new(); for val in $values { if let Multi::$variant(v) = val { result.push(v.clone()); } } result } } } fn main() { let values = vec![ Multi::Byte(1), Multi::Int(1000), Multi::Str(\u0026#34;a string\u0026#34;.to_string()), Multi::Byte(2), ]; let ints = values_of_type!(\u0026amp;values, Int); println!(\u0026#34;Integer values: {ints:?}\u0026#34;); let bytes = values_of_type!(\u0026amp;values, Byte); println!(\u0026#34;Byte values: {bytes:?}\u0026#34;); // Output: // Integer values: [1000] // Byte values: [1, 2] } 另一个宏的使用场景是，规避同一结构体中的数据被分散在代码的不同区域。\n比如，假设一个结构体封装了 HTTP 的状态码。通过宏可以避免实现这些信息时代码的分散：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 // http.rs module #[derive(Debug, PartialEq, Eq, Clone, Copy)] pub enum Group { Informational, // 1xx Successful, // 2xx Redirection, // 3xx ClientError, // 4xx ServerError, // 5xx } // Information about HTTP response codes. http_codes! { Continue =\u0026gt; (100, Informational, \u0026#34;Continue\u0026#34;), SwitchingProtocols =\u0026gt; (101, Informational, \u0026#34;Switching Protocols\u0026#34;), // ... Ok =\u0026gt; (200, Successful, \u0026#34;Ok\u0026#34;), Created =\u0026gt; (201, Successful, \u0026#34;Created\u0026#34;), // ... } 通过使用宏，可以将每个 HTTP 状态码的所有相关联的信息 —— 数值、元组以及描述信息 —— 都聚集起来，看起来就像是使用一种领域特定语言（domain-specifix language, DSL）来保存数据一样。\n汇聚之后，宏就可以生成代码。每一行类似$( ... )+中的代码都会被扩展成特定的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 macro_rules! http_codes { { $( $name:ident =\u0026gt; ($val:literal, $group:ident, $text:literal), )+ } =\u0026gt; { #[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)] #[repr(i32)] enum Status { $( $name = $val, )+ } impl Status { fn group(\u0026amp;self) -\u0026gt; Group { match self { $( Self::$name =\u0026gt; Group::$group, )+ } } fn text(\u0026amp;self) -\u0026gt; \u0026amp;\u0026#39;static str { match self { $( Self::$name =\u0026gt; $text, )+ } } } impl core::convert::TryFrom\u0026lt;i32\u0026gt; for Status { type Error = (); fn try_from(v: i32) -\u0026gt; Result\u0026lt;Self, Self::Error\u0026gt; { match v { $( $val =\u0026gt; Ok(Self::$name), )+ _ =\u0026gt; Err(()) } } } } } 这样处理后，宏就可以依据输入的参数来派生如下的代码：\n一个enum枚举用来保存所有的数值。 一个group()方法来返回一个 HTTP 状态码的分组归属。 一个text()方法来将状态码映射到对应的文字描述中。 一个TryFrom\u0026lt;i32\u0026gt;的特征实现来将数值转换成enum中的枚举值。 如果需要新增一个状态码，只需要添加这样的一行代码：\n1 ImATeapot =\u0026gt; (418, ClientError, \u0026#34;I\u0026#39;m a teapot\u0026#34;), 如果不使用宏的话，就需要对四部分代码分别更新。编译器可能会有一些提示信息（match表达式需要覆盖所有的场景），但是存在一些遗漏 —— TryFrom\u0026lt;i32 就很容易被遗忘。\n由于宏可以在调用的地方对代码进行展开，所有它们也可以用来自动生成一些提示信息 —— 尤其是，在使用了标准库中的file!()以及line!()宏了之后，可以生成代码的位置信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 macro_rules! log_failure { { $e:expr } =\u0026gt; { { let result = $e; if let Err(err) = \u0026amp;result { eprintln!(\u0026#34;{}:{}: operation \u0026#39;{}\u0026#39; failed: {:?}\u0026#34;, file!(), line!(), stringify!($e), err); } result } } } 当报错出现时，日志文件中就会自动地包含报错内容、位置等细节：\n1 2 3 4 use std::convert::TryInto; let x: Result\u0026lt;u8, _\u0026gt; = log_failure!(512.try_into()); // too big for `u8` let y = log_failure!(std::str::from_utf8(b\u0026#34;\\xc3\\x28\u0026#34;)); // invalid UTF-8 # 宏的缺点 使用宏的最大缺点是引入之后代码的可读性及可维护性。之前在声明宏小结中介绍了宏允许我们创建一个特定的语言来简明地描述代码及数据的关键特性。但是，这也意味着任何阅读这段代码的人将不得不理解这段使用 Rust 实现的特定的语句 —— 而且这还是使用宏来定义的。比如，在http_codes!宏的示例中使用了一个名为Status的 Rust enum，但是在使用的时候并不能察觉到。\n这种使用宏而引入的不可知性远超一般程序员所能带来的影响：很多分析或和 Rust 交互的工具无法理解这样晦涩的代码，因为它不在遵循 Rust 代码交互语法。先前展示的square_once!宏就是一个直观的例子：宏的主体并没有按照rustfmt的规则来格式化：\n1 2 3 4 5 6 { let x = $e; // The `rustfmt` tool doesn\u0026#39;t really cope with code in // macros, so this has not been reformatted to `x * x`. x*x } 另一个例子是已经提到的http_codes!宏，这里使用了Group枚举了诸如Informational的值，而没有使用Group::前缀或use语句。这一点会让代码的补全工具感到混淆。\n甚至编译器本身也无法提供更多的帮助：编译器提供的报错信息没有完全符合宏的定义及使用。当然，还是有一些工具（参照第 31 条）可以辅助宏的使用，比如早先使用的 David Tolnay 的 cargo-expand。\n使用宏也可能会导致代码的膨胀 —— 一个简单的宏调用就可能引入数百行的生成代码，并且在进行代码分析时是无法直观看到的。这在代码第一次编写时可能不会成为问题，因为彼时这些代码是需要的，并且帮助开发者节约了大量的代码编写时间。但是，如果这些代码随后不再需要了，考虑实际生成的数百行代码，仅从数行的宏调用中可能并不能看到将其删除的必要性。\n# 建议 尽管上节我们列举了很多宏的缺点，但是当我们需要合并存在一些存在一致性的代码，但是没有其他可用的方式时，使用宏仍然是完成这样工作的正确工具：当宏是确保不同代码保持一致的唯一方式时，使用它！\n当我们需要合并一些模版化的代码时，宏也是可以使用的工具：使用宏来处理模版代码，当它们无法合并为一个函数或者一个特性时。\n为了降低宏对可读性的影响，请尽量避免在宏中使用和 Rust 的一般语法规则相冲突的语法。要么让宏在调用时和一般的代码表现的一致；要么让宏在调用时和一般的代码完全不同，这样就没有用户会混淆宏和一般的代码。特别地，可以遵循如下的准则：\n尽可能的避免向宏传递参数的引用 —— 类似my_macro!(list)的使用就比my_macro!(\u0026amp;list)要好。 尽量避免在宏中引入非局部的控制流，这样所有阅读这段代码的人都可以在不了解宏的细节的情况下，正确理解上下文中的控制流。 这种倾向于类似 Rust 一般代码的可读性偏好有时会影响声明宏或者过程式宏的选择。如果你需要给一个struct的每一个字段或者enum中的每一个枚举值都生成代码，尽量使用派生宏来处理（暂时忽略在上一节中列举的问题） —— 这样会更加符合语言习惯并且读起来更加简单。\n然而，如果要添加的派生宏并非是项目中所独有的功能，可以检查下外部的库中是否已经提供了所需要的宏（参照第 25 条）。比如，类似将数值类型转换为合适的 C 风格的枚举值的需求：在enumn::N、[num_enum::TryFromPrimitive]、num_derive::FromPrimitive以及strum::FromRepr中都一定程度的实现了这个需求。\n# 注释 原文点这里查看。\n眼神儿好的读者可能已经注意到了format_arg!仍然像是一个宏的调用，尽管它在println!宏的展开代码里。这是因为它是编译器的内建宏。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n在std::fmt 模块中也包含了很多其他展示特定格式数据是会使用的特性。比如，当需要一个 x 格式的特殊说明符来输出小写的十六进制输出时，就会使用LowerHex特性。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-07-29T14:59:31+08:00","permalink":"https://liyan-ah.github.io/p/%E8%AF%91%E6%96%87/effective-rust%E7%AC%AC-28-%E6%9D%A1%E5%9C%A8%E5%90%88%E9%80%82%E7%9A%84%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8%E5%AE%8F/","title":"【译文/effective-rust】第 28 条：在合适的时候使用宏"},{"content":" 原文由笔者翻译并提交至 rustx-labs/effective-rust-cn/item27，同步转载到此处。\n如果你的包（crate）会被其他程序员所使用，那么为包中的内容添加文档就是很好的实践，尤其是包中的公共接口。如果你的包不仅仅是随用随丢的代码，那么这个“其他程序员”就包括未来的你，那个已经忘掉了自己代码细节的你。\n这个建议并不是 Rust 所独有的，它也并不是一个新的建议 —— 比如，Effective Java 第二版（2008年出版）在第 44 条中建议：“为所有导出的 API 元素编写文档注释”。\nRust 文档类型注释的细节 —— 基于 Markdown 格式，以 /// 或者 //! 分割 —— 已经在Rust book中介绍了，如下为示例：\n1 2 3 4 5 /// Calculate the [`BoundingBox`] that exactly encompasses a pair /// of [`BoundingBox`] objects. pub fn union(a: \u0026amp;BoundingBox, b: \u0026amp;BoundingBox) -\u0026gt; BoundingBox { // ... } 然而，关于文档型注释的格式仍有一些值得关注的细节：\n使用代码格式：对于任何作为源代码的注释，使用反引号来确保在最终的文档中代码会以一种等宽字体来展示，并以此来明确的区分code以及一般的文本。 添加丰富的引用内容：为任何能够给读者提供上下文信息的内容添加 Markdown 链接。特别地，可以使用比较方便的 [SomeThing] 格式的交叉引用标注符语法 —— 括号内的Something将会在最终文档中被添加正确的超链接。 多添加示例代码：如果接口应该如何使用并非一目了然的，那么添加一个使用该接口的# Example段落将会很有用。如在文档注释里的示例代码会在你执行cargo test（详情查看第 13 条）时编译并且运行，这一特性将有助于示例代码和它希望表述的代码保持一致。 为panic和unsafe的代码添加说明文档：如果存在会导致函数panic的输入，在文档（# Panics段落）里说明规避panic!的前置条件。同样地，在文档（# Safety段落）里说明unsafe代码的使用要求。 Rust 的标准库是一个能够实践了上述所有细节的优秀示例。\n# 工具 在注释文档中使用 Markdown 格式不仅意味着优美的输出，还意味着需要有一个明确的转换步骤（cargo doc）。而转换也就会增加出现问题的可能性。\n对于这个问题，最简单的建议是在写完文档后，运行cargo doc --open（或者cargo doc --no-deps --open，这个指令能够严格约束仅产生当前包中的文档）并来仔细阅读生成的结果。\n对于所有生成超链接的有效性，你当然可以人工地去校验它们，或者让机器来完成这项工作 —— 通过broken_intra_dock_links的包特性1：\n1 2 3 4 5 6 7 #![deny(broken_intra_doc_links)] /// The bounding box for a [`Polygone`]. #[derive(Clone, Debug)] pub struct BoundingBox { // ... } 当特性生效的时候，cargo doc将会找出无效的链接：\n1 2 3 4 5 6 error: unresolved link to `Polygone` --\u0026gt; docs/src/main.rs:4:30 | 4 | /// The bounding box for a [`Polygone`]. | ^^^^^^^^ no item named `Polygone` in scope | 你也可以设置要求文档化，通过在包里设置![warn(missing_docs)]属性。当设置生效的时候，编译器将会给每个未配置文档的公开条目生成警告信息。然而，这样设置也存在着为了解决编译器报错而提供低质量注释文档的风险 —— 当然设置引入的问题不仅如此。\n同样地，为了能够及时发现潜在风险，这些工具应该被纳入到你的持续集成系统（第 32 条）。\n# 其他的文档位置 cargo doc的输出是包中文档所在的主要位置，但并不是唯一的地方 —— 在项目中的其他地方添加注释也可以帮助用户理解如何使用你的代码。\n在 Cargo 项目的examples/子目录下可以添加一些方便使用包的示例代码。这些代码可以构建并运行，和集成测试（第 30 条）的运行方式非常类似，不同的是这些代码提供的是便于理解包中接口使用的代码。\n需要说明的是，tests/子目录下的集成测试代码也可以给用户提供帮助，虽然它们的主要作用是测试包的对外接口。\n# 发布包的文档 如果你的包会发布到crates.io，项目的文档就可以在docs.rs中查看到。docs.rs 是为发布的包构建并提供文档的官方 Rust 网站。\n注意，crates.io和docs.rs的受众是不同的：crates.io旨在为选择包的用户提供服务，而docs.rs的受众是那些需要弄明白他们已经引用的包该如何使用的人（很明显的，这两种场景有很大的重叠）。\n综上，一个包的主页在不同的地方会展示不同的内容：\ndocs.rs：展示cargo doc产出结果的顶层页面，比如从顶层src/lib.rs文件的//!生成的文档。 crates.io：展示包含在项目仓库中的任何顶层README.md 2文件内容。 # 不文档化的内容 当一个项目要求公共条目都需要添加注释的时候，很容易就陷入到给无价值的内容也文档化的陷阱中。编译器的缺少注释文档的警告只是提醒你添加真正需要内容 —— 有用的文档 —— 的一种表现，并且仅仅期望程序员添加必要的内容来消除警告。\n好的注释文档是一种能够帮助用户了解他们所使用代码的福利；糟糕的注释文档则增加了代码的维护成本并且让用户在它们不再和代码保持一致的时候变得更加困惑。那么好与不好的区别是什么呢？\n最重要的建议是避免重复可以从代码中看出的信息。第 1 条建议你的代码尽量的和 Rust 的类型系统保持一致；一旦你做到了这一点，就通过类型系统来说明这些语意。可以假定使用代码的用户对 Rust 已经熟悉了 —— 可能他们已经读了一些描述了如何高效使用语言的建议 —— 并且不需要重复从代码中的参数类型和函数签名中就能读出来的东西。\n回到之前的例子，一个冗余的注释文档可能如下面描述的这样：\n1 2 3 4 5 6 7 8 /// Return a new [`BoundingBox`] object that exactly encompasses a pair /// of [`BoundingBox`] objects. /// /// Parameters: /// - `a`: an immutable reference to a `BoundingBox` /// - `b`: an immutable reference to a `BoundingBox` /// Returns: new `BoundingBox` object. pub fn union(a: \u0026amp;BoundingBox, b: \u0026amp;BoundingBox) -\u0026gt; BoundingBox { 这个注释重复了很多从函数签名中就能读到的信息，注释信息毫无益处。\n更糟的是，考虑一种代码重构后，将结果存储到其中一个参数（这是一种不兼容的变更；参照第 21 条）。没有编译器或者工具能够发现注释没有随之更新，结果就产生了一个未能和代码逻辑保持一致的注释：\n1 2 3 4 5 6 7 8 /// Return a new [`BoundingBox`] object that exactly encompasses a pair /// of [`BoundingBox`] objects. /// /// Parameters: /// - `a`: an immutable reference to a `BoundingBox` /// - `b`: an immutable reference to a `BoundingBox` /// Returns: new `BoundingBox` object. pub fn union(a: \u0026amp;mut BoundingBox, b: \u0026amp;BoundingBox) { 相反地，原本恰当的注释在重构中则可以毫发无损地保留下来，因为它的文本描述的是行为，而非语意本身：\n1 2 3 /// Calculate the [`BoundingBox`] that exactly encompasses a pair /// of [`BoundingBox`] objects. pub fn union(a: \u0026amp;mut BoundingBox, b: \u0026amp;BoundingBox) { 先前的建议也可以帮助提升文档质量：在文档中包含任何从代码中无法了解的内容。这包含前置条件、可变性、异常、报错条件以及任何可能会让用户感到意外的事情；如果你的代码不能遵守最小惊讶原则，确保这些意外都被记录在文档里，至少你可以说“我已经告诉过你了”。\n另一个常见的失败情形是，注释里描述了其他使用这个方法的代码，而非这个方法做了什么：\n1 2 3 4 5 6 7 8 9 /// Return the intersection of two [`BoundingBox`] objects, returning `None` /// if there is no intersection. The collision detection code in `hits.rs` /// uses this to do an initial check to see whether two objects might overlap, /// before performing the more expensive pixel-by-pixel check in /// `objects_overlap`. pub fn intersection( a: \u0026amp;BoundingBox, b: \u0026amp;BoundingBox, ) -\u0026gt; Option\u0026lt;BoundingBox\u0026gt; { 像这样的注释几乎不可能和代码保持一致：当使用了这个方法的代码（比如，hits.rs）变更的时候，这段描述了调用行为的注释相隔甚远而无法保持一致。\n应当将注释重新组织以聚焦在为什么这样使用，可以让这段注释更好的适应未来的变更。\n1 2 3 4 5 6 7 8 /// Return the intersection of two [`BoundingBox`] objects, returning `None` /// if there is no intersection. Note that intersection of bounding boxes /// is necessary but not sufficient for object collision -- pixel-by-pixel /// checks are still required on overlap. pub fn intersection( a: \u0026amp;BoundingBox, b: \u0026amp;BoundingBox, ) -\u0026gt; Option\u0026lt;BoundingBox\u0026gt; { 当编写软件时，“面向未来的编程”3是一种很好的实践：调整代码结构以适应未来的变更。同样的原则也适用于文档：聚焦在语意，为什么这样做以及为什么不这样做，会让文本在未来的运行中始终是有意义的。\n# 总结 给公共的 API 内容添加注释文档。 为那些从代码中无法明确看出的内容添加描述 —— 比如panics以及unsafe的条件。 不要给可以从代码中明确看出的内容重复描述。 通过交叉引用及添加标志符来让导航变得明确。 # 注释 原文点这里查看。\n这个配置也曾称成为intra_doc_link_resolution_failure。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n包含 README.md 的引用动作可以被Cargo.toml 中的 readme 字段覆盖。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nScott Meyers，More Effective C++ (Addison-Wesley)，第 32 条。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","date":"2024-06-17T15:08:08+08:00","permalink":"https://liyan-ah.github.io/p/%E8%AF%91%E6%96%87/effective-rust%E7%AC%AC-27-%E6%9D%A1%E4%B8%BA%E5%85%AC%E5%85%B1%E6%8E%A5%E5%8F%A3%E6%92%B0%E5%86%99%E6%96%87%E6%A1%A3/","title":"【译文/effective-rust】第 27 条：为公共接口撰写文档"},{"content":" # 从 3-sum 问题开始说起 3-sum 问题是 leetcode 中的一个经典问题。笔者最近重新重新回顾了这个问题，尴尬的是 关键时刻居然没有解出来。今天来重新回顾下。作为数组类问题中的经典问题，笔者认为这里有三个关键点：\n记得排序。数组问题大多需要进行排序，有序的数组才具有可操作性。 通过比较，来决定下标移动的位置。在处理 2-sum 过程时，比较当前下标数字的和与目标值的大小来决定下标的下一步移动方向。 对去重的处理。尴尬的就是这部分的处理过程。以笔者目前写代码的习惯，会直接使用 set 来进行去重。翻了下代码，对这部分的处理确实有点绕。 围绕第三点，下面给出两个解法。\n# set 去重 先看第一种解法，在处理结果集不重复时，使用 HashSet 来处理结果集唯一性的问题：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 impl Solution { pub fn three_sum_n(mut nums: Vec\u0026lt;i32\u0026gt;, sum: i32) -\u0026gt; Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt; { nums.sort(); let mut res = std::collections::HashSet::new(); for i in 0..nums.len() { let target = sum - nums[i]; let mut left = i + 1; let mut right = nums.len() - 1; while left \u0026lt; right { if nums[left] + nums[right] == target { // 题目中要求的时结果集不重复。直接使用 set 来保证唯一性。 res.insert(vec![nums[i], nums[left], nums[right]]); // 找到一个后，同时移动 left \u0026amp; right 后继续遍历 left += 1; right -= 1; continue; } if nums[left] + nums[right] \u0026gt; target { right -= 1; } else { left += 1; } } } res.into_iter().collect() } pub fn three_sum(mut nums: Vec\u0026lt;i32\u0026gt;) -\u0026gt; Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt; { Self::three_sum_n(nums, 0) } } # 通过比较来去重 第二种解法也是经典解法：在移动下标时，确保当前值和前一个值不同。笔 者回顾了下自己的思路以及给候选人的建议：先进行去重，然后进行比对。 先去重的问题就是，像 [0, 0, 0] 这样的结果就会先被去重环节排除 掉。而题目中没有结果集中的 [x, y, z] x != y \u0026amp;\u0026amp; y != z 的条件。 正确的去重方式应该是，通过后置位和前置位的对比来允许 [0, 0, 0]的 候选集能够出现。解题过程如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 impl Solution { pub fn three_sum_n(mut nums: Vec\u0026lt;i32\u0026gt;, sum: i32) -\u0026gt; Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt; { nums.sort(); let mut res = vec![]; for i in 0..nums.len() { // 同样需要对 i 进行去重处理 if i != 0 \u0026amp;\u0026amp; nums[i] == nums[i-1]{ continue; } let target = sum - nums[i]; let mut left = i + 1; let mut right = nums.len() - 1; while left \u0026lt; right { // 允许第一个 left 值继续处理。第二个值和前置值对比 if left != i + 1 \u0026amp;\u0026amp; nums[left] == nums[left - 1] { left += 1; continue; } // 允许第一个 right 值继续处理。第二个值和前置值对比 if right != nums.len() - 1 \u0026amp;\u0026amp; nums[right] == nums[right + 1] { right -= 1; continue; } if nums[left] + nums[right] == target { res.push(vec![nums[i], nums[left], nums[right]]); // 找到一个后，同时移动 left \u0026amp; right 后继续遍历 left += 1; right -= 1; continue; } if nums[left] + nums[right] \u0026gt; target { right -= 1; } else { left += 1; } } } res } pub fn three_sum(mut nums: Vec\u0026lt;i32\u0026gt;) -\u0026gt; Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt; { Self::three_sum_n(nums, 0) } } # 一些感想 最近接触了很多实习生，感觉现在的实习生实力都很强。笔者找工作时，简历里的项目只有小学期的一个项目以及实验室里的一个项目，而且工程量都很小。现在 的候选人都可以在网上找一些开源项目的教程项目来学习了，而且给开源项目提 PR 的能力也很强。确实超过笔者很多。\n另一点感想是，学校所在的城市对学生的工程能力还是有影响的：北上的研究生工程实践都很多，而且普遍对工程涉及的一些项目（Redis, ES等）都有一些了解。 而非大厂所在城市的学校，研究生跟着导师做的项目普遍偏学术，而且对工程的了解要少很多。这确实是地利带来的影响，而且确实对候选人的面试有很大的影响。 还是应该通过适当的实习来接触行业。同样的，工作了也需要不断的提升自己的视野面。\n","date":"2024-05-26T14:39:35+08:00","permalink":"https://liyan-ah.github.io/p/3-sum-%E9%97%AE%E9%A2%98/","title":"3-sum 问题"},{"content":"Emacs 指令行中，比如 load-file 加载文件时默认会填充当前的目录，可以使用 Ctr-backspace 来较为快速的删除文本。也可以通过光标移动至待删除处，Ctr-k 来直接删除光标（含）之后的所有文本。\n快捷键 功能 Ctr-backspace 删除光标前的一个单词 Ctr-k 删除光标（含）后的所有文本 ","date":"2024-05-13T10:51:15+08:00","permalink":"https://liyan-ah.github.io/p/emacs-%E5%AD%97%E7%AC%A6%E6%93%8D%E4%BD%9C%E5%BF%AB%E6%8D%B7%E9%94%AE/","title":"Emacs 字符操作快捷键"},{"content":"本文旨在回答如下问题：\nRust 项目中，如何配置 dependencies 的路径为指定仓库。 在不指定 branch 或 version 的情况下，dependencies 会拉取什么版本/仓库里的数据。 Rust 项目中，配置 dependencies 的最佳实践。 以下为正文。\n# 如何配置 dependencies 的路径？ 出于稳定性考虑，工作中使用的项目，尤其是一些开源的项目，往往无法和社区时刻保持一致。甚至，在选定了一个基线版本后，以周或者年计，主干会持续保持这个版本。有一些效果较好的“新特性”需要合入时，就需要以 patch 的形式合入。同样出于稳定性考虑， 或者兼容性考虑，服务的依赖，甚至依赖的依赖都是无法进行升级的。如果项目的新特性需要依赖库进行变更，就只能将依赖库的基线版本单独维护，按需合入依赖库的 patch。这样的维护方式看起来较为繁琐，但是能够有效避免项目因依赖库的升级而引入新的问 题。\n有了这样的需求，对应到 Rust 项目中，就需要对 Cargo.toml 里的 dependencies 配置进行调整，将部分依赖调整为自有库。 参照reference/specifying-dependencies，可以通过如下方式来指定依赖库：\n1 2 [dependencies] regex = { version = \u0026#34;1.10.3\u0026#34;, git = \u0026#34;https://github.com/rust-lang/regex.git\u0026#34;, branch = \u0026#34;next\u0026#34;, rev = \u0026#34;0c0990399270277832fbb5b91a1fa118e6f63dba\u0026#34;, tag = \u0026#34;11.10.4\u0026#34; } 除了 git，version、branch、rev 以及 tag 都是可选的，补充四者中的一个参数即可实现分支提交控制的目的。在实践过程中，考虑到分支上的提交是时刻进行的，在确认了基础的功能后，可以考虑发布一个版本。一来可以通过 tag 来进行版本/功能的 发布控制，同时也便于后续的功能梳理以及项目整理关键里程碑可视化。通过 branch 来指定依赖库会比较方便，这种方式对仓库的开发流程管理较为依赖：如果分支上提交了功能异常的代码，项目的编译就会异常。rev 方案也可以唯一指定代码版本，只是看起来 不像 tag 那样直观。\n# dependences 默认拉取什么版本？ 笔者在近期的工作中，遇到了如下的配置方式：\n1 2 [dependencies] regex = { git = \u0026#34;https://github.com/rust-lang/regex.git\u0026#34; } 这里并没有指定 version, branch 或者 rev。但是在编译项目时也会进行拉取的动作。默认会拉取目标仓库的最新提交（效果和直接 git clone 一致）。\n在复杂的项目中，通常会出现依赖库和依赖库的依赖有重合的情况。而Rust 工程在编译时，会通过校验目标库的 source 信息（Cargo.lock 中生成）来识别两个库是相同。当项目的依赖库的 dependence 配置和项目依赖库的依赖的 dependence 配置不同时， 就会出现种种类型不兼容的情况。比如，目前有这样的一个项目dep-check，其依赖 trait-lib和middle-lib两个库。同时，middle-lib又对 trait-lib存在依赖。当dep-check使用了trait_lib::Check，并且将该trait通过引用 middle-lib里的函数进行处理时，就涉及到dep-check和middle-lib对trait-lib的引用校验问题：两个库里涉及的Check是否是同一个Trait？就笔者目前的理解来看，由于 rust 里的 trait 采用的不是 duck-typing，因此就需要编译器在编译时对类型进行强校验。在这个小示例中，如果 middle-lib 的 dependencies 设置如下：\n1 2 [dependencies] trait-lib = { git = \u0026#34;https://github.com/liyan-ah/trait-lib.git\u0026#34;, tag = \u0026#34;1.0.0\u0026#34; } 而 dep-check 的 dependencies 设置如下：\n1 2 3 [dependencies] trait-lib = { git = \u0026#34;https://github.com/liyan-ah/trait-lib.git\u0026#34;, tag = \u0026#34;1.0.0\u0026#34; } middle-lib = { git = \u0026#34;https://github.com/liyan-ah/middle-lib.git\u0026#34; } # 注意，这种配置方式在 Cargo.lock 生成后，除非使用 cargo update 触发更新，否则依赖版本不会随着代码提交而更新。 dep-check 编译时，其引用的trait_lib::Check和 middle-lib 里使用的trait_lib::Check就无法认为是同一个（即使实际上代码的提交是同一个）。依赖库的设置可以通过 Cargo.lock 里的 source 来确认。当 dep-check 和 middle-lib 的 Cargo.lock 对 trait-lib 的 source 配置相同时，就不会出现类型不一致的问题。\n由于使用了 tag / rev / branch 来作为 dependencies 的配置，一个问题是当 trait-lib 发生更新时，需要同时升级 middle-lib 和 dep-check 这两个仓库。否则就会出现版本不一致而编译失败的情况。如果使用 version 控制，由于 version 实际 上表示的是一个范围，只要 update 后的依赖库是同一个版本即可（准确来说，x.y.z 中的 x.y 保持一致即可），可 以在 cargo update 后检查 dep-check 的 Cargo.lock 中存在几个 trait-lib。在仅存在一个 trait-lib 时，说明依赖库不存在版本冲突，此时不需要更新 middle-lib 中的 Cargo.toml。\n配置的问题在这里有描述：The dependency resolution is confused when using git dependency and there\u0026rsquo;s a lockfile。\nduck-typing 的接口在校验时还比较简单，只需要检查是否实现了目标类型/接口定义的函数即可。但是对于非 duck-typing，情况会复杂些：不同的库里是允许出现同名的 trait 的。如何确定项目中实现的 trait 和引用库中需要的 trait 是同一个 trait？这就需要确保项目中 trait 的来源库和引用库中所需要的 trait 来源库是相同的。而看起来，库是否相同，又是通过 source 来确定的。Cargo.toml 中的 source 毕竟是一个工程里的概念，是如何影响编译的呢？是否是编译过程中，函数签名里带着一些source 信息？还需要进一步的探索，期望能够整理成文档。\n# dependences 配置的最佳实践？ golang 和 rust 都支持通过配置 git 仓库的地址来直接引用，个人还是比较喜欢 rust 的配置方式：通过 Cargo.toml 能够简洁、明了的声明各种依赖的信息，在工程里可以直接使用库名（而非 golang 里的项目地址）。此外，rust 里的 workspace 机制 对仓库里存在多个 sub-lib 时也能较好的处理依赖的管理。\n下面是一个实践示例dep-check：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 [workspace] members = [ \u0026#34;dep-check\u0026#34;, \u0026#34;dep-run\u0026#34;, ] default-members = [\u0026#34;dep-check\u0026#34;] resolver = \u0026#34;2\u0026#34; [workspacepackage] name = \u0026#34;dep-check\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [workspace.dependencies] trait-lib = { git = \u0026#34;https://github.com/liyan-ah/trait-lib.git\u0026#34;, tag = \u0026#34;1.0.0\u0026#34; } middle-lib = { git = \u0026#34;https://github.com/liyan-ah/middle-lib.git\u0026#34;, tag = \u0026#34;1.0.0\u0026#34; } 对于其中的一个 member:dep-check，其配置为：\n1 2 3 4 5 6 7 8 9 10 [package] name = \u0026#34;dep-check\u0026#34; version = \u0026#34;0.1.0\u0026#34; edition = \u0026#34;2021\u0026#34; # See more keys and their definitions at https://doc.rust-lang.org/cargo/reference/manifest.html [dependencies] trait-lib = { workspace = true } middle-lib = { workspace = true } 这样，就能很便捷的对项目里的依赖进行管理了。\n以上。\n","date":"2024-05-07T11:39:00+08:00","permalink":"https://liyan-ah.github.io/p/cargo-config-%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"Cargo config 使用备注"},{"content":" 很久没有找工作的经历了，反而由于种种原因，最近接触了一些候选人。总体的感觉是最近是越来越卷了。 候选人的的水平明显比笔者毕业的时候高的多，也可能是笔者太菜了。其中一个合并区间的问题，笔者看到了 一个很有意思的解法。在这里记录下。\n《合并区间》问题的思路很明显：排序、合并。笔者最近见到了一种特殊场景下很有意思的解法：在数据范围较小的情况下，使用桶的思想来 解决，就不再需要进行排序了。算法复杂度也从时间复杂度o(nlgn)降到了o(n)。这里记录下。\n# 题目描述 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] = [starti, endi] 。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间 。 示例 1： 输入：intervals = [[1,3],[2,6],[8,10],[15,18]] 输出：[[1,6],[8,10],[15,18]] 解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6]. 示例 2： 输入：intervals = [[1,4],[4,5]] 输出：[[1,5]] 解释：区间 [1,4] 和 [4,5] 可被视为重叠区间。 提示： 1 \u0026lt;= intervals.length \u0026lt;= 10000 intervals[i].length == 2 0 \u0026lt;= starti \u0026lt;= endi \u0026lt;= 10000 # 两种解法 # 排序 先排序，然后遍历、比较。关键点在于需要处理好比较时的边界条件。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 impl Solution { pub fn merge(mut intervals: Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt;) -\u0026gt; Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt; { let mut merged = vec![]; intervals.sort_by(|x, y| x[0].cmp(\u0026amp;y[0])); let mut interval = (None, None); for v in intervals.iter() { if interval.0.is_none() { interval.0 = Some(v[0]); interval.1 = Some(v[1]); continue; } // [0, 1] and [1, 2] if interval.1.is_some() \u0026amp;\u0026amp; interval.1.unwrap() \u0026gt;= v[0] { if interval.1.unwrap() \u0026lt; v[1] { interval.1 = Some(v[1]); } continue; } // [0, 1] and [2, 3] merged.push(vec![interval.0.unwrap(), interval.1.unwrap()]); interval.0 = Some(v[0]); interval.1 = Some(v[1]); } if interval.0.is_some() { merged.push(vec![interval.0.unwrap(), interval.1.unwrap()]); } merged } } # 桶处理 采用匹配的思路，借助桶来记录数组的各个区间。这个思路还需要再体会下。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 impl Solution { pub fn merge(intervals: Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt;) -\u0026gt; Vec\u0026lt;Vec\u0026lt;i32\u0026gt;\u0026gt; { let mut merged = vec![]; if intervals.len() == 0 { return merged; } // 0. 找出桶的范围。这一步可以去掉，直接设一个 10000 大小的桶。 let mut max = 0; for iter in intervals.iter() { if max \u0026lt; iter[1] { max = iter[1]; } } // 由于 rust 的枚举特性，这里就不需要使用两个 bucket 了。 let mut bucket = vec![None; (max + 1) as usize]; for iter in intervals.iter() { if bucket[iter[0] as usize].is_none() { bucket[iter[0] as usize] = Some(0); } if bucket[iter[1] as usize].is_none() { bucket[iter[1] as usize] = Some(0); } bucket[iter[0] as usize] = Some(bucket[iter[0] as usize].unwrap() + 1); bucket[iter[1] as usize] = Some(bucket[iter[1] as usize].unwrap() - 1); } let mut start = None; let mut sum = 0; let mut p = 0 as usize; loop { if p \u0026gt;= bucket.len() { break; } let iter = bucket[p]; if iter.is_none() { p += 1; continue; } if start.is_none() { start = Some(p); } sum += iter.unwrap(); if sum == 0 { merged.push(vec![start.unwrap() as i32, p as i32]); start = None; } p += 1; } merged } } # 后记 这个问题是leetcode上的56. 合并区间。一般刷题 的人都会刷到。惭愧的是笔者已经没有印象了。得赶紧把插件修一修，有时间刷点题。\n","date":"2024-04-20T17:11:31+08:00","permalink":"https://liyan-ah.github.io/p/%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4/","title":"合并区间"},{"content":" BPF 技术看起来还有很多不易察觉的缺陷。最近又踩了一个坑。记录下。\nLRU_HASH_MAP 在实现的时候，出现了不符合预期的数据驱逐问题：设定一个 512 大小的LRU_HASH_MAP，很可能出现在40-50个key的时候，之前的key就被覆盖。在一段时间未更新时，重新更新也可能会出现异常。总结就是，执行了写入操作，很可能没有写入。这个问题在Elements incorrectly evicted from eBPF LRU hash map有较为详细的描述。\n但是，笔者之所以使用LRU_HASH_MAP主要是期望保持整个程序的鲁棒性：期望可以一直写入key而不需对bpf map的状态进行维护。如果使用固定大小的HASH_MAP，当写入的key超过map的预设大小时，测试的demo会出现崩溃的现象。由于LRU_HASH_MAP的功能出现了不符合预期的情况，显然也就需要使用HASH_MAP来替代了。 笔者遇到的需要使用LRU_HASH_MAP的场景有两种：1. 作为配置项。用户态的代码向BPF MAP里写入配置，而后在BPF里使用。2. 作为数据中转。比如涉及多个hook点配合时，就需要使用BPF MAP来存储一些中间数据。对于场景1，可以直接使用HASH_MAP来替代，用户态添加一些检查的措施，定期批量对MAP进行数据清理以及数据写入即可。但是对于场景2，可能会麻烦很多：数据是随时产出的，用户态没有办法控制其产出的频率、周期。目前能想到的是设置一个较大的MAP（这个异常的触发是否和MAP的大小有关？），仍然使用LRU_HASH_MAP；或者设置一个较大的HASH_MAP，然后定时在用户态进行数据的清理。\n以上。\n","date":"2024-03-12T11:02:00Z","permalink":"https://liyan-ah.github.io/p/bpf-lru_hash_map-%E5%8F%8A-hash_map-%E7%9A%84%E4%BD%BF%E7%94%A8%E5%BC%82%E5%B8%B8/","title":"BPF LRU_HASH_MAP 及 HASH_MAP 的使用异常"},{"content":" 最近做了一些 TCP 连接观测相关的项目，又到了一个节奏点上了。这里趁着这个机会，做一些总结，同时描述一下 tcp close 过程中的一些疑惑。\n在一些场景下，对服务的调用观测是很有价值的。笔者最近实践了使用tcp_close对服务主被调信息的观测，在这里作一下记录。\n# 一、tcp close 的一般过程 首先来看一下tcp close的过程。\n对tcp涉及操作的分析最权威的自然是RFC文档。依据RFC-793文档中的描述，tcp close时的状态转移信息为如下：\n但是涉及到具体的Linux下的tcp close的过程分析，文档就比较少了。笔者找到了一篇介绍Linux下tcp操作相关的介绍文档。Analysis_TCP_in_Linux中描述了主动触发close及被动触发close的socket双方涉及的函数调用，这为后面的验证提供了思路。\n# 二、BPF 来观测 tcp close 过程 依据Analysis_TCP_in_Linux中的描述，笔者使用python构建了如下的验证demo。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 # coding=UTF-8 import socket import time import getopt import sys srv_ip = \u0026#34;\u0026#34; srv_port = 0 def server(srv_ip, srv_port): conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM) conn.bind((srv_ip, srv_port)) conn.listen(1024) conn.setblocking(1) index = 0 while True: connection, address = conn.accept() try: dst = connection.getpeername() while True: request = connection.recv(1024) req_str = str(request.decode()) if req_str == \u0026#39;end\u0026#39;: # 这里以客户端传输一个特殊信息作为结束信息 # tcp server 和 client 之间的 close 是没有必然联系的 # 只能约定一个关闭条件。此时，无法确定客户端是否发起了断联 print(\u0026#34;rcv end, close...\u0026#34;) connection.close() time.sleep(2) break # pass print(\u0026#34;conn: %s:%d received: %s\u0026#34; % (dst[0], dst[1], req_str)) response = (\u0026#34;client, msg index: %d\u0026#34; % index).encode() connection.send(response) index += 1 print(\u0026#34;conn: %s:%d closed\u0026#34; % (dst[0], dst[1])) except Exception as e: print(\u0026#34;handle exception during dst. %s ...\u0026#34; % e) # pass # pass def client(srv_ip, srv_port): try: server_addr = (srv_ip, srv_port) conn = socket.socket(socket.AF_INET, socket.SOCK_STREAM) conn.connect(server_addr) msg = (\u0026#34;server, msg index: 0\u0026#34;).encode() conn.send(msg) data = conn.recv(1024) print(\u0026#34;rcv from server: %s\u0026#34; % str(data.decode())) conn.send(\u0026#34;end\u0026#34;.encode()) print(\u0026#34;end. close ...\u0026#34;) time.sleep(2) conn.close() time.sleep(2) except Exception as e: print(\u0026#34;connection with server with error, %s\u0026#34; % e) return if __name__ == \u0026#34;__main__\u0026#34;: work_mode = \u0026#34;s\u0026#34; try: opts, args = getopt.getopt(sys.argv[1:], \u0026#34;i:p:s:c\u0026#34;, [\u0026#34;srv_ip=\u0026#34;, \u0026#34;port=\u0026#34;, \u0026#34;server\u0026#34;, \u0026#34;client\u0026#34;]) if len(opts) == 0: print(\u0026#34;unknown opts\u0026#34;) sys.exit(0) for opt, arg in opts: if opt in (\u0026#34;-i\u0026#34;, \u0026#34;--srv_ip\u0026#34;): srv_ip = arg if opt in (\u0026#34;-p\u0026#34;, \u0026#34;--port\u0026#34;): srv_port = int(arg) if opt in (\u0026#34;--server\u0026#34;): work_mode = \u0026#34;s\u0026#34; if opt in (\u0026#34;--client\u0026#34;): work_mode = \u0026#34;c\u0026#34; except Exception as e: print(\u0026#34;unknown args\u0026#34;) sys.exit(0) if work_mode == \u0026#34;s\u0026#34;: server(srv_ip, srv_port) else: client(srv_ip, srv_port) 从demo中可以看到，笔者构建的测试代码中，是server端发起的close，而后client端发起close。\n同时，笔者使用bpftrace构造了如下的观测代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 #include \u0026lt;net/sock.h\u0026gt; /* TCP_ESTABLISHED = 1, TCP_SYN_SENT = 2, TCP_SYN_RECV = 3, TCP_FIN_WAIT1 = 4, TCP_FIN_WAIT2 = 5, TCP_TIME_WAIT = 6, TCP_CLOSE = 7, TCP_CLOSE_WAIT = 8, TCP_LAST_ACK = 9, TCP_LISTEN = 10, TCP_CLOSING = 11, TCP_NEW_SYN_RECV = 12, TCP_MAX_STATES = 13 每个 hook 点关注 进程的 pid, sk_state */ kprobe:tcp_close / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_close] pid: %d, state: %d, sock: %d, sk_max_ack_backlog: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk, $sk-\u0026gt;sk_max_ack_backlog); } kprobe:tcp_set_state / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; $ns = arg1; printf(\u0026#34;[tcp_set_state] pid: %d, state: %d, ns: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $ns, $sk); } kprobe:tcp_rcv_established / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_rcv_established] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_fin / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_fin] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_send_fin / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_send_fin] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_timewait_state_process / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_timewait_state_process] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_rcv_state_process / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_rcv_state_process] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_v4_do_rcv / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_v4_do_rcv] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } kprobe:tcp_timewait_state_process / comm == \u0026#34;python\u0026#34; / { $sk = (struct sock*)arg0; printf(\u0026#34;[tcp_stream_wait_close] pid: %d, state: %d, sk: %d \u0026#34;, pid, $sk-\u0026gt;__sk_common.skc_state, $sk); } 首先启动bpftrace，然后启动server，使用client进行通信。此时bpftrace端的输出为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 [tcp_close] pid: 2828708, state: 1, sock: -1907214080, sk_max_ack_backlog: 1024 [tcp_set_state] pid: 2828708, state: 1, ns: 4, sk: -1907214080 [tcp_send_fin] pid: 2828708, state: 4, sk: -1907214080 [tcp_v4_do_rcv] pid: 2828708, state: 1, sk: -1907216512 [tcp_rcv_established] pid: 2828708, state: 1, sk: -1907216512 [tcp_fin] pid: 2828708, state: 1, sk: -1907216512 [tcp_set_state] pid: 2828708, state: 1, ns: 8, sk: -1907216512 [tcp_v4_do_rcv] pid: 2855763, state: 1, sk: -1907214080 [tcp_rcv_established] pid: 2855763, state: 1, sk: -1907214080 [tcp_close] pid: 2855763, state: 8, sock: -1907216512, sk_max_ack_backlog: 0 [tcp_set_state] pid: 2855763, state: 8, ns: 9, sk: -1907216512 [tcp_send_fin] pid: 2855763, state: 9, sk: -1907216512 [tcp_timewait_state_process] pid: 2855763, state: 6, sk: -2077492080 [tcp_stream_wait_close] pid: 2855763, state: 6, sk: -2077492080 [tcp_v4_do_rcv] pid: 2855763, state: 9, sk: -1907216512 [tcp_rcv_state_process] pid: 2855763, state: 9, sk: -1907216512 [tcp_set_state] pid: 2855763, state: 9, ns: 7, sk: -1907216512 # 三、笔者的困惑 这里，笔者观测到的结果和Analysis_TCP_in_Linux存在出入，主动发起close的一方，在第三次挥手时，响应的并不是tcp_rcv_state_process。相反的，被动close的socket在第四次挥手时触发了这个函数。而且，主动close的socket，第二次挥手时，响应的socket看起来发生了变更，而且其状态是TCP_ESTABLISHED。这其中需要继续探索。\n以上，作为记录了部分总结。\n","date":"2024-02-24T15:55:00Z","permalink":"https://liyan-ah.github.io/p/tcp-close-%E8%BF%87%E7%A8%8B%E5%88%86%E6%9E%90/","title":"TCP close 过程分析"},{"content":" 搞项目。\n观测服务的请求调用需求是客观存在的。一般是需要观测服务的主动发起的调用信息，但是偶尔也会遇到需要观测服务被调用信息的需求。但是一般待采集的服务都是挂载在LVS下面的。这就势必涉及到LVS预设的工作模式下，一般都是FULLNET，需要的real client ip的信息获取方式。\n笔者通过调研，实现了一种通过BPF来观测挂载在LVS下的RS被调用TCP连接信息的方式。本文中关于toa的操作及代码定义均引用自Huawei/TCP_option_address。\n# 一、效果 先看下采集效果：\n# 二、LVS FullNat 关于LVS的Nat,DR,Tun以及FullNat模式的介绍已经有了很多的资料，比如这篇文章就介绍的很详细。这里笔者附上FullNat模式下的示意图：\n如图所示，如果需要在RS上获取CIP，就涉及到TOA信息的解析。TOA (tcp optional address)是利用tcp协议option字段来传递信息的一种工作方式。关于TOA的约定笔者并没有找到官方的RFC文档。只有一些结构的定义。\n1 2 3 4 5 6 7 /* MUST be 4 bytes alignment */ struct toa_data { __u8 opcode; __u8 opsize; __u16 port; __u32 ip; }; 同时，rfc793里对TCP header的约定如下，理论上toa_data应该写在Options字段中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Source Port | Destination Port | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Sequence Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Acknowledgment Number | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Data | |U|A|P|R|S|F| | | Offset| Reserved |R|C|S|S|Y|I| Window | | | |G|K|H|T|N|N| | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Checksum | Urgent Pointer | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | Options | Padding | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ | data | +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+ TCP Header Format 一般来说，将real-client ip写入tcp option字段的操作是在LVS上进行的。而解析并且方便RS操作，主要是需要在getname的时候需要返回real-client ip以便于做进一步的业务逻辑，比如按照IP限流等，是RS的toa模块在操作的。一般是在tcp握手的第三个SYN报文处理时，toa.ko通过tcp_v4_syn_recv_sock处理的hook函数方式来触发toa数据的处理。\n这里附一段这里的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 static struct sock * tcp_v4_syn_recv_sock_toa(struct sock *sk, struct sk_buff *skb, struct request_sock *req, struct dst_entry *dst) #endif { struct sock *newsock = NULL; TOA_DBG(\u0026#34;tcp_v4_syn_recv_sock_toa called \u0026#34;); /* call orginal one */ #if LINUX_VERSION_CODE \u0026gt;= KERNEL_VERSION(4,4,0) newsock = tcp_v4_syn_recv_sock(sk, skb, req, dst, req_unhash, own_req); #else newsock = tcp_v4_syn_recv_sock(sk, skb, req, dst); #endif /* set our value if need */ if (NULL != newsock \u0026amp;\u0026amp; NULL == newsock-\u0026gt;sk_user_data) { newsock-\u0026gt;sk_user_data = get_toa_data(skb); if (NULL != newsock-\u0026gt;sk_user_data) TOA_INC_STATS(ext_stats, SYN_RECV_SOCK_TOA_CNT); else TOA_INC_STATS(ext_stats, SYN_RECV_SOCK_NO_TOA_CNT); TOA_DBG(\u0026#34;tcp_v4_syn_recv_sock_toa: set \u0026#34; \u0026#34;sk-\u0026gt;sk_user_data to %p \u0026#34;, newsock-\u0026gt;sk_user_data); } return newsock; } static void *get_toa_data(struct sk_buff *skb) { struct tcphdr *th; int length; unsigned char *ptr; struct toa_data tdata; void *ret_ptr = NULL; unsigned char buff[(15 * 4) - sizeof(struct tcphdr)]; TOA_DBG(\u0026#34;get_toa_data called \u0026#34;); if (NULL != skb) { th = tcp_hdr(skb); length = (th-\u0026gt;doff * 4) - sizeof(struct tcphdr); ptr = skb_header_pointer(skb, sizeof(struct tcphdr), length, buff); if (!ptr) return NULL; while (length \u0026gt; 0) { int opcode = *ptr++; int opsize; switch (opcode) { case TCPOPT_EOL: return NULL; case TCPOPT_NOP:\t/* Ref: RFC 793 section 3.1 */ length--; continue; default: opsize = *ptr++; if (opsize \u0026lt; 2)\t/* \u0026#34;silly options\u0026#34; */ return NULL; if (opsize \u0026gt; length) /* don\u0026#39;t parse partial options */ return NULL; if (TCPOPT_TOA == opcode \u0026amp;\u0026amp; // 254 TCPOLEN_TOA == opsize) { // 8 memcpy(\u0026amp;tdata, ptr - 2, sizeof(tdata)); TOA_DBG(\u0026#34;find toa data: ip = \u0026#34; \u0026#34;%u.%u.%u.%u, port = %u \u0026#34;, NIPQUAD(tdata.ip), ntohs(tdata.port)); memcpy(\u0026amp;ret_ptr, \u0026amp;tdata, sizeof(ret_ptr)); TOA_DBG(\u0026#34;coded toa data: %p \u0026#34;, ret_ptr); return ret_ptr; } ptr += opsize - 2; length -= opsize; } } } return NULL; } 可以看到，这里首先调用了原有的tcp_v4_syn_recv_sock函数，并且在sk_user_data未被占用的情况下，通过get_toa_data的方式，从原始的skb中将toa信息解析出来，并将数据赋值给sk-\u0026gt;sk_user_data。\n虽然这部分逻辑并不完全理解，但是从逻辑来看，只要读取sk_user_data并且判断其中是否有符合条件的值，即可获取real-client ip。\n至此，基本的逻辑就梳理出来了。对应的BPF处理逻辑也就很清晰了。\n# 三、BPF 逻辑 直接上代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 #define INADDR_LOOPBACK 0x7f000001 /* 127.0.0.1 */ #define INADDR_LOOPBACK_HOST INADDR_LOOPBACK #define INADDR_LOOPBACK_NET 0x0100007f /* 127.0.0.1 */ #define ns2sec(ns) ((ns) / (1000 * 1000 * 1000)) #ifndef memcpy #define memcpy(dest, src, n) __builtin_memcpy((dest), (src), (n)) #endif #define MERGE_SEC 10 typedef struct { u8 opcode; u8 opsize; u16 port; u32 ip; } toa_data_t; // 一般 toa 模块里只会填充一个 toa 数据 #define TCP_OPTION_LEN 1 struct tcp_event { u32 raddr; u32 laddr; u16 rport; u16 lport; int err; u64 toa_addr; toa_data_t toa_data; u64 sec; u64 ns; }; typedef struct tcp_event tcp_event_t; const struct tcp_event* unused_0x01 __attribute__((unused)); struct { __uint(type, BPF_MAP_TYPE_LRU_HASH); __uint(key_size, sizeof(tcp_event_t)); __uint(value_size, sizeof(u64)); // timestamp __uint(max_entries, 1024); } tcp_event_map SEC(\u0026#34;.maps\u0026#34;); struct { __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY); __uint(max_entries, 1024); } events SEC(\u0026#34;.maps\u0026#34;); enum toa_type { ipopt_toa = 254, // IP_v4 客户端 IP，目前仅考虑 }; #define _AF_INET 2 /* internetwork: UDP, TCP, etc. */ #define _IPPROTO_TCP 6 SEC(\u0026#34;kretprobe/inet_csk_accept\u0026#34;) int kretprobe__inet_csk_accept(struct pt_regs* ctx) { u64 start_ns = bpf_ktime_get_ns(); tcp_event_t event = {}; struct sock* sk = (struct sock*)PT_REGS_RC(ctx); if (sk == NULL) { return 0; } struct sock_common sk_common = {}; bpf_probe_read(\u0026amp;sk_common, sizeof(sk_common), (const void*)(sk)); if (sk_common.skc_family != _AF_INET) { return 0; } // 不处理本地回环 if (sk_common.skc_rcv_saddr == INADDR_LOOPBACK_NET || sk_common.skc_daddr == INADDR_LOOPBACK_NET) { return 0; } event.laddr = bpf_ntohl(sk_common.skc_rcv_saddr); event.raddr = bpf_ntohl(sk_common.skc_daddr); event.lport = sk_common.skc_num; event.rport = bpf_ntohs(sk_common.skc_dport); int err; toa_data_t toa_data[TCP_OPTION_LEN] = {}; err = BPF_CORE_READ_INTO(\u0026amp;toa_data, sk, sk_user_data); if (err) { return 0; } u8 i = 0; #pragma unroll for (i = 0; i \u0026lt; TCP_OPTION_LEN; i++) { if (toa_data[i].opcode != ipopt_toa) { continue; } memcpy(\u0026amp;event.toa_data, \u0026amp;toa_data[i], sizeof(toa_data_t)); } u32 raddr = event.raddr; if (event.toa_data.ip != 0 \u0026amp;\u0026amp; event.toa_data.port != 0) { // 挂载在 lvs 时，DS 的 IP 会发生变更。这里也给聚合掉。 event.raddr = 0; } // remote port 都不要 event.toa_data.port = 0; event.rport = 0; u64 sec = 0; u64 now_ns = bpf_ktime_get_ns(); u64* last_ns = (u64*)bpf_map_lookup_elem(\u0026amp;tcp_event_map, \u0026amp;event); if (last_ns != NULL) { sec = ns2sec((now_ns - *last_ns)); if (sec \u0026lt;= MERGE_SEC) { return 0; } } else { sec = 99; } bpf_map_update_elem(\u0026amp;tcp_event_map, \u0026amp;event, \u0026amp;now_ns, BPF_ANY); event.sec = sec; event.raddr = raddr; u64 end_ns = bpf_ktime_get_ns(); event.ns = end_ns - start_ns; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } 以上，周末愉快。\n","date":"2024-01-03T16:15:00Z","permalink":"https://liyan-ah.github.io/p/bpf-%E8%8E%B7%E5%8F%96-lvs-fullnat-%E6%A8%A1%E5%BC%8F%E4%B8%8B%E7%9A%84-client-ip/","title":"BPF 获取 LVS FullNat 模式下的 Client IP"},{"content":" 2023年就要结束了，算起来距离上一次更新也有很久了。搜肠刮肚，总得在23年结束前再搞两篇总结，算是有始有终。总结今年，总还是绕不过 BPF，golang。既然如此，就对BPF观测golang这个话题再往下挖掘下，先做第一篇文章。下旬如果有时间并且顺利的话，希望能把BPF的原理总结完成。\n在无侵入观测服务拓扑四元组的一种实现中，笔者有提到追踪golang处理过程的两个无法解决的问题是golang里的channel处理以及goroutine pool。再深究下，这两个问题实际上都可以归纳到对channel的处理，因为很多goroutine pool都离不了channel的使用，比如Jeffail/tunny这个库。\n本文将会构建一个channel的追踪的方案。\n# 一、追踪效果 按照惯例，我们还是来看下效果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 // terminal 1，启动服务 $ ./drink-srv // terminal 2，启动追踪脚本 $ sudo bpftrace ./drink.bt Attaching 7 probes... // 启动后停止在这里 serve HTTP: /alcohol // 触发接口后输出 caller: /alcohol, callee: :/unknown/prepare/hotel serve HTTP: /tea caller: /tea, callee: :/unknown/prepare/club // terminal 3，触发服务接口 $ curl \u0026#34;localhost:1423/alcohol?age=22\u0026#34; $ curl \u0026#34;localhost:1423/tea?age=12\u0026#34; # 二、方案设计 关于golang channel的实现及设计，可以参见图解Go的channel底层实现，里面有非常生动的动图实现；搭配源码食用更好runtime/chan.go。\n笔者在这里再简单的总结下，对send及recv两种操作设计的状态做一个简单的概述： chan-send的状态： chan-recv的状态： 比如，对于下面的代码，派生出的g1在开启select后，由于ticketChan是空的，会触发g1让出m里的执行权限，进入gopark状态。同时，ticketChan会将g1封装成sudog，放到recvq队列中。当一段时间之后，其他的g将数据写入channel里时，会在chansend时，检查到recvq不为空，会直接将数据拷贝到空闲的sudog中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 var ticketChan = make(chan TicketInfo, 10) func HandleDrink() { for { select { case info, ok := \u0026lt;-ticketChan: ... } } } } func main() { go HandleDrink() ... } chanrecv进入recvq对应的golang处理逻辑在这里：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // runtime/chan.go ... // no sender available: block on this channel. gp := getg() mysg := acquireSudog() mysg.releasetime = 0 if t0 != 0 { mysg.releasetime = -1 } // No stack splits between assigning elem and enqueuing mysg // on gp.waiting where copystack can find it. mysg.elem = ep mysg.waitlink = nil gp.waiting = mysg mysg.g = gp mysg.isSelect = false mysg.c = c gp.param = nil c.recvq.enqueue(mysg) ... chansend直接将数据拷贝到recvq对应的golang处理逻辑在这里：\n1 2 3 4 5 6 7 8 9 10 // runtime/chan.go ... if sg := c.recvq.dequeue(); sg != nil { // Found a waiting receiver. We pass the value we want to send // directly to the receiver, bypassing the channel buffer (if any). send(c, sg, ep, func() { unlock(\u0026amp;c.lock) }, 3) return true } ... # 三、方案实现 了解了channel的处理流程，追踪的方案就比较明确了，直接在关键的函数处设置hook点即可。先来看下目标服务：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 package main import ( \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) const ( ALCOHOL = iota + 1001 COCO COFFEE TEA ) type TicketInfo struct { Age int Name string Type int } var ticketChan = make(chan TicketInfo, 10) func AlcoholH(c *gin.Context) { var ticket = TicketInfo{} var err error ticket.Age, err = strconv.Atoi(c.Query(\u0026#34;age\u0026#34;)) if err != nil { c.String(http.StatusOK, \u0026#34;handle failed\u0026#34;) return } ticket.Name = c.Query(\u0026#34;name\u0026#34;) ticket.Type = ALCOHOL ticketChan \u0026lt;- ticket return } func TeaH(c *gin.Context) { var ticket = TicketInfo{} var err error ticket.Age, err = strconv.Atoi(c.Query(\u0026#34;age\u0026#34;)) if err != nil { log.Println(\u0026#34;handle failed, \u0026#34;, err.Error()) c.String(http.StatusOK, \u0026#34;handle failed\u0026#34;) return } ticket.Name = c.Query(\u0026#34;name\u0026#34;) ticket.Type = TEA ticketChan \u0026lt;- ticket c.String(http.StatusOK, \u0026#34;okay\u0026#34;) return } func HandleDrink() { for { select { case info, ok := \u0026lt;-ticketChan: if !ok { log.Println(\u0026#34;chan closed.\u0026#34;) return } log.Println(\u0026#34;get ticket\u0026#34;) switch info.Type { case ALCOHOL: Alcohol(info) case COCO: SoftDrink(info) case COFFEE, TEA: Tea(info) default: log.Println(\u0026#34;unknown drink type\u0026#34;) } } } } func Alcohol(ticket TicketInfo) { var url = \u0026#34;http://localhost/unknown/prepare/hotel\u0026#34; http.DefaultClient.Get(url) return } func SoftDrink(ticket TicketInfo) { log.Printf(\u0026#34;[%s, %d] drink %d\u0026#34;, ticket.Name, ticket.Age, ticket.Type) return } func Tea(ticket TicketInfo) { var url = \u0026#34;http://localhost/unknown/prepare/club\u0026#34; http.DefaultClient.Get(url) return } func main() { defer func() { close(ticketChan) }() go HandleDrink() var r = gin.Default() r.GET(\u0026#34;/alcohol\u0026#34;, AlcoholH) r.GET(\u0026#34;/tea\u0026#34;, TeaH) var srv = \u0026amp;http.Server{ Addr: \u0026#34;127.0.0.1:1423\u0026#34;, Handler: r, } if srv.ListenAndServe() != nil { log.Println(\u0026#34;failed to handle service listen\u0026#34;) return } } 对于这样的一个服务，希望达到示例中的追踪效果，对应的方案为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 #define OFF_TASK_THRD 4992 #define OFF_THRD_FSBASE 40 #define GOID_OFFSET 152 uprobe:./drink-srv:\u0026#34;runtime.runqput\u0026#34; { $prob_mark = \u0026#34;runqput\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; if (@new_go[tid, pid] == 0){ return; } $p_goid = @new_go[tid, pid]; $g = (uint64)(reg(\u0026#34;bx\u0026#34;)); $goid = *(uint64*)($g+GOID_OFFSET); @caller_addr[$goid] = @caller_addr[$p_goid]; @caller_len[$goid] = @caller_len[$p_goid]; } uprobe:./drink-srv:\u0026#34;runtime.newproc1\u0026#34; { $prob_mark = \u0026#34;newproc1\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $g = (uint64)(reg(\u0026#34;bx\u0026#34;)); $goid = *(uint64*)($g+GOID_OFFSET); if (@caller_addr[$goid] == 0){ return; } @new_go[tid, pid] = $goid; } // 这里，将 caller 信息和写入 channel 信息的 key 关联起来 uprobe:./drink-srv:\u0026#34;runtime.chansend\u0026#34; { $prob_mark = \u0026#34;chansend\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $cur = (uint64)curtask; $fsbase = *(uint64*)($cur+OFF_TASK_THRD+OFF_THRD_FSBASE); $g = *(uint64*)($fsbase-8); $goid = *(uint64*)($g+GOID_OFFSET); // 如果当前执行goroutine中没有caller，跳过 if(@caller_addr[$goid] == 0){ return; } $chan = (uint64)reg(\u0026#34;ax\u0026#34;); $qcount = *(uint32*)($chan + 0); $buf = *(uint64*)($chan+16); @send_addr[$chan, $qcount] = @caller_addr[$goid]; @send_len[$chan, $qcount] = @caller_len[$goid]; return; } uprobe:./drink-srv:\u0026#34;runtime.chanrecv\u0026#34; { $prob_mark = \u0026#34;chanrecv\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $cur = (uint64)curtask; $fsbase = *(uint64*)($cur+OFF_TASK_THRD+OFF_THRD_FSBASE); $g = *(uint64*)($fsbase-8); $goid = *(uint64*)($g+GOID_OFFSET); $chan = (uint64)reg(\u0026#34;ax\u0026#34;); $qcount = *(uint32*)($chan + 0); $buf = *(uint64*)($chan+16); if (@send_addr[$chan, $qcount] == 0){ return; } @caller_addr[$goid] = @send_addr[$chan, $qcount]; @caller_len[$goid] = @send_len[$chan, $qcount]; return; } uprobe:./drink-srv:\u0026#34;runtime.send\u0026#34; { $prob_mark = \u0026#34;send\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $chan = (uint64)reg(\u0026#34;ax\u0026#34;); $sg = (uint64)reg(\u0026#34;bx\u0026#34;); $g = *(uint64*)($sg+0); $goid = *(uint64*)($g+GOID_OFFSET); $qcount = *(uint32*)($chan+0); @caller_addr[$goid] = @send_addr[$chan, $qcount]; @caller_len[$goid] = @send_len[$chan, $qcount]; return; } /* type serverHandler struct { srv *Server } func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { */ uprobe:./drink-srv:\u0026#34;net/http.serverHandler.ServeHTTP\u0026#34; { $prob_mark = \u0026#34;ServeHTTP\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $cur = (uint64)curtask; $fsbase = *(uint64*)($cur+OFF_TASK_THRD+OFF_THRD_FSBASE); $g = *(uint64*)($fsbase-8); $goid = *(uint64*)($g+GOID_OFFSET); $req_addr = reg(\u0026#34;di\u0026#34;); // offset(Request.URL) = 16 $url_addr = *(uint64*)($req_addr+16); // offset(URL.Path) = 56 $path_addr = *(uint64*)($url_addr+56); $path_len = *(uint64*)($url_addr+64); @caller_addr[$goid] = $path_addr; @caller_len[$goid] = $path_len; printf(\u0026#34;serve HTTP: %s \u0026#34;, str($path_addr, $path_len)); return; } /* func (c *Client) do(req *Request) (retres *Response, reterr error) { */ uprobe:./drink-srv:\u0026#34;net/http.(*Client).do\u0026#34; { $prob_mark = \u0026#34;do\u0026#34;; @prob[$prob_mark] = @prob[$prob_mark] + 1; $cur = (uint64)curtask; $fsbase = *(uint64*)($cur+OFF_TASK_THRD+OFF_THRD_FSBASE); $g = *(uint64*)($fsbase-8); $goid = *(uint64*)($g+GOID_OFFSET); if (@caller_addr[$goid] == 0){ printf(\u0026#34;%d: has no caller. \u0026#34;, $goid); return; } $req_addr = reg(\u0026#34;bx\u0026#34;); // offset(Request.URL) = 16 $url_addr = *(uint64*)($req_addr+16); // offset(URL.Host) = 40 $host_addr = *(uint64*)($req_addr+40); $host_len = *(uint64*)($req_addr+48); // offset(URL.Path) = 56 $path_addr = *(uint64*)($url_addr+56); $path_len = *(uint64*)($url_addr+64); $c_addr = @caller_addr[$goid]; $c_len = @caller_len[$goid]; printf(\u0026#34;caller: %s, callee: %s:%s \u0026#34;, str($c_addr, $c_len), str($host_addr, $host_len), str($path_addr, $path_len)); } # 四、追踪的风险 至此，看起来golang channel是可以追踪的。但是实际上并非如此。比如如下这个示例：\n1 2 3 4 5 6 7 8 9 10 func HandleDrink() { for { select { case info, ok := \u0026lt;-ticketChan: ... default: // 注意这个 stop // no stop here } } } 这段逻辑在代码编写、编译阶段均无问题，是一段完全合理的逻辑。当我们试图追踪这段代码时：\n1 2 3 4 $ sudo bpftrace ./drink.bt Attaching 7 probes... ^C // 直接停止，没有请求 @prob[chanrecv]: 908571 注意，此时并没有做任何的操作，但是这个chanrecv这个hook点已经触发了数十万次。而我们知道，BPF hook点的触发并非没有开销的。因此，目标的代码在完全合理的情况下，我们的追踪程序会给系统带来很大的负载。这显然是我们需要避免的。\n以上，周末愉快～\n","date":"2023-12-08T19:43:00Z","permalink":"https://liyan-ah.github.io/p/%E5%A6%82%E4%BD%95%E8%BF%BD%E8%B8%AAgolang-channel/","title":"如何追踪golang channel?"},{"content":" 不出意外的，之前提到的 ELF 文件解析内容又拖延了。目前还不知道什么时候有时间能够把希望完成的几篇文章给搞完。翻一翻目前的博客，已经有很久没有更新了。那就水一篇文章吧。目前算是项目里的低谷期，希望能够重拾程序员的意义。\n在bpftrace 无侵入遍历golang链表里，笔者展示了使用bpftrace来遍历golang链表的方法。由于go-17和go-16的函数调用规约存在不同，因此bpftrace 无侵入遍历golang链表并不适用于go-17。其实这个问题在go-1.17+ 调用规约已经提到了解决方案。本文给一个实例，算是更进一步的延伸这个话题，希望能够起到一些效果。\n# 一、执行效果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 $ sudo bpftrace ./link.bt Attaching 1 probe... // 在触发目标程序前，停止在这里 // 触发目标程序后，输出 == enter main.showNode name: Alice, age: 11 name: Bob, age: 12 name: Claire, age: 13 == end // 目标程序执行结果 $ ./link name: Alice, age: 11 name: Bob, age: 12 name: Claire, age: 13 需要注意的是，笔者的验证环境为：\n1 2 3 Linux 4.18.0-193.el8.x86_64 go version go1.17 linux/amd64 bpftrace v0.14.0-72-g6761-dirty 由于不同的CPU架构下，寄存器的信息会有所不同。本文中所涉及的代码示例仅在amd64里有效。\n# 二、代码 本文涉及两部分代码：目标的go代码以及bpftrace代码。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // link/main.go package main import \u0026#34;fmt\u0026#34; type Node struct { Name string Age int64 Next *Node } //go:noinline func showNode(head *Node) { var cur = head for cur != nil { fmt.Printf(\u0026#34;name: %s, age: %d \u0026#34;, cur.Name, cur.Age) cur = cur.Next } return } func main() { var node = \u0026amp;Node{ Name: \u0026#34;Alice\u0026#34;, Age: 11, Next: \u0026amp;Node{ Name: \u0026#34;Bob\u0026#34;, Age: 12, Next: \u0026amp;Node{ Name: \u0026#34;Claire\u0026#34;, Age: 13, Next: nil, }, }, } showNode(node) } bpftrace代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 // link/link.bt // 这里，符号使用双引号包裹起来是个好习惯 uprobe:./link:\u0026#34;main.showNode\u0026#34; { printf(\u0026#34;== enter main.showNode \u0026#34;); $head_ptr = reg(\u0026#34;ax\u0026#34;); unroll(10){ $name_ptr = *(uint64*)($head_ptr+0); $name_len = *(uint64*)($head_ptr+8); $age_v = *(int64*)($head_ptr+16); printf(\u0026#34;name: %s, age: %d \u0026#34;, str($name_ptr, $name_len), $age_v); // set head = next $head_ptr = *(uint64*)($head_ptr+24); if ($head_ptr == 0){ printf(\u0026#34;== end \u0026#34;); return; } } } 以上。周末愉快。\n","date":"2023-11-18T15:36:00Z","permalink":"https://liyan-ah.github.io/p/bpftrace-%E9%81%8D%E5%8E%86-golang-%E9%93%BE%E8%A1%A8go17-/","title":"bpftrace 遍历 golang 链表（go17+）"},{"content":" 最近在整理一些技术文章。本来希望把涉及ELF的内容整理出来，结果发现太难了。ELF涉及的内容要多很多，如果要把希望整理的内容表述清楚，还需要做一些准备的工作。刚好最近完成了tail-calls 的调研，先把关于eBPF的tail-calls的功能整理下吧。\neBPF程序是事件驱动的，这就意味着当目标事件触发后，程序才能执行。考虑这样一个场景：有几个不同的BPF程序均挂载在相同的hook点上，而执行需要保持一定的顺序。这时就需要借助tail calls的功能来实现。\n# 一、tail calls 与 bpf2bpf calls的对比 首先要说明的是，将不同的逻辑分支都放到一个bpf程序里是很难进行的，因为bpf程序存在严格的限制：比如512B的执行栈。处理逻辑复杂，往往意味着需要使用的结构体就多，很容易就超出了512B的限制，编译时会报类似如下的错误：\n1 2 3 4 5 cd uretprobe \u0026amp;\u0026amp; go generate ./uretprobe.c:24:15: error: Looks like the BPF stack limit of 512 bytes is exceeded. Please move large on stack variables into BPF per-cpu array map. struct event event = {}; ^ ./uretprobe.c:24:15: error: Looks like the BPF stack limit of 512 bytes is exceeded. Please move large on stack variables into BPF per-cpu array map. 对于使用而言，tail calls从一定程度上规避这个问题：使用bpf_tail_call跳转（注意，跳转callee函数执行完成后，不会继续执行caller剩余的逻辑，而是直接退出）的目标函数，函数内部的栈资源限制计算是独立的，会覆盖调用caller的栈帧。而常规的bpf2bpf call，调用的callee执行完成后，会继续执行caller里的代码。而且，512B的限制会对caller callee整体生效。如，下述的bpf2bpf call是会报错的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 struct event { u32 pid; // 4B u8 line[256]; // 256B }; // linux-4.16以前，需要这样声明。4.16新增了真正意义上的函数调用而非inline处理。 // static __always_inline void send_event(ctx) { static void send_event(struct pt_regs *ctx) { struct event event = {}; event.pid = bpf_get_current_pid_tgid(); event.line[0] = 49; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); } SEC(\u0026#34;uretprobe/bash_readline\u0026#34;) int uretprobe_bash_readline(struct pt_regs *ctx) { struct event event = {}; event.pid = bpf_get_current_pid_tgid(); event.line[0] = 49; send_event(ctx); // 这里发起了一个bpf2bpf call // 如果将line的长度调小，程序能够正常执行。send_event后会继续执行。 bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } 这里算是笔者目前感知到的主要差异。tail calls的特性在linux-4.2的版本就上线了。在centos-8版本的系统上运行没有问题。\n# 二、tail calls 的一个示例 这里附上执行效果和一段示例。笔者构建的场景是使用uretprobe/bash_readline作为hook点，依据返回字符串长度的奇偶性来触发不同的bpf function，分别输出不同的事件。实现效果如下。\n1 2 3 4 5 6 $ sudo ./uretprobe 2023/08/26 14:34:39 Listening for events.. 2023/08/26 14:34:45 /bin/bash:readline return value: ll 2023/08/26 14:34:45 get even event 2023/08/26 14:35:01 /bin/bash:readline return value: ls -l 2023/08/26 14:35:01 get odd event bpf代码为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 char __license[] SEC(\u0026#34;license\u0026#34;) = \u0026#34;Dual MIT/GPL\u0026#34;; struct event { u32 pid; u8 line[256]; u8 mark; }; struct { __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY); } events SEC(\u0026#34;.maps\u0026#34;); // Force emitting struct event into the ELF. const struct event *unused __attribute__((unused)); // 通过bpf-tail-call只能调用同类型的bpf函数 SEC(\u0026#34;uretprobe/bash_readline_odd\u0026#34;) int uretprobe_bash_readline_odd(struct pt_regs *ctx){ struct event event = {}; event.pid = bpf_get_current_pid_tgid(); event.line[0] = 49; event.mark = 5; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } // 通过bpf-tail-call只能调用同类型的bpf函数 SEC(\u0026#34;uretprobe/bash_readline_even\u0026#34;) int uretprobe_bash_readline_even(struct pt_regs *ctx){ struct event event = {}; event.pid = bpf_get_current_pid_tgid(); event.mark = 8; event.line[0] = 50; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } struct{ __uint(type, BPF_MAP_TYPE_PROG_ARRAY); __uint(key_size, sizeof(u32)); __uint(value_size, sizeof(u32)); __uint(max_entries, 1024); __array(values, int (void*)); } tail_jmp_table SEC(\u0026#34;.maps\u0026#34;) = { .values = { // 这里的id是可以在用户态通过map update来更新的。由此可以延伸出其他有意思的功能。这里从实际需求直接固定值了。 [135] = (void*)\u0026amp;uretprobe_bash_readline_odd, [146] = (void*)\u0026amp;uretprobe_bash_readline_even, }, }; SEC(\u0026#34;uretprobe/bash_readline\u0026#34;) int uretprobe_bash_readline(struct pt_regs *ctx) { struct event event = {}; event.pid = bpf_get_current_pid_tgid(); bpf_probe_read(\u0026amp;event.line, sizeof(event.line), (void *)PT_REGS_RC(ctx)); event.mark = 3; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); u8 line_length=0; for(line_length=0; line_length\u0026lt;80; line_length++){ if(event.line[line_length] == 0){ break; } } if (line_length % 2 == 0){ // 偶数调用 uretprobe_bash_readline_even bpf_tail_call(ctx, \u0026amp;tail_jmp_table, 146); }else{ // 奇数调用 uretprobe_bash_readline_odd bpf_tail_call(ctx, \u0026amp;tail_jmp_table, 135); } return 0; } 以上。周末愉快～\n# 三、参考文章 [1] BPF Architecture\n[2] bpf-helpers\n[3] 在 ebpf/libbpf 程序中使用尾调用（tail calls）\n[4] kernel version\n","date":"2023-08-26T12:30:00Z","permalink":"https://liyan-ah.github.io/p/ebpf-tail-calls%E7%A4%BA%E4%BE%8B/","title":"eBPF tail-calls示例"},{"content":" 原文地址Challenges of BPF Tracing Go。翻译不尽如人意，继续努力。\n# BPF追踪Go程序的挑战 当大家对Go 1.17语言调用规约(function calling convention)调整带来的性能优化感到兴奋时，我却遗憾的看到Go 1.17并没有让BPF uretprobe变得可行。事实证明，我还没有完全意识到Go的可调整的栈空间会让事情变得多复杂。\nGo极短的编译时间使得“输出调试”变得非常便捷。当你知道问题处在一个特定的变量时，往往会随手塞入一个fmt.Printf或者log.Debug或者spew.Dump来观察感兴趣的点。但是我经常工作在一个有状态的系统中，在这样的环境下“输出调试”变 得非常受限。重新编入一个log语句并且重启系统，往往意味着丢失掉可能导致异常的状态，并且日志输出可能会带来性能开销并掩盖掉bug。在这种背景下，我选择BPF工具，比如bpftrace，来定位问题。\n对应用程序开发者而言，BPF的一大强力功能是用户态的动态程序观测，在uprobe及uretprobe的基础上构建起来。uprobe会嵌入一个BPF探针在函数被调用的地方，uretprobe则会嵌入一个探针在函数返回的地方。\n比如，这里是一个使用C语言写的程序：\n1 2 3 int sum(int a, int b){ return a+b; } 使用如下的bpftrace程序可以输出上述程序的参数及返回值。\n1 2 3 4 5 6 7 8 9 10 11 #!/usr/bin/env bpftrace uprobe:./sum:\u0026#34;sum\u0026#34; { printf(\u0026#34;args: %d + %d\\n\u0026#34;, arg0, arg1); } uretprobe:./sum:\u0026#34;sum\u0026#34; { printf(\u0026#34;result: %d\\n\u0026#34;, reg(\u0026#34;ax\u0026#34;)); } 当我们运行这个bptrace脚本是，它会等待我们在另一个终端运行目标C程序，然后输出如下内容：\n1 2 3 4 5 $ sudo ./sum.bt Attaching 2 probes... args: 2 + 3 result: 5 ^C 对于一个有状态的服务来说是这是一种不可思议的强力功能，因为你可以将这些探针附加在一个运行中的程序而不需重新编译它，并且几乎不会带来性能损失。这种思想诞生在DTrace，而后由BPF将这种观测能力 移植到Linux中。\n但是Go在1.17之前的调用规约(calling convention)使得Go的追踪变得复杂。在System V AMD64调用规约中，函数入参及返回值均通 寄存器传递。BPF的工具也假定编译器会遵循这一规约，但是Go没有。不同的是，Go遵循Plan9的调用规约，即通过栈来传递参数。返回值也会通过出栈来返回。\n对于uprobe而言这意味着我们不能遵循AMD64调用规约，使用arg参数来将寄存器里的参数读出。与此相对应的是，我们需要从栈里将参数读出来。从栈里读参会比较繁琐，因为你需要获取栈帧(stack pointer)，从中读取参数地址，然后读取地址里 的参数。在bpftrace-0.9.3里，这些操作被封装成了sargx，所以还不算特别糟。\n但是对于uretprobe就不一样了。不同于每个goroutine使用一个线程，Go的是多个goroutine对应多个线程的（\u0026ldquo;M:N调度\u0026rdquo;）。所以不同于每个线程拥有2MB的栈空间，每个goroutine只有被goroutine自己维护而非操作系统维护的，短短的 2KB的栈空间。当程序需要为一个goroutine增加栈空间并且当前空间内没有足够多的空余时，运行时会将整个goroutine的栈拷贝到另外一个有足够多空间用来扩展的内存空间中。\n当你配置uretprobe时，内核也会创建一个拥有返回探针处理的uprobe。当这个uprobe触发时，它会劫持返回地址并且使用一个中断 的“跳转地址”(tramponline)来替代它。\n如果这个地址在uprobe触发时被移动了，返回地址将不再有效，所以一个uretprobe将会读取其他地方的内存。这将会使得程序崩溃。\n为了解决这个问题，你需要从程序的入口处使用uprobe来追踪程序调用，然后记录函数每个return点的偏移信息。这显得格外的粗暴并且涉及二进制信息的反汇编。\n你大概不会花费一整天来学习汇编，我当然也不会。所以让我们快速的来看下如何读取go反汇编后的内容。假设这是我们的程序：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; ) func swap(x, y string) (string, string) { return y, x } func main() { args := os.Args if len(args) \u0026lt; 3 { panic(\u0026#34;needs 2 args\u0026#34;) } a, b := swap(args[1], args[2]) fmt.Println(a, b) } 由于这段程序比较简短，Go可能会把swap函数进行内联。为了能够说明问题，我们将会使用go build -gcflags '-l' -o swapper .进行编译以防止内联。\n首先我们使用GDB来反汇编程序。你当然也可以使用objdump来进行，但是这里我们希望能够多获取些内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 $ gdb --args ./swapper hello go ... Reading symbols from ./swapper... Loading Go Runtime support. (gdb) b main.swap Breakpoint 1 at 0x497800: file /home/tim/swapper/main.go, line 9 . (gdb) run Starting program: /home/tim/swapper/swapper hello world [New LWP 3413956] [New LWP 3413957] [New LWP 3413958] [New LWP 3413959] [New LWP 3413960] Thread 1 \u0026#34;swapper\u0026#34; hit Breakpoint 1, main.swap (x=..., y=..., ~r2=..., ~r3=...) at /home/tim/swapper/main.go:9 9 return y, x (gdb) disas Dump of assembler code for function main.swap: =\u0026gt; 0x0000000000497800 \u0026lt;+0\u0026gt;: mov rax,QWORD PTR [rsp+0x18] 0x0000000000497805 \u0026lt;+5\u0026gt;: mov QWORD PTR [rsp+0x28],rax 0x000000000049780a \u0026lt;+10\u0026gt;: mov rax,QWORD PTR [rsp+0x20] 0x000000000049780f \u0026lt;+15\u0026gt;: mov QWORD PTR [rsp+0x30],rax 0x0000000000497814 \u0026lt;+20\u0026gt;: mov rax,QWORD PTR [rsp+0x8] 0x0000000000497819 \u0026lt;+25\u0026gt;: mov QWORD PTR [rsp+0x38],rax 0x000000000049781e \u0026lt;+30\u0026gt;: mov rax,QWORD PTR [rsp+0x10] 0x0000000000497823 \u0026lt;+35\u0026gt;: mov QWORD PTR [rsp+0x40],rax 0x0000000000497828 \u0026lt;+40\u0026gt;: ret End of assembler dump. 总的来看，我们有4个指针需要移动：每个string都有一个长度以及一段字节码，并且我们有两个string。函数将指针重新排列在栈上，并且当函数返回时，这些值会从栈上弹出。\n第一个指令是将栈帧上偏移量为0x18的值移动到暂存寄存器rax。让我们查看下这个地址，然后看看它是否是一个可读的string：\n1 2 3 4 (gdb) x/a $rsp+0x18 0xc00011af18: 0x7fffffffddcd (gdb) x/s 0x7fffffffddcd 0x7fffffffddcd: \u0026#34;go\u0026#34; 妙啊！所以第一个指令的意思是，我们将值喜庆string的64-bit的指针(QWORD PTR)赋给了暂存寄存器。下一个指令是将同一个指针从暂存区移动到栈顶(rsp+0x28)。\n下一个指令是将0x20上的任意值移动到暂存区。这是个整数：我们字符串的长度！\n1 2 (gdb) x/a $rsp+0x20 0xc00011af20: 0x2 然后这个整数就被从暂存区移动到栈顶(rsp+0x30)。接下来的四个指令对另外两个参数做了相同的事情：\n1 2 3 4 5 6 7 (gdb) x/a $rsp+0x8 0xc00011af08: 0x7fffffffddc7 (gdb) x/s 0x7fffffffddc7 0x7fffffffddc7: \u0026#34;hello\u0026#34; (gdb) x/a $rsp+0x10 0xc00011af10: 0x5 我们单步执行(si)8次，直到来到ret指令处：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 ... (gdb) si 0x0000000000497828 in main.swap (x=..., y=..., ~r2=..., ~r3=...) at /home/tim/swapper/main.go:9 9 return y, x (gdb) disas Dump of assembler code for function main.swap: 0x0000000000497800 \u0026lt;+0\u0026gt;: mov rax,QWORD PTR [rsp+0x18] 0x0000000000497805 \u0026lt;+5\u0026gt;: mov QWORD PTR [rsp+0x28],rax 0x000000000049780a \u0026lt;+10\u0026gt;: mov rax,QWORD PTR [rsp+0x20] 0x000000000049780f \u0026lt;+15\u0026gt;: mov QWORD PTR [rsp+0x30],rax 0x0000000000497814 \u0026lt;+20\u0026gt;: mov rax,QWORD PTR [rsp+0x8] 0x0000000000497819 \u0026lt;+25\u0026gt;: mov QWORD PTR [rsp+0x38],rax 0x000000000049781e \u0026lt;+30\u0026gt;: mov rax,QWORD PTR [rsp+0x10] 0x0000000000497823 \u0026lt;+35\u0026gt;: mov QWORD PTR [rsp+0x40],rax =\u0026gt; 0x0000000000497828 \u0026lt;+40\u0026gt;: ret End of assembler dump. 函数已经完成了所有的功能，并且我们来到了这个函数将会返回给调用者的地方。现在我们可以确认下栈顶的内存地址：\n1 2 3 4 5 6 (gdb) x/a $rsp+0x40 0xc00011af40: 0x5 (gdb) x/a $rsp+0x38 0xc00011af38: 0x7fffffffddc7 (gdb) x/s 0x7fffffffddc7 0x7fffffffddc7: \u0026#34;hello\u0026#34; 此时，我们可以看到我们已经将返回值移动到距离栈顶一定偏移量的指针上，而指针指向字符串。因为是在栈上，所以是“后进先出”的。这里可能会有些困惑因为函数的主要功能是交换这两个字符串。\n如果你跟上了我的思路，自然的就能画出这样的分布： 如何将我们所学的内容应用到BPF呢？\n首先，我们知道了尽管Go函数仅定义了两个参数，但实际上栈上有四个参数。所以我们需要定义两组栈上的参数。我们可以将它们正确的通过bpftrace里的str函数：bpftrace:str(sarg0, sarg1)来输出x，str(sarg2, sarg3)来 输出y。\n然后，尽管uretprobe无法工作，我们可以通过添加一个指向return指令偏移量的uprobe来模拟它。如果你再看下汇编指令，就能看到这个偏移地址是+40。所以uprobe最终看起来 是：uprobe:./bin/swapper:\u0026quot;main.swap\u0026quot;+40。当我们触发这个探针时，我们仅查看返回值寄存器无法满足目标。我们需要检查上述发现的每个返回值的偏移地址。最终的bpftrace程序如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 #!/usr/bin/env bpftrace uprobe:./swapper:\u0026#34;main.swap\u0026#34; { printf(\u0026#34;swapping \\\u0026#34;%s\\\u0026#34; and \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(sarg0, sarg1), str(sarg2, sarg3)); } uprobe:./swapper:\u0026#34;main.swap\u0026#34;+40 { printf(\u0026#34;results: \\\u0026#34;%s\\\u0026#34; and \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(*(reg(\u0026#34;sp\u0026#34;)+0x28), *(reg(\u0026#34;sp\u0026#34;)+0x30)), str(*(reg(\u0026#34;sp\u0026#34;)+0x38), *(reg(\u0026#34;sp\u0026#34;)+0x40)) ) } 我们在一个终端运行这段代码，在另一个终端运行./swapper hello world：\n1 2 3 4 5 $ sudo ./swapper.bt Attaching 2 probes... swapping \u0026#34;hello\u0026#34; and \u0026#34;go\u0026#34; results: \u0026#34;go\u0026#34; and \u0026#34;hello\u0026#34; ^C 如你所见，仅一个return probe就需要做很多的准备。如果我们的程序有很多的返回点，我们不得不为每个返回点都做一次相同的事情。\n对于一些复杂的函数，如Nomad的FSM Apply方法，我不得不采用如下方式生成bpftrace代码的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 #!/usr/bin/env bash cat \u0026lt;\u0026lt;EOF #!/usr/bin/env bpftrace /* Get Nomad FSM.Apply latency Note: using sarg with offsets isn\u0026#39;t really concurrency safe and emits a warning */ EOF base=$(objdump --disassemble=\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34; \\ -Mintel -S ./bin/nomad \\ | awk \u0026#39;/hashicorp/{print $1}\u0026#39; \\ | head -1) objdump --disassemble=\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34; \\ -Mintel -S ./bin/nomad \\ | awk -F\u0026#39; |:\u0026#39; \u0026#39;/ret/{print $2}\u0026#39; \\ | xargs -I % \\ python3 -c \u0026#34;print(\u0026#39;uprobe:./bin/nomad:\\\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\\\u0026#34;+\u0026#39; + hex(0x% - 0x$base)) print(\u0026#39;{\u0026#39;) print(\u0026#39; @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000);\u0026#39;) print(\u0026#39; delete(@start[str(*sarg1)]);\u0026#39;) print(\u0026#39;}\u0026#39;) print(\u0026#39;\u0026#39;) \u0026#34; 这样就得到了下面近300行的庞然大物：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 231 232 233 234 235 236 237 238 239 240 241 242 243 244 245 246 247 248 249 250 251 252 253 254 255 256 257 258 259 260 261 262 263 264 265 266 267 268 269 270 271 272 273 274 275 276 277 278 279 280 281 282 283 284 285 286 287 288 289 290 291 292 293 294 295 296 297 298 299 #!/usr/bin/env bpftrace /* Get Nomad FSM.Apply latency Note: using sarg with offsets isn\u0026#39;t really concurrency safe and emits a warning */ uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1d3 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x257 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x2f3 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x377 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x3fb { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x49b { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x51b { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x5a0 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x634 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x6b4 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x738 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x7e7 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x86e { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x8ee { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x982 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xa06 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xa8e { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xb27 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xbae { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xc2e { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xcc2 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xd46 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xdce { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xe77 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xefb { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0xf80 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1014 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1098 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x111c { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x11b7 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x123b { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x12c0 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1350 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x13d0 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1450 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x14f7 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1577 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x15f7 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x168f { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x170f { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x178f { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x18ca { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1948 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x19ce { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1a52 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1a6d { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1b07 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1b87 { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } uprobe:./bin/nomad:\u0026#34;github.com/hashicorp/nomad/nomad.(*nomadFSM).Apply\u0026#34;+0x1c0e { @usecs = hist((nsecs - @start[str(*sarg1)]) / 1000); delete(@start[str(*sarg1)]); } Go 1.17引入的新的调用规约使得这种情况得到改善，但是仍没有解决uretprobe的问题。相同的swapper代码在Go 1.17上将会反汇编成如下内容：\n1 2 3 4 5 6 7 8 9 10 11 12 (gdb) disas Dump of assembler code for function main.swap: =\u0026gt; 0x000000000047e260 \u0026lt;+0\u0026gt;: mov QWORD PTR [rsp+0x8],rax 0x000000000047e265 \u0026lt;+5\u0026gt;: mov QWORD PTR [rsp+0x18],rcx 0x000000000047e26a \u0026lt;+10\u0026gt;: mov rdx,rax 0x000000000047e26d \u0026lt;+13\u0026gt;: mov rax,rcx 0x000000000047e270 \u0026lt;+16\u0026gt;: mov rsi,rbx 0x000000000047e273 \u0026lt;+19\u0026gt;: mov rbx,rdi 0x000000000047e276 \u0026lt;+22\u0026gt;: mov rcx,rdx 0x000000000047e279 \u0026lt;+25\u0026gt;: mov rdi,rsi 0x000000000047e27c \u0026lt;+28\u0026gt;: ret End of assembler dump. 所有的值传递操作都通过寄存器进行了，减少了指针寻址的内容：\n1 2 3 4 5 6 7 8 (gdb) x/s $rax 0x7fffffffddca: \u0026#34;hello\u0026#34; (gdb) i r $rbx rbx 0x5 5 (gdb) x/s $rcx 0x7fffffffddd0: \u0026#34;go\u0026#34; (gdb) i r $rdi rdi 0x2 2 （我确实不知道为什么第二个参数的长度存储在rdi而非rdx，如果你知道的话，我很乐意知晓下）（译者按：参见golang-1.17参数调用规约）。\n返回值也放到了寄存器里，这意味着我们可以通过uretprobe来直接获取。我们的bpftrace程序变得简洁了许多：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 #!/usr/bin/env bpftrace uprobe:./swapper:\u0026#34;main.swap\u0026#34; { printf(\u0026#34;swapping \\\u0026#34;%s\\\u0026#34; and \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(reg(\u0026#34;ax\u0026#34;)), str(reg(\u0026#34;cx\u0026#34;))); } uretprobe:./swapper:\u0026#34;main.swap\u0026#34; { printf(\u0026#34;results: \\\u0026#34;%s\\\u0026#34; and \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(reg(\u0026#34;ax\u0026#34;)), str(reg(\u0026#34;cx\u0026#34;))); } $ sudo ./swapper.bt Attaching 2 probes... swapping \u0026#34;hello\u0026#34; and \u0026#34;go\u0026#34; results: \u0026#34;go\u0026#34; and \u0026#34;hello\u0026#34; ^C 所以问题是什么？这样不是很好么？目前为止，我们关注的示例都没有需要很多栈空间以至于运行时需要对栈进行调整。而运行时的调整是uretprobe失败的原因。\n看下下面的示例。temp变量从没有逃逸到对上（我们可以通过添加-gcflags -m进行编译以验证这一点），所以我们需要在goroutine栈上申请sizeof(Example)*count大小的空间。如果我们执行./stacker 1000000，将会申请 多余能够提供的空闲内存，Go的运行时将不得不移动栈空间。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;os\u0026#34; \u0026#34;strconv\u0026#34; ) type Example struct { ID int Name string } func stacker(count int) string { var result int for i := 0; i \u0026lt; count; i++ { temp := Example{ID: i * 2, Name: fmt.Sprintf(\u0026#34;%d\u0026#34;, result)} result += temp.ID } s := fmt.Sprintf(\u0026#34;hello: %d\u0026#34;, result) return s } func main() { args := os.Args if len(args) \u0026lt; 2 { panic(\u0026#34;needs 1 arg\u0026#34;) } count, err := strconv.Atoi(args[1]) if err != nil { panic(\u0026#34;arg needs to be a number\u0026#34;) } s := stacker(count) fmt.Println(s) } 这是我们的bpftrace程序：\n1 2 3 4 5 6 #!/usr/bin/env bpftrace uretprobe:./stacker:\u0026#34;main.stacker\u0026#34; { printf(\u0026#34;result: \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(reg(\u0026#34;ax\u0026#34;))); } 如果我们在uretprobe加载的同时，给stacker一个巨大的参数count，程序将会崩溃！\n1 2 3 4 $ ./stacker 1000000 runtime: unexpected return pc for main.stacker called from 0x7fffffffe000 stack: frame={sp:0xc000074ef0, fp:0xc000074f48} stack=[0xc000074000,0xc000075000) ... 这里是崩溃时完整的信息：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 $ ./stacker 1000000 runtime: unexpected return pc for main.stacker called from 0x7fffffffe000 stack: frame={sp:0xc000074ef0, fp:0xc000074f48} stack=[0xc000074000,0xc000075000) 0x000000c000074df0: 0x0000000000000002 0x000000c000508100 0x000000c000074e00: 0x000000c000508000 0x00000000004672e0 \u0026lt;sync.(*Pool).pinSlow·dwrap·3+0x0000000000000000\u0026gt; 0x000000c000074e10: 0x0000000000557f58 0x000000c000074e08 0x000000c000074e20: 0x0000000000419860 \u0026lt;runtime.gcAssistAlloc.func1+0x0000000000000000\u0026gt; 0x000000c0000001a0 0x000000c000074e30: 0x0000000000010000 0x000000c000074eb8 0x000000c000074e40: 0x000000000040b305 \u0026lt;runtime.mallocgc+0x0000000000000125\u0026gt; 0x000000c0000001a0 0x000000c000074e50: 0x0000000000000002 0x000000c000074e88 0x000000c000074e60: 0x000000c000074e88 0x000000000047a06a \u0026lt;fmt.(*pp).free+0x00000000000000ca\u0026gt; 0x000000c000074e70: 0x0000000000522100 0x00000000004938e0 0x000000c000074e80: 0x000000c00007a820 0x000000c000074ee0 0x000000c000074e90: 0x000000000047a245 \u0026lt;fmt.Sprintf+0x0000000000000085\u0026gt; 0x000000c00007a820 0x000000c000074ea0: 0x000000c00012b230 0x000000000000000b 0x000000c000074eb0: 0x000000c0000001a0 0x000000c000074ee0 0x000000c000074ec0: 0x00000000004095e5 \u0026lt;runtime.convT64+0x0000000000000045\u0026gt; 0x0000000000000008 0x000000c000074ed0: 0x0000000000487ee0 0x000000c00007a800 0x000000c000074ee0: 0x000000c000074f38 0x0000000000480d7b \u0026lt;main.stacker+0x000000000000003b\u0026gt; 0x000000c000074ef0: \u0026lt;0x0000000644e0732a 0x0000000000000002 0x000000c000074f00: 0x000000c000074f28 0x0000000000000001 0x000000c000074f10: 0x0000000000000001 0x0000000644e0732a 0x000000c000074f20: 0x00000000000280fa 0x0000000000000000 0x000000c000074f30: 0x0000000000000000 0x000000c000074f70 0x000000c000074f40: !0x00007fffffffe000 \u0026gt;0x00000000000f4240 0x000000c000074f50: 0x0000000000000007 0x0000000000415d45 \u0026lt;runtime.gcenable+0x0000000000000085\u0026gt; 0x000000c000074f60: 0x00000000004873a0 0x000000c0000001a0 0x000000c000074f70: 0x000000c000074fd0 0x0000000000432047 \u0026lt;runtime.main+0x0000000000000227\u0026gt; 0x000000c000074f80: 0x000000c000022060 0x0000000000000000 0x000000c000074f90: 0x0000000000000000 0x0000000000000000 0x000000c000074fa0: 0x0100000000000000 0x0000000000000000 0x000000c000074fb0: 0x000000c0000001a0 0x0000000000432180 \u0026lt;runtime.main.func2+0x0000000000000000\u0026gt; 0x000000c000074fc0: 0x000000c000074fa6 0x000000c000074fb8 0x000000c000074fd0: 0x0000000000000000 0x000000000045ab01 \u0026lt;runtime.goexit+0x0000000000000001\u0026gt; 0x000000c000074fe0: 0x0000000000000000 0x0000000000000000 0x000000c000074ff0: 0x0000000000000000 0x0000000000000000 fatal error: unknown caller pc runtime stack: runtime.throw({0x4988ba, 0x516760}) /usr/local/go/src/runtime/panic.go:1198 +0x71 runtime.gentraceback(0x400, 0x400, 0x80, 0x7f73bbffafff, 0x0, 0x0, 0x7fffffff, 0x7ffc46fe0e28, 0x7f73bbe23200, 0x0) /usr/local/go/src/runtime/traceback.go:274 +0x1956 runtime.scanstack(0xc0000001a0, 0xc000030698) /usr/local/go/src/runtime/mgcmark.go:748 +0x197 runtime.markroot.func1() /usr/local/go/src/runtime/mgcmark.go:232 +0xb1 runtime.markroot(0xc000030698, 0x14) /usr/local/go/src/runtime/mgcmark.go:205 +0x170 runtime.gcDrainN(0xc000030698, 0x10000) /usr/local/go/src/runtime/mgcmark.go:1134 +0x14b runtime.gcAssistAlloc1(0xc0000001a0, 0xc000074b58) /usr/local/go/src/runtime/mgcmark.go:537 +0xef runtime.gcAssistAlloc.func1() /usr/local/go/src/runtime/mgcmark.go:448 +0x25 runtime.systemstack() /usr/local/go/src/runtime/asm_amd64.s:383 +0x49 goroutine 1 [GC assist marking (scan)]: runtime.systemstack_switch() /usr/local/go/src/runtime/asm_amd64.s:350 fp=0xc000074de8 sp=0xc000074de0 pc=0x458a20 runtime.gcAssistAlloc(0xc0000001a0) /usr/local/go/src/runtime/mgcmark.go:447 +0x18b fp=0xc000074e48 sp=0xc000074de8 pc=0x41974b runtime.mallocgc(0x8, 0x487ee0, 0x0) /usr/local/go/src/runtime/malloc.go:959 +0x125 fp=0xc000074ec8 sp=0xc000074e48 pc=0x40b305 runtime.convT64(0x644e0732a) /usr/local/go/src/runtime/iface.go:364 +0x45 fp=0xc000074ef0 sp=0xc000074ec8 pc=0x4095e5 runtime: unexpected return pc for main.stacker called from 0x7fffffffe000 stack: frame={sp:0xc000074ef0, fp:0xc000074f48} stack=[0xc000074000,0xc000075000) 0x000000c000074df0: 0x0000000000000002 0x000000c000508100 0x000000c000074e00: 0x000000c000508000 0x00000000004672e0 \u0026lt;sync.(*Pool).pinSlow·dwrap·3+0x0000000000000000\u0026gt; 0x000000c000074e10: 0x0000000000557f58 0x000000c000074e08 0x000000c000074e20: 0x0000000000419860 \u0026lt;runtime.gcAssistAlloc.func1+0x0000000000000000\u0026gt; 0x000000c0000001a0 0x000000c000074e30: 0x0000000000010000 0x000000c000074eb8 0x000000c000074e40: 0x000000000040b305 \u0026lt;runtime.mallocgc+0x0000000000000125\u0026gt; 0x000000c0000001a0 0x000000c000074e50: 0x0000000000000002 0x000000c000074e88 0x000000c000074e60: 0x000000c000074e88 0x000000000047a06a \u0026lt;fmt.(*pp).free+0x00000000000000ca\u0026gt; 0x000000c000074e70: 0x0000000000522100 0x00000000004938e0 0x000000c000074e80: 0x000000c00007a820 0x000000c000074ee0 0x000000c000074e90: 0x000000000047a245 \u0026lt;fmt.Sprintf+0x0000000000000085\u0026gt; 0x000000c00007a820 0x000000c000074ea0: 0x000000c00012b230 0x000000000000000b 0x000000c000074eb0: 0x000000c0000001a0 0x000000c000074ee0 0x000000c000074ec0: 0x00000000004095e5 \u0026lt;runtime.convT64+0x0000000000000045\u0026gt; 0x0000000000000008 0x000000c000074ed0: 0x0000000000487ee0 0x000000c00007a800 0x000000c000074ee0: 0x000000c000074f38 0x0000000000480d7b \u0026lt;main.stacker+0x000000000000003b\u0026gt; 0x000000c000074ef0: \u0026lt;0x0000000644e0732a 0x0000000000000002 0x000000c000074f00: 0x000000c000074f28 0x0000000000000001 0x000000c000074f10: 0x0000000000000001 0x0000000644e0732a 0x000000c000074f20: 0x00000000000280fa 0x0000000000000000 0x000000c000074f30: 0x0000000000000000 0x000000c000074f70 0x000000c000074f40: !0x00007fffffffe000 \u0026gt;0x00000000000f4240 0x000000c000074f50: 0x0000000000000007 0x0000000000415d45 \u0026lt;runtime.gcenable+0x0000000000000085\u0026gt; 0x000000c000074f60: 0x00000000004873a0 0x000000c0000001a0 0x000000c000074f70: 0x000000c000074fd0 0x0000000000432047 \u0026lt;runtime.main+0x0000000000000227\u0026gt; 0x000000c000074f80: 0x000000c000022060 0x0000000000000000 0x000000c000074f90: 0x0000000000000000 0x0000000000000000 0x000000c000074fa0: 0x0100000000000000 0x0000000000000000 0x000000c000074fb0: 0x000000c0000001a0 0x0000000000432180 \u0026lt;runtime.main.func2+0x0000000000000000\u0026gt; 0x000000c000074fc0: 0x000000c000074fa6 0x000000c000074fb8 0x000000c000074fd0: 0x0000000000000000 0x000000000045ab01 \u0026lt;runtime.goexit+0x0000000000000001\u0026gt; 0x000000c000074fe0: 0x0000000000000000 0x0000000000000000 0x000000c000074ff0: 0x0000000000000000 0x0000000000000000 main.stacker(0xf4240) /home/tim/stacker/main.go:17 +0x3b fp=0xc000074f48 sp=0xc000074ef0 pc=0x480d7b 这样，我们仍然不得不使用之前实践的uprobe+offset的方式来进行uretprobe的实现。bpftrace程序会正常工作，但是地址的偏移量将很大程度上取决于使用的Go版本：\n1 2 3 4 5 6 #!/usr/bin/env bpftrace uprobe:./stacker:\u0026#34;main.stacker\u0026#34;+213 { printf(\u0026#34;result: \\\u0026#34;%s\\\u0026#34;\\n\u0026#34;, str(reg(\u0026#34;ax\u0026#34;))); } 这个问题看起来不会在Go的运行时侧修复，因为可重新分配的栈空间是整个goroutine内存模型的基础。但是通过uprobe以及一点小小的调整，你可以实现uretprobe的功能。\n","date":"2023-06-25T17:08:00Z","permalink":"https://liyan-ah.github.io/p/bpf%E8%BF%BD%E8%B8%AAgo%E7%A8%8B%E5%BA%8F%E7%9A%84%E6%8C%91%E6%88%98/","title":"BPF追踪Go程序的挑战"},{"content":" 笔者一直都是文本编辑器教派的忠实拥趸：期望将所有的任务都通过文本编辑，而非鼠标/触摸板等，进行实现。从早年的Vim，到现而今的Emacs，对文本化完成需求是越来越习惯，也越来越依赖了。最近刚好有了些时间，把最近的一些实践整理下。\n在之前的文章，emacs org-mode 绘制思维导图，中，笔者有提到在探索不跳出Emacs这一文本编辑器的情况下，完成思维导图绘制的需求。在翻了一些文章后，找到了一款神器：PlantUML。其完美的匹配了笔者的需求：\n不仅是思维导图，工程、文档常用的UML图像也能全部支持文本化表示； 功能强大，颜色、文本等格式均能支持； Emacs友好，而且可以集成到Org-mode里使用。 而且，PlantUML支持在线使用，意味着能够很方便的获取、使用。这里做下介绍。\n# 一、依赖内容 这里先列一下笔者使用时的配置：\nplantuml.jar，安装在本地后，可以通过配置，在本地进行文本-\u0026gt;多格式输出的编译。plantuml.jar 下载； plantuml 配置。由于笔者还是使用的Emacs，这里列一下参照官网配置的Emacs设置。 1 2 3 4 5 6 7 8 9 ;; plantuml ;; 安装 plantuml-mode (ensure-package-installed \u0026#39;plantuml-mode) ;; 设置 plantuml.jar 的本地路径 (setq org-plantuml-jar-path (expand-file-name \u0026#34;~/.emacs.d/tools/plantuml.jar\u0026#34;)) ;; 将 .plantuml 后缀文件默认以 plantuml-mode 打开。非必需，后面都在 org-mode 里使用了 (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\.plantuml\\\u0026#39;\u0026#34; . plantuml-mode)) ;; 比较重要，在 org-mode 里声明 plantuml (org-babel-do-load-languages \u0026#39;org-babel-load-languages \u0026#39;((plantuml . t))) 配置很简单。下面就可以愉快的使用了。\n# 二、plantuml 介绍 plantuml官网，目前支持的部分图标类型：\nUML 图 时序图 用例图 状态图 活动图 类图 用例图 等等 非UML图 思维导图 甘特图 工作分解结构图 等等 在官网中，对每种图都给出了教程及示例，可以通过在线生成 进行感受。\nPlantUML的输入是文本，输出可以是ASCII, PNG, SVG等等格式。满足日常工作的需求。\n# 三、思维导图 # 3.1 一个简单的思维导图 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 #+begin_src plantuml :file mindmap.png @startmindmap \u0026lt;style\u0026gt; mindmapDiagram { .green { BackgroundColor lightgreen } .yellow { BackgroundColor yellow } .rose{ BackgroundColor #FFBBCC } } \u0026lt;/style\u0026gt; * emacs planuml 介绍 \u0026lt;\u0026lt;rose\u0026gt;\u0026gt; left side ** 依赖内容 \u0026lt;\u0026lt;yellow\u0026gt;\u0026gt; ***_ plantuml.jar 安装 ***_ plantuml 配置 ** plantuml 介绍 \u0026lt;\u0026lt;yellow\u0026gt;\u0026gt; ***_ 支持多种UML文本化编辑 \\ 多种格式文件输出的组件 ***_ 在线体验 right side ** 思维导图 \u0026lt;\u0026lt;green\u0026gt;\u0026gt; ***_ 一个简单的思维导图 ***_ 编译输出 ** 时序图 \u0026lt;\u0026lt;green\u0026gt;\u0026gt; ***_ 一个简单的时序图 ***_ 编译输出 @endmindmap #+end_src 由于笔者已经在Org-mode里配置了plantuml，因此只要在begin_src后声明plantuml即可。通过:file mindmap.png指定了输出的文件为png格式内容。C-c C-e或者org-export-dispatch即可通过org-mode的输出界面触发编译、输出。\n# 3.2 编译输出 输出结果： mindmap.png # 四、时序图 # 4.1 一个简单的时序图 这里来一点展示内容更丰富的UML时序图实际使用示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 #+begin_src plantuml :file ngx_request.png @startuml title: nginx+php请求处理示例 [-\u0026gt;nginx: \u0026lt;font color=blue\u0026gt;/caller_path note right of nginx nginx 视角: caller=nginx, caller_func=/caller_path, callee=php, callee_func=/index.php/caller_path end note activate nginx #yellow nginx-\u0026gt;php: \u0026lt;font color=red\u0026gt;/index.php/caller_path activate php #yellow note right of php #gray laravel end note php-\u0026gt;callee: \u0026lt;font color=blue\u0026gt;/callee_path note right of php php 视角: caller=php, caller_func=/index.php/caller_path, callee=callee, callee_func=callee_path end note activate callee callee-\u0026gt;php: response deactivate callee php-\u0026gt;nginx: response deactivate php nginx-\u0026gt;[: response deactivate nginx note over nginx, php #aqua: 实际四元组: \\ caller=nginx caller_func=/caller_path, callee=callee, callee_func=callee_path, @enduml #+end_src # 4.2 编译输出 输出结果如下： ngx_request.png 可以看到，基本上能够满足一般工程文档使用的需求。\n以上是本次介绍的内容。周末愉快～\n","date":"2023-04-21T20:51:00Z","permalink":"https://liyan-ah.github.io/p/plantuml-%E6%96%87%E6%9C%AC%E5%8C%96%E7%BB%98%E5%88%B6uml%E5%A4%9A%E7%B1%BB%E5%9B%BE%E8%A1%A8/","title":"PlantUML-文本化绘制UML多类图表"},{"content":" 最近有了些时间，继续整理下之前的项目。服务四元组的信息对于故障处置、根因定位等都有重要意义。使用eBPF可以做到无侵入用户代码获取服务四元组信息的功能。这一点在工程应用上很有意义。笔者在这方面投入了一些精力，这里做一下简单的总结。\n服务四元组指的是[caller, caller_func, callee, callee_func]四元组。如下图是一个调用示例，站在服务A的角度，就存在如下两个四元组: [A, /a, B, /b]，[A, /a, C, /c]。站在服务B, C的角度，也存在两个四元组（可能有不同的理解）: [B, /b, none, none], [C, /c, none, none]。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 service call ,-------. ,-. ,-. ,-. |outisde| |A| |B| |C| `---+---\u0026#39; `+\u0026#39; `+\u0026#39; `+\u0026#39; | /a | | | |--------------\u0026gt;| | | | | | | | | /b | | | |-----------\u0026gt;| | | | | | | | /c | | |------------------------\u0026gt;| ,---+---. ,+. ,+. ,+. |outisde| |A| |B| |C| `-------\u0026#39; `-\u0026#39; `-\u0026#39; `-\u0026#39; 在弄清楚四元组是什么之后，下面进入今天的话题：如何使用BPF来采集四元组。需要说明的是，笔者这里的语言使用的是golang-1.16。golang不同语言版本间的区别，见：golang-1.17+调用规约。\n值得注意的是，关于观测服务数据，是有很多解决方案的。本文仅是笔者实践的一种解决方案，在文末会简单提到这种方案的优缺点。\n按照惯例，先看下效果吧：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 启动采集 bpftrace ./http.bt Attaching 2 probes... # 未触发请求前，停止在这里 caller: # 触发请求后，输出 caller_path: /handle callee: method: GET host: 0.0.0.0:9932 url: /echo caller: caller_path: /echo callee: none # 开始服务 ./http_demo \u0026amp; # 触发请求 curl http://0.0.0.0:9932/handle # 一段golang代码示例 下面是一段golang的http服务的代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) type Resp struct { Errno int `json:\u0026#34;errno\u0026#34;` Errmsg string `json:\u0026#34;errmsg\u0026#34;` } //go:noinline func echo(c *gin.Context) { c.JSON(http.StatusOK, \u0026amp;Resp{ Errno: 0, Errmsg: \u0026#34;ok\u0026#34;, }) return } //go:noinline func handle(c *gin.Context) { client := http.Client{} req, _ := http.NewRequest(http.MethodGet, \u0026#34;http://0.0.0.0:9932/echo\u0026#34;, nil) resp, err := client.Do(req) if err != nil { fmt.Println(\u0026#34;failed to request\u0026#34;, err.Error()) c.JSON(http.StatusOK, \u0026amp;Resp{ Errno: 1, Errmsg: \u0026#34;failed to request\u0026#34;, }) return } respB, err := ioutil.ReadAll(resp.Body) if err != nil { fmt.Println(\u0026#34;read resp failed\u0026#34;) c.JSON(http.StatusOK, \u0026amp;Resp{ Errno: 2, Errmsg: \u0026#34;failed to read request\u0026#34;, }) return } defer resp.Body.Close() fmt.Println(\u0026#34;resp: \u0026#34;, string(respB)) c.JSON(http.StatusOK, \u0026amp;Resp{ Errno: 0, Errmsg: \u0026#34;request okay\u0026#34;, }) return } func main() { s := http.Server{ Addr: \u0026#34;0.0.0.0:9932\u0026#34;, } r := gin.Default() r.GET(\u0026#34;/echo\u0026#34;, echo) r.GET(\u0026#34;/handle\u0026#34;, handle) s.Handler = r if err := s.ListenAndServe(); err != nil { fmt.Println(\u0026#34;error, \u0026#34;, err.Error()) } } 这是一段比较简单的golang代码。需要注意的是，这里的四元组是：[local, /handle, local, /echo]。为了便于示例说明，这里的handle的逻辑和请求下游的逻辑是串行的，没有开新的goroutine。这一点很重要，后面会说明。\n# 采集的逻辑 下面是采集的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 /* func (sh serverHandler) ServeHTTP(rw ResponseWriter, req *Request) { ... } type Request struct { Method string URL *url.URL } type URL struct { Scheme string Opaque string // encoded opaque data User *Userinfo // username and password information Host string // host or host:port Path string // path (relative paths may omit leading slash) RawPath string // encoded path hint (see EscapedPath method) ForceQuery bool // append a query (\u0026#39;?\u0026#39;) even if RawQuery is empty RawQuery string // encoded query values, without \u0026#39;?\u0026#39; Fragment string // fragment for references, without \u0026#39;#\u0026#39; RawFragment string // encoded fragment hint (see EscapedFragment method) } */ uprobe:./http_demo:net/http.serverHandler.ServeHTTP { $req_addr = sarg3; $url_addr = *(uint64*)($req_addr+16); $path_addr = *(uint64*)($url_addr+56); $path_len = *(uint64*)($url_addr+64); // 在http请求触发处，依据pid将caller_func存储起来 @caller_path_addr[pid] = $path_addr; @caller_path_len[pid] = $path_len; @callee_set[pid] = 0; } /* type Request struct { Method string URL *url.URL } func (c *Client) do(req *Request) (retres *Response, reterr error) { ... } */ uprobe:./http_demo:\u0026#34;net/http.(*Client).do\u0026#34; { // 依据 pid 获取 caller 信息 printf(\u0026#34;caller: caller_path: %s \u0026#34;, str(@caller_path_addr[pid], @caller_path_len[pid])); $req_addr = sarg1; // 获取 callee 信息 $addr = *(uint64*)($req_addr); $len = *(uint64*)($req_addr + 8); printf(\u0026#34;callee: method: %s \u0026#34;, str($addr, $len)); $url_addr = *(uint64*)($req_addr + 16); $addr = *(uint64*)($url_addr + 40); $len = *(uint64*)($url_addr + 48); printf(\u0026#34; host: %s \u0026#34;, str($addr, $len)); $addr = *(uint64*)($url_addr + 56); $len = *(uint64*)($url_addr + 64); printf(\u0026#34; url: %s \u0026#34;, str($addr, $len)); @callee_set[pid] = 1 } uprobe:./http_demo:\u0026#34;net/http.(*response).finishRequest\u0026#34; { // 如果没有下游请求，单独输出 if (@callee_set[pid] == 0){ printf(\u0026#34;caller: caller_path: %s \u0026#34;, str(@caller_path_addr[pid], @caller_path_len[pid])); printf(\u0026#34;callee: none \u0026#34;); @callee_set[pid] = 1; } } 到这里就基本上把主要思路介绍清楚了。需要说明的是，示例里使用的是pid作为caller_map里的key，当存在并发时，pid肯定是不够的。对于golang语言，可以使用goid作为caller_map的key。目前对于使用golang常规的使用来说，就足够了。引入goid的另一个问题是，业务代码里可能使用新的goroutine来进行callee的请求、处理。这里就需要引入goroutine的派生关系维护，或者session trace。关于session trace，可以参见基于ebpf实现的gls这部分的逻辑，思路都是一致的。\n但是session trace能够覆盖所有的场景么？看一下下面的逻辑：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 var( info = make(chan interface{}, 1000) ) func handle(info chan interface{}){ for{ select{ case inf,ok \u0026lt;- info: // do some request ... } } } type Resp struct{ Code int `json:\u0026#34;code\u0026#34;` Msg string `json:\u0026#34;msg\u0026#34;` } func Handler(ctx *gin.Context){ info \u0026lt;- ctx c.JSON(http.StatusOk, \u0026amp;Resp{Code: 0, Msg: \u0026#34;okay\u0026#34;}) } func main(){ go handle(info) // normal http register and start ... } 以上是一种http请求的处理方式，大抵的意思是对于每个请求，handleFunc并没有立即有效响应，而是通过channel将一部分的请求信息传递到其他goroutine里处理。这样虽然callerFunc的响应客观上触发了callee的请求，但是handle()所在的goroutine并不是handleFunc派生的。这种场景下，trace也就断掉了。同理，如果是开了goroutine pool来处理，也会丢失。\n# 方案的优缺点 优点。一如笔者在示例及demo中介绍的，对于方案trace能够覆盖的通信类型，callerFunc, callee, calleeFunc等的获取可以直接通过解析函数的参数来获取。对比基于kprobe的报文解析方案，即通过hook tcp_send tcp_rcv等来获取传输层报文，不需要进行复杂的报文解析。这就使得整个解析的触发次数接近O(n)，即一次http交互，一次probe的触发。此外，hook kprobe显然会对机器上所有会调用这个kprobe的进程造成影响，因为其他进程也会等待着调用kprobe。但是本方案里涉及的还仅是目标程序启动后的进程受到影响，并不会从调用角度来影响其他进程（但是CPU的抢占等是会产生轻微影响的）。 缺点。本方案的缺点同样很明显：它把语言及框架的依赖引入进来了。相对于kprobe可以直接面向协议进行解析，本方案需要考虑各种语言。同时，如果同一个语言中存在多种http的实现，也需要进行逐个适配。从这一角度而言，golang天然贴合本方案：其拥有官方统一维护的net/http库，同时，下游的请求方式也一并维护了。 以上是本次介绍的全部内容。在ebpf落地上，笔者还有很多内容需要探索，期望将来能够落地更多有价值的场景。周末愉快～\n","date":"2023-03-29T19:42:00Z","permalink":"https://liyan-ah.github.io/p/%E6%97%A0%E4%BE%B5%E5%85%A5%E8%A7%82%E6%B5%8B%E6%9C%8D%E5%8A%A1%E6%8B%93%E6%89%91%E5%9B%9B%E5%85%83%E7%BB%84%E7%9A%84%E4%B8%80%E7%A7%8D%E5%AE%9E%E7%8E%B0/","title":"无侵入观测服务拓扑四元组的一种实现"},{"content":" go-1.17是一个很不友好的版本，这里我指的是函数调用规约的变更。在此之前，虽然栈传参比较奇怪，但是在掌握了规律后，参数信息很好获取。升级到go-1.17之后，笔者发现变更后的寄存器传值方式并不是系统的调用规约，至少和C/C++的是完全不一致的。这个问题使得笔者在处理ebpf方案时，始终无法覆盖go-1.17+的版本。虽然短期不会造成影响，线上服务使用的大多还在go-1.16以下，但是这始终是一个绕不过去的问题。近期通过查阅资料和参考其他开源项目里对这部分内容的处理，整理了一下go-1.17+的调用规约。\ngo在1.17之前使用的是内存栈来传递参数，这种传参的方式使得golang的语言设计很灵活：golang函数的多返回值能够很容易的实现。同样的，由于golang需要这样灵活的能力，是的系统默认的调用规约方式并不适用。在Proposal: Register-based Go calling convention文章里对这个问题进行了详细的讨论，总结起来是golang的特性使得使用系统默认规约并不能带来多语言交互上的收益，且golang希望保持独特。\n本文下面会给出总结的调用规约，并且给出验证程序。本文档的整理所基于的平台是x86_64的centos8系统。其他架构下，寄存器名称可能不同。\n# 调用规约 入参：\n参数序号 标准规约 golang规约 1 rdi rax 2 rsi rbx 3 rdx rcx 4 rcx rdi 5 r8 rsi 6 r9 r8 7 栈传值 r9 8 栈传值 r10 9 栈传值 r11 10 栈传值 栈传值 返回值：\n参数序号 标准规约 golang规约 1 rax rax 2 - rbx 3 - rcx 4 - rdi 5 - rsi 6 - r8 7 - r9 8 - r10 9 - r11 10 - 栈传值 # 验证规约 这个条件是比较好验证的，看下验证代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // go version 1.18 // ./go_18/arg/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func longArgs(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11 uint64) (r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11 uint64) { return a1 + 1, a2 + 2, a3 + 3, a4 + 4, a5 + 5, a6 + 6, a7 + 7, a8 + 8, a9 + 9, a10 + 10, a11 + 11 } func main() { a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11 := longArgs(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11) fmt.Println(a1, a2, a3, a4, a5, a6, a7, a8, a9, a10, a11) } 先生成plan9代码以说明参数传入和参数返回均是使用的寄存器，并且寄存器顺序是一致的（内存传参时也是）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 go build -gcflags \u0026#34;-N -S -l\u0026#34; \u0026gt;\u0026gt; arg.info # 然后截取部分生成 plan9 汇编 # go_18/arg \u0026#34;\u0026#34;.longArgs STEXT nosplit size=411 args=0x68 locals=0x50 funcid=0x0 align=0x0 0x0000 00000 TEXT\t\u0026#34;\u0026#34;.longArgs(SB), NOSPLIT|ABIInternal, $80-104 0x0000 00000 SUBQ\t$80, SP 0x0004 00004 MOVQ\tBP, 72(SP) 0x0009 00009 LEAQ\t72(SP), BP 0x000e 00014 FUNCDATA\t$0, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x000e 00014 FUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x000e 00014 FUNCDATA\t$5, \u0026#34;\u0026#34;.longArgs.arginfo1(SB) 0x000e 00014 MOVQ\tAX, \u0026#34;\u0026#34;.a1+120(SP) # 注意这里的读取参数寄存器 0x0013 00019 MOVQ\tBX, \u0026#34;\u0026#34;.a2+128(SP) 0x001b 00027 MOVQ\tCX, \u0026#34;\u0026#34;.a3+136(SP) 0x0023 00035 MOVQ\tDI, \u0026#34;\u0026#34;.a4+144(SP) 0x002b 00043 MOVQ\tSI, \u0026#34;\u0026#34;.a5+152(SP) 0x0033 00051 MOVQ\tR8, \u0026#34;\u0026#34;.a6+160(SP) 0x003b 00059 MOVQ\tR9, \u0026#34;\u0026#34;.a7+168(SP) 0x0043 00067 MOVQ\tR10, \u0026#34;\u0026#34;.a8+176(SP) 0x004b 00075 MOVQ\tR11, \u0026#34;\u0026#34;.a9+184(SP) 0x0053 00083 MOVQ\t$0, \u0026#34;\u0026#34;.r1+64(SP) 0x005c 00092 MOVQ\t$0, \u0026#34;\u0026#34;.r2+56(SP) 0x0065 00101 MOVQ\t$0, \u0026#34;\u0026#34;.r3+48(SP) 0x006e 00110 MOVQ\t$0, \u0026#34;\u0026#34;.r4+40(SP) 0x0077 00119 MOVQ\t$0, \u0026#34;\u0026#34;.r5+32(SP) 0x0080 00128 MOVQ\t$0, \u0026#34;\u0026#34;.r6+24(SP) 0x0089 00137 MOVQ\t$0, \u0026#34;\u0026#34;.r7+16(SP) 0x0092 00146 MOVQ\t$0, \u0026#34;\u0026#34;.r8+8(SP) 0x009b 00155 MOVQ\t$0, \u0026#34;\u0026#34;.r9(SP) 0x00a3 00163 MOVQ\t$0, \u0026#34;\u0026#34;.r10+104(SP) 0x00ac 00172 MOVQ\t$0, \u0026#34;\u0026#34;.r11+112(SP) 0x00b5 00181 MOVQ\t\u0026#34;\u0026#34;.a1+120(SP), DX 0x00ba 00186 INCQ\tDX 0x00bd 00189 MOVQ\tDX, \u0026#34;\u0026#34;.r1+64(SP) 0x00c2 00194 MOVQ\t\u0026#34;\u0026#34;.a2+128(SP), DX 0x00ca 00202 ADDQ\t$2, DX 0x00ce 00206 MOVQ\tDX, \u0026#34;\u0026#34;.r2+56(SP) 0x00d3 00211 MOVQ\t\u0026#34;\u0026#34;.a3+136(SP), DX 0x00db 00219 ADDQ\t$3, DX 0x00df 00223 MOVQ\tDX, \u0026#34;\u0026#34;.r3+48(SP) 0x00e4 00228 MOVQ\t\u0026#34;\u0026#34;.a4+144(SP), DX 0x00ec 00236 ADDQ\t$4, DX 0x00f0 00240 MOVQ\tDX, \u0026#34;\u0026#34;.r4+40(SP) 0x00f5 00245 MOVQ\t\u0026#34;\u0026#34;.a5+152(SP), DX 0x00fd 00253 ADDQ\t$5, DX 0x0101 00257 MOVQ\tDX, \u0026#34;\u0026#34;.r5+32(SP) 0x0106 00262 MOVQ\t\u0026#34;\u0026#34;.a6+160(SP), DX 0x010e 00270 ADDQ\t$6, DX 0x0112 00274 MOVQ\tDX, \u0026#34;\u0026#34;.r6+24(SP) 0x0117 00279 MOVQ\t\u0026#34;\u0026#34;.a7+168(SP), DX 0x011f 00287 ADDQ\t$7, DX 0x0123 00291 MOVQ\tDX, \u0026#34;\u0026#34;.r7+16(SP) 0x0128 00296 MOVQ\t\u0026#34;\u0026#34;.a8+176(SP), DX 0x0130 00304 ADDQ\t$8, DX 0x0134 00308 MOVQ\tDX, \u0026#34;\u0026#34;.r8+8(SP) 0x0139 00313 MOVQ\t\u0026#34;\u0026#34;.a9+184(SP), DX 0x0141 00321 ADDQ\t$9, DX 0x0145 00325 MOVQ\tDX, \u0026#34;\u0026#34;.r9(SP) 0x0149 00329 MOVQ\t\u0026#34;\u0026#34;.a10+88(SP), DX # 这里使用栈传递a10 0x014e 00334 ADDQ\t$10, DX 0x0152 00338 MOVQ\tDX, \u0026#34;\u0026#34;.r10+104(SP) 0x0157 00343 MOVQ\t\u0026#34;\u0026#34;.a11+96(SP), DX 0x015c 00348 ADDQ\t$11, DX 0x0160 00352 MOVQ\tDX, \u0026#34;\u0026#34;.r11+112(SP) # 这里使用栈传递 a11 0x0165 00357 MOVQ\t\u0026#34;\u0026#34;.r1+64(SP), AX # 注意这里返回参数的寄存器 0x016a 00362 MOVQ\t\u0026#34;\u0026#34;.r2+56(SP), BX 0x016f 00367 MOVQ\t\u0026#34;\u0026#34;.r3+48(SP), CX 0x0174 00372 MOVQ\t\u0026#34;\u0026#34;.r4+40(SP), DI 0x0179 00377 MOVQ\t\u0026#34;\u0026#34;.r5+32(SP), SI 0x017e 00382 MOVQ\t\u0026#34;\u0026#34;.r6+24(SP), R8 0x0183 00387 MOVQ\t\u0026#34;\u0026#34;.r7+16(SP), R9 0x0188 00392 MOVQ\t\u0026#34;\u0026#34;.r8+8(SP), R10 0x018d 00397 MOVQ\t\u0026#34;\u0026#34;.r9(SP), R11 0x0191 00401 MOVQ\t72(SP), BP 0x0196 00406 ADDQ\t$80, SP 0x019a 00410 RET 从上面的plan9可以看出来，函数入参和返回值确实是使用寄存器传递的，且寄存器信息是一致的。实际上到这里就足够了。但是笔者还需要确定下使用的寄存器名称并进行验证，因为这些参数是在做ebpf逻辑处理的时候使用的。\n# 使用ebpf获取入参并输出 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // 这里表述下依据plan9寄存器符号推测的实际寄存器名称： #define GO_PARAM1(x) ((x)-\u0026gt;rax) #define GO_PARAM2(x) ((x)-\u0026gt;rbx) #define GO_PARAM3(x) ((x)-\u0026gt;rcx) #define GO_PARAM4(x) ((x)-\u0026gt;rdi) #define GO_PARAM5(x) ((x)-\u0026gt;rsi) #define GO_PARAM6(x) ((x)-\u0026gt;r8) #define GO_PARAM7(x) ((x)-\u0026gt;r9) #define GO_PARAM8(x) ((x)-\u0026gt;r10) #define GO_PARAM9(x) ((x)-\u0026gt;r11) struct event { u32 pid; u8 comm[64]; // args u64 arg0; u64 arg1; u64 arg2; u64 arg3; u64 arg4; u64 arg5; u64 arg6; u64 arg7; u64 arg8; u64 arg9; u64 arg10; }; SEC(\u0026#34;uprobe/main.longArgs\u0026#34;) int uprobe__main_long_args(struct pt_regs *ctx) { struct event args={}; args.pid = bpf_get_current_pid_tgid(); bpf_get_current_comm(\u0026amp;args.comm, sizeof(args.comm)); // read args 0-8，从寄存器中获取 args.arg0 = GO_PARAM1(ctx); args.arg1 = GO_PARAM2(ctx); args.arg2 = GO_PARAM3(ctx); args.arg3 = GO_PARAM4(ctx); args.arg4 = GO_PARAM5(ctx); args.arg5 = GO_PARAM6(ctx); args.arg6 = GO_PARAM7(ctx); args.arg7 = GO_PARAM8(ctx); args.arg8 = GO_PARAM9(ctx); // read args 9-10，从栈上获取 bpf_probe_read(\u0026amp;args.arg9, sizeof(args.arg9), (void*)(PT_REGS_SP(ctx))+8); bpf_probe_read(\u0026amp;args.arg10, sizeof(args.arg10), (void*)(PT_REGS_SP(ctx))+16); bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;args, sizeof(args)); return 0; } 编译完成后，启动这部分ebpf监听任务：\n1 2 3 4 5 6 7 8 9 10 # 启动监听 ./go_18 -bin_path ./arg/arg -uprobe main.longArgs 2023/03/03 22:07:32 Listening for events.. # 触发 ./arg/arg 执行 2023/03/03 22:07:46 pid: 756309, comm: arg 2023/03/03 22:07:46 /home/odin/pdliyan/blog/go_18/arg/arg: main.longArgs value: {Pid:756309 Comm:[97 114 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] _:[0 0 0 0] Arg0:1 Arg1:2 Arg2:3 Arg3:4 Arg4:5 Arg5:6 Arg6:7 Arg7:8 Arg8:9 Arg9:10 Arg10:11} # 请注意这里的参数是和我们的代码一致的。 2023/03/03 22:07:46 event info: {Pid:756309 Comm:[97 114 103 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0] _:[0 0 0 0] Arg0:1 Arg1:2 Arg2:3 Arg3:4 Arg4:5 Arg5:6 Arg6:7 Arg7:8 Arg8:9 Arg9:10 Arg10:11} # 退出 2023/03/03 22:08:38 Received signal, exiting program... 从上面的输出可以确定plan9的寄存器符号和实际寄存器的对应关系是正确的。\n以上就验证了困扰笔者的go-17+参数调用规约的问题。可以看到，依旧十分的奇葩。\n周末愉快。\n","date":"2023-03-03T20:59:00Z","permalink":"https://liyan-ah.github.io/p/go-1.17-%E8%B0%83%E7%94%A8%E8%A7%84%E7%BA%A6/","title":"go-1.17+ 调用规约"},{"content":" 在这里对文章题目作一些说明。笔者想了很长时间也无法给这篇文章想个恰当的表意题目。实际上使用ebpf来进行服务观测是有在进行的，比如获取目前l1s上的常见的四元组。但是本文不是介绍这部分可观测实践的。文章希望阐述的场景是：采集请求触发里的一些信息（诸如trace及其他header等）并和服务请求下游的传输层五元组(protocol, src-ip, src-port, dst-ip, dst-port)进行关联。这也是最近工作中实际遇到的问题。\n基于ebpf的丰富的特性能够获取服务很多的信息，不同特性的组合更是可以达到极强的数据整合能力。比如通过uprobe便捷的获取业务信息后，结合kprobe来获取系统调用里的内容，可以获取一般侵入式可观测代码无法获取的内容。笔者最近遇到的一个实际问题是：获取服务A的接口/a响应后，向下游B发起的请求时，所使用的传输层五元组，同时带上结合一些/a触发时的一些内容，比如caller_fun或者traceId。\n这里值得说明的是，用户态请求的是一个域名。域名的解析是在golang的http里完成的。但是请注意，golang发起tcp请求时，local port设置的是0，然后由内核态的tpc处理来选择一个空闲的port作为socket里的lport。这部分的信息通过代码的埋点显然是无法获取的（详情可参考TCP连接中客户端的端口号是如何确定的？）。\n下面介绍下实现效果及思路。\n关于bpftrace使用的介绍，可以参见：bpftrace 无侵入遍历golang链表，关于ebpf来进行数据采集的实践，可以参见ebpf采集mysql请求信息及ebpf对应用安全的思考。\n# 实现效果 服务端启动、触发的效果：\n1 2 3 4 5 6 7 8 9 10 11 # 启动目标服务 ./caller_tuple [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \u0026#34;debug\u0026#34; mode. Switch to \u0026#34;release\u0026#34; mode in production. - using env:\texport GIN_MODE=release - using code:\tgin.SetMode(gin.ReleaseMode) [GIN-debug] GET /echo --\u0026gt; main.Echo (3 handlers) # 这里触发一次接口调用 [GIN] 2023/02/24 - 22:05:29 | 200 | 85.618975ms | 127.0.0.1 | GET \u0026#34;/echo\u0026#34; bpftrace 采集端的效果：\n1 2 3 4 5 6 7 8 # 启动采集 bpftrace ./caller.bt Attaching 3 probes... start to gather caller info. get caller path: /echo # 将 caller_path 和 传输层五元组结合起来（本机的IP实际上是输出的，但是为了信息安全，就使用 0.0.0.0 来代替了） caller info: /echo 3326691 caller_tuple 0.0.0.0 38610 110.242.68.66 80 # 代码实现 这里分别上一下目标服务caller_func以及采集脚本caller.bt的代码，来说明下实现思路。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 // ./caller_tuple/main.go package main import ( \u0026#34;net/http\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; ) type Resp struct { Errno int64 `json:\u0026#34;errno\u0026#34;` Msg string `json:\u0026#34;msg\u0026#34;` } func Echo(c *gin.Context) { req, _ := http.NewRequest(http.MethodGet, \u0026#34;http://baidu.com\u0026#34;, nil) client := http.Client{} resp, err := client.Do(req) if err != nil { c.JSON(http.StatusOK, \u0026amp;Resp{Errno: 1, Msg: \u0026#34;request error\u0026#34;}) return } defer resp.Body.Close() c.JSON(http.StatusOK, \u0026amp;Resp{Errno: 0, Msg: \u0026#34;ok\u0026#34;}) return } func main() { r := gin.Default() srv := \u0026amp;http.Server{ Addr: \u0026#34;0.0.0.0:3344\u0026#34;, } r.GET(\u0026#34;/echo\u0026#34;, Echo) srv.Handler = r srv.ListenAndServe() } // caller_tuple/caller.bt #!/usr/bin/env bpftrace #define AF_INET 2 struct sock_common { union { struct { __be32 skc_daddr; __be32 skc_rcv_saddr; }; }; union { unsigned int skc_hash; __u16 skc_u16hashes[2]; }; union { struct { __be16 skc_dport; __u16 skc_num; }; }; short unsigned int skc_family; }; struct sock { struct sock_common __sk_common; }; BEGIN{ printf(\u0026#34;start to gather caller info. \u0026#34;); @caller[pid] = \u0026#34;none\u0026#34;; } // 这里通过 uprobe 来便捷的获取会话信息。同时将信息写入bpf_map uprobe:./caller_tuple:\u0026#34;net/http.serverHandler.ServeHTTP\u0026#34;{ $req_ptr = sarg3; $method_ptr = *(uint64*)($req_ptr); $method_len = *(uint64*)($req_ptr+8); /* read request.url.Path */ $url_ptr = *(uint64*)($req_ptr + 16); $path_ptr = *(uint64*)($url_ptr+56); $path_len = *(uint64*)($url_ptr+64); printf(\u0026#34;get caller path: %s \u0026#34;, str($path_ptr, $path_len)); // 这里使用 pid 来作为 key 只是为了实现方便。实际可以采取其他更有区分性的内容。 @caller_ptr[pid]=$path_ptr; @caller_len[pid]=$path_len; } // 通过 kprobe 来获取用户态无法获取的内容。同时通过 bpf_map 来控制生效及内容的交互。 kprobe:tcp_connect { if (@caller_ptr[pid] == 0){ return; } $ptr = @caller_ptr[pid]; $len = @caller_len[pid]; printf(\u0026#34;caller info: %s \u0026#34;, str($ptr, $len)); @caller_ptr[pid] = 0; @caller_len[pid] = 0; $sk = ((struct sock *) arg0); $inet_family = $sk-\u0026gt;__sk_common.skc_family; if ($inet_family == AF_INET) { $daddr = ntop($sk-\u0026gt;__sk_common.skc_daddr); $saddr = ntop($sk-\u0026gt;__sk_common.skc_rcv_saddr); $lport = $sk-\u0026gt;__sk_common.skc_num; $dport = $sk-\u0026gt;__sk_common.skc_dport; $dport = (((($dport) \u0026gt;\u0026gt; 8) \u0026amp; 0xff) | ((($dport) \u0026amp; 0xff) \u0026lt;\u0026lt; 8)); printf(\u0026#34;%-8d %-16s \u0026#34;, pid, comm); printf(\u0026#34;%-39s %-6d %-39s %-6d \u0026#34;, $saddr, $lport, $daddr, $dport); } } 这样就达到了笔者的目标。这只是ebpf应用的一个简单的场景，更多的metric采集内容仍在进行。\n以上，周末愉快！\n","date":"2023-02-24T21:44:49Z","permalink":"https://liyan-ah.github.io/p/ebpf-%E9%87%87%E9%9B%86ebpf-%E9%87%87%E9%9B%86tag-tcp%E4%BA%94%E5%85%83%E7%BB%84/","title":"ebpf 采集ebpf 采集tag+tcp五元组"},{"content":" 工作中难免会搞一些思维导图，一些小的需求又不希望切换窗口到另外一个界面去特地绘制。使用 emacs 来整理思维导图可以提升一些的效率，在当前窗口（文本编辑器）里即可完成简单思维导图的绘制。同时可以便于对工作内容进行归档（比如把相关的文本都放到一起）。live in emacs.\n# 依赖内容 org-contrib 扩展文件。用来将 org-mode 格式的文本转换成 freemind mm 文件。 freemind 软件。用来查看生成的 mm 文件。 笔者试了一下，Xmind思维导图看起来无法打开mm文件，freemind工作正常。也可能是我操作有问题。\n此外，生成的思维导图展现样式肯定没有目前专业的思维导图工具丰富，如果有正式的使用需求，还是首先考虑下专业的思维导图工具。\n# org-contrib 安装 笔者使用的emacs发布版本默认没有org-contrib，需要自行安装。安装过程也比较简单，从github里把org-contrib拉下来，在emacs init.el里配置加载路径，然后主动加载需要的ox-freemind.el即可。\ngithub org-contrib地址为git@github.com:emacsmirror/org-contrib.git。目录地址可以视自己的需求确定。笔者的emacs配置都放到了.emacs.d里，org-contrib的本地目录也就放到了~/.emacs.d/org-contrib这里。扩展下载后，在init.el里做如下配置即可：\n1 2 3 4 5 ;; ox-fremind ;; 这里改成本地的 org-contrib 地址 (add-to-list \u0026#39;load-path \u0026#34;~/.emacs.d/org-contrib/lisp\u0026#34;) ;; 目前只需要 ox-freemind，因此仅加载这个插件。 (load-file \u0026#34;~/.emacs.d/org-contrib/lisp/ox-freemind.el\u0026#34;) 安装结束后，需要重新加载一下emacs的配置文件，ox-freemind才能可用。\n# 使用 org-mode 整理文档并转换 这里直接贴一个示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #+TITLE: emacs org-mode 绘制思维导图 #+OPTIONS: H:1000 * org-contrib 安装 org-contrib 可以直接从 github 下载，然后在 emacs 配置文件里加载。 ** org-contrib github 地址 *** git@github.com:emacsmirror/org-contrib.git ** emacs 本地配置 *** (add-to-list \u0026#39;load-path \u0026#34;~/.emacs.d/org-contrib/lisp\u0026#34;)(load-file \u0026#34;~/.emacs.d/org-contrib/lisp/ox-freemind.el\u0026#34;) * org-mode 下文档编写 ** org-mode 是 emacs 下的神器 *** 打开 freemind.org 文件，输入这个文本 ** 转换文本文件到 freemind mm 文件 *** M-x org-freemind-export-to-freemind * 查看 mm 文件 ** 使用 freemind 查看生成的 freemind.mm 用emacs打开一个freemind.org，笔者这里直接触发了org-mode。如果没有触发org-mode的话，需要手动执行下M-x org-mode。然后执行org-freemind-export-to-freemind。如果没有这个函数，需要看下之前org-contrib的安装是否有问题，或者加载路径是否正常，加载是否有报错。如果函数执行异常，则需要查下原因。笔者安装后即可直接执行，因此没有报错处置的经验可供参考。\n# 使用freemind查看及导出 mac可以直接brew install --cask freemind。或者到其他下载源下载，如freemind sourceforge 下载。\n最后使用freemind打开freemind.org同级目录生成的freemind.mm。展示效果如下： 最后，可以使用emacs查看导出的freemind.png（🐶，笔者还在探索如何在不打开freemind的情况下把mm文件转换成png)。\n","date":"2023-02-10T19:46:21Z","permalink":"https://liyan-ah.github.io/p/emacs-org-mode-%E7%BB%98%E5%88%B6%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE/","title":"emacs org-mode 绘制思维导图"},{"content":" 即将过去的2022年，笔者相当比例的精力都投入在了eBPF上。最初的时候，写了一篇golang 常见类型字节数 ，开启了eBPF+golang的总结性工作。此后陆续整理了一些关于ebpf的使用文章，同时项目也在逐步的推进。eBPF的实际落地有很大的挑战，但是最终还是找到了一些落地的场景。年底了，结合最近的调研工作，笔者整理了这篇文章。既算是对之前文章的呼应，也是对今年整理内容的总结。\neBPF能够提供一种切入服务细节的独特视角。本文即通过实例，对golang常见类型作为函数参数时进行解析，期望读者能够感受这一视角。需要说明的是，本文是基于golang-1.16来整理的。\n# 数值类型 目前golang支持的数值类型大概有int, int8, int16, int32, int64及相对应的无符号类型。无符号类型在传递时和对应的有符号类型是一致的，这里不再赘述。int在不同平台上大小会不同，64位操作系统时，sizeof(int)=sizeof(int64)。作为参数传递时，数值类型会直接传递值。\n一般来说，int8, int16, int32在作为参数传递时，基于内存对齐的原则，会使用8B的空间来传递。但是并不绝对，笔者在准备本篇文章时，就找到了这样的示例：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 // type/main.go package main import \u0026#34;fmt\u0026#34; // 如果严格按照\u0026#34;内存对齐\u0026#34;来推算，int_p 的参数大小应为 8B*5 //go:noinline func int_p(a int8, b int16, c int32, d int64, e int) { fmt.Println(a, b, c, d, e) } func main() { int_p(1, 2, 3, 4, 5) } /* 从输出结果来看，int_p 参数列表带大小为 3*8B，其中第一个 8B 的分布为： |int8|--|int16|int32| | 1B |1B| 2B | 4B | type/type.bt */ uprobe:./type:\u0026#34;main.int_p\u0026#34; { printf(\u0026#34;int8: %d \u0026#34;, (int8)(sarg0)); printf(\u0026#34;int16: %d \u0026#34;, (int16)(sarg0\u0026gt;\u0026gt;16)); printf(\u0026#34;int32: %d \u0026#34;, (int32)(sarg0\u0026gt;\u0026gt;32)); printf(\u0026#34;int64: %d \u0026#34;, sarg1); printf(\u0026#34;int: %d \u0026#34;, sarg2); } // 运行结果 Attaching 1 probe... int8: 1 int16: 2 int32: 3 int64: 4 int: 5 由此可知，当数值类型作为函数参数时，需要结合前后参数来判断是否触发了内存对齐，进而判断数值类型参数的具体位置。\n# string string是由8B addr + 8B length来描述的。作为函数参数传递时，亦通过这样的方式来解析：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 // type/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func string_p(name string) { fmt.Println(name) } func main() { name := string(\u0026#34;didi\u0026#34;) string_p(name) } // type/type.bt uprobe:./type:\u0026#34;main.string_p\u0026#34; { printf(\u0026#34;addr: %d \u0026#34;, sarg0); printf(\u0026#34;length: %d \u0026#34;, sarg1); printf(\u0026#34;name: %s \u0026#34;, str(sarg0, sarg1)); } bpftrace ./type.bt Attaching 1 probe... addr: 4958864 // 所谓的地址，就是这么个东西 @V@ length: 4 name: didi 由于string的地址和长度都是8B，所以不会触发内存对齐。\n# slice slice是由8B addr + 8B length + 8B cap来描述的。作为函数值来传递时，需要关注地址及长度，以防止出现过解析的情况：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 // type/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func slice_p(slices []int64) { fmt.Println(slices) } func main() { slices := []int64{1, 2, 3} slice_p(slices) } // type/type.bt uprobe:./type:\u0026#34;main.slice_p\u0026#34; { printf(\u0026#34;addr: %d \u0026#34;, sarg0); printf(\u0026#34;length: %d \u0026#34;, sarg1); printf(\u0026#34;cap: %d \u0026#34;, sarg2); $pos = 0; $offset = 0; unroll(10){ if ($pos \u0026gt;= sarg1){ return; } $value = *(int64*)(sarg0+$offset); printf(\u0026#34;%d: %d \u0026#34;, $pos, $value); $offset = $offset+8; $pos = $pos + 1; } return; } bpftrace ./type.bt Attaching 1 probe... addr: 1310720 length: 3 cap: 3 0: 1 1: 2 2: 3 由于eBPF对循环的长度是有限制的，所以通过循环来读取数据会麻烦。一般可以直接将所有的数据都读出来，记录长度并将其传递到用户空间处理。\n# 定长数组 golang的定长数组在传递时，会直接将数据拷贝上去。所以一般是不建议使用定长数组作为函数参数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 // type/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func array_p(slices [4]int64) { fmt.Println(slices) } func main() { arrays := [4]int64{1, 2, 3, 4} array_p(arrays) } // type/type.bt uprobe:./type:\u0026#34;main.array_p\u0026#34; { printf(\u0026#34;arr[0]: %d \u0026#34;, sarg0); printf(\u0026#34;arr[1]: %d \u0026#34;, sarg1); printf(\u0026#34;arr[2]: %d \u0026#34;, sarg2); printf(\u0026#34;arr[3]: %d \u0026#34;, sarg3); return; } bpftrace ./type.bt Attaching 1 probe... arr[0]: 1 arr[1]: 2 arr[2]: 3 arr[3]: 4 需要注意的是，定长数组作为结构体参数时，也是直接将参数堆积的，而不是类似slice的由指针及长度组成。\n# 结构体 golang结构体作为函数参数传递时，会直接将结构体内的成员逐个传递。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 // type/main.go package main import ( \u0026#34;fmt\u0026#34; ) type S struct { X int64 Y int64 Z [3]int64 A int64 } // 请注意 other 参数，虽然其作为函数的第二个参数，但其在函数列表中的偏移量是 48B //go:noinline func struct_p(s S, other int64) { fmt.Println(s, other) } func main() { s := S{ X: 1, Y: 2, Z: [3]int64{3, 4, 5}, A: 6, } struct_p(s, 7) } // type/type.bt uprobe:./type:\u0026#34;main.struct_p\u0026#34; { printf(\u0026#34;X: %d \u0026#34;, sarg0); printf(\u0026#34;Y: %d \u0026#34;, sarg1); printf(\u0026#34;A: %d \u0026#34;, sarg5); printf(\u0026#34;other: %d \u0026#34;, sarg6); return; } bpftrace ./type.bt Attaching 1 probe... X: 1 Y: 2 A: 6 other: 7 结构体作为函数参数，往往会涉及到内存对齐的问题。需要逐个分析了。\n# 指针 golang指针作为函数参数时，会直接传递指针数值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // type/main.go package main import ( \u0026#34;fmt\u0026#34; ) type P struct { X int64 Y int64 Z [3]int64 A int64 } //go:noinline func pointer_p(p *P) { fmt.Println(*p) } func main() { p := \u0026amp;P{ X: 1, Y: 2, Z: [3]int64{3, 4, 5}, A: 6, } pointer_p(p) } // type/type.bt uprobe:./type:\u0026#34;main.pointer_p\u0026#34; { $p = sarg0; printf(\u0026#34;X: %d \u0026#34;, *(int64*)($p+0)); printf(\u0026#34;Y: %d \u0026#34;, *(int64*)($p+8)); printf(\u0026#34;A: %d \u0026#34;, *(int64*)($p+40)); return; } bpftrace ./type.bt Attaching 1 probe... X: 1 Y: 2 A: 6 解析golang指针成员的时候，需要提前知晓指针结构体的内容。\n# map golang的map实现比较复杂，详细的介绍可以看下这篇文章：golang map。map作为参数传递时，实际上传递的是hmap的指针。\n由于golang的map实际的结构及具体结构体的大小会受到map key, map value的影响，这对使用eBPF来解析golang map带来了额外的挑战。所幸本文并不期望提供一个golang map解析的通用方法，我们可以提前定义所需要解析的map为map[int64]int64，在这个条件下，bmap的结构就为：\n1 2 3 4 5 6 7 8 // sizeof(bmap) = 144B type bmap struct { topbits [8]uint8 // 8B keys [8]int64 // 64B values [8]int64 // 64B //pad uintptr //不需要添加内存对齐参数 overflow uintptr } 确定了bmap的信息后，可以看到，keys及values的偏移信息就确定了，可以直接读取。但是由于key实际映射时是通过hash来决定其位置的，完整的读取map显然是很困难的。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 // type/main.go package main import \u0026#34;fmt\u0026#34; //go:noinline func map_p(m map[int64]int64) { fmt.Println(m) } func main() { m := map[int64]int64{} for i := int64(1); i \u0026lt;= int64(10); i++ { m[i] = i } map_p(m) } // type/type.bt uprobe:./type:\u0026#34;main.map_p\u0026#34; { $hmap_addr = sarg0; $bucket_addr = *(uint64*)($hmap_addr+16); $bucket_offset = 0; unroll(2){ // 尝试读取两个 bmap $bmap_addr = $bucket_addr + $bucket_offset; $key_addr = $bmap_addr + 8; $value_addr = $bmap_addr + 72; $offset = 0; unroll(8){ // 读取每个 bmap 的所有 key-value $key = *(int64*)($key_addr+$offset); $value = *(int64*)($value_addr+$offset); printf(\u0026#34;key: %d, value: %d \u0026#34;, $key, $value); $offset = $offset + 8; } $bucket_offset = $bucket_offset + 144; } return; } // 笔者的这次运行，把[1,10]所有的key都输出了 bpftrace ./type.bt Attaching 1 probe... key: 2, value: 2 key: 3, value: 3 key: 5, value: 5 key: 6, value: 6 key: 7, value: 7 key: 8, value: 8 key: 9, value: 9 key: 10, value: 10 key: 1, value: 1 key: 4, value: 4 key: 0, value: 0 key: 0, value: 0 key: 0, value: 0 key: 0, value: 0 key: 0, value: 0 key: 0, value: 0 使用eBPF来读取map，不得不预设一个确定的大小。至于是否能够读取所有的map值，就不好说了。\n# interface golang的interface是由8B type pointer+8B struct pointer组成的。当解析interface的时候，需要的往往是struct pointer。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 // type/main.go package main import ( \u0026#34;fmt\u0026#34; ) type Inter interface{} type S struct { X int64 Y int64 Z [3]int64 A int64 } //go:noinline func struct_p(i Inter, other int64) { s, _ := i.(S) fmt.Println(s, other) } func main() { s := S{ X: 1, Y: 2, Z: [3]int64{3, 4, 5}, A: 6, } struct_p(s, 7) } // type/type.bt uprobe:./type:\u0026#34;main.struct_p\u0026#34; { $addr = sarg1; printf(\u0026#34;X: %d \u0026#34;, *(int64*)($addr+0)); printf(\u0026#34;Y: %d \u0026#34;, *(int64*)($addr+8)); printf(\u0026#34;A: %d \u0026#34;, *(int64*)($addr+40)); printf(\u0026#34;other: %d \u0026#34;, sarg2); return; } bpftrace ./type.bt Attaching 1 probe... X: 1 Y: 2 A: 6 other: 7 从示例中可以看出，当解析interface时，interface具体的结构体成员对我们而言更加重要。在实际的工程里，往往会出现多个结构体实现同一个interface，并且均可以作为该interface来传递值的情况。这时就需要依据所实际期望解析的结构体来进行实际采集的过滤或者适配了。\n# 写在最后 本文编写的文章超过了笔者的估计时间 :)。anyway，这篇文章最终整理完成了。期望有读者能够籍此对eBPF有直观的认识，同时体会到其观察golang的独特视角。\n周末愉快，新年快乐！\n","date":"2022-12-30T19:24:18Z","permalink":"https://liyan-ah.github.io/p/golang%E5%B8%B8%E8%A7%81%E7%B1%BB%E5%9E%8B%E4%BD%9C%E4%B8%BA%E5%8F%82%E6%95%B0%E7%9A%84ebpf%E8%A7%A3%E6%9E%90/","title":"golang常见类型作为参数的eBPF解析"},{"content":" 虽然golang并不推荐使用goid来构建gls(goroutine local storage)，仍然有着很多的实现gls并使用的尝试。github-gls这里是一个常见的实现，基本表述了golang里gls的实现思路：获取goid，基于goid构建一个存储。本文中笔者尝试基于ebpf来构建一个golang的gls。\n# 基本功能 本文中基于ebpf实现的gls具有如下功能：\n基于goid的存储。即map[goid]=value； 基于goroutine派生关系设置的value缺省值。即map[goid=1]=121，且goid=1派生goid=2，则map[goid=2]=map[goid=1]=121；\n本文建议参照黑魔法-ebpf-对用户空间数据的写入进行理解。 # 用户态代码及效果 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;sync\u0026#34; ) var Len = 5 // 当 info 为空时，使用父 goid 设置的值，否则存入 info func Go1(ctx context.Context, info string, wg *sync.WaitGroup) { defer wg.Done() third := Third{} if info != \u0026#34;\u0026#34; { third.Store(info) } /* 诸多其他的逻辑 */ info1 := third.Get() fmt.Printf(\u0026#34;raw info: [%s], info get: [%s] \u0026#34;, info, info1) } //go:noinline func Set(info []byte) { if len(info) \u0026gt; Len { info = info[:Len] } if len(info) \u0026lt; Len { tmp := make([]byte, Len-len(info)) info = append(tmp, info...) } fmt.Println(\u0026#34;info: \u0026#34;, string(info)) return } //go:noinline func Get(info []byte) []byte { // alalalala, magic come return info } type Third struct { Info string } func (t *Third) Store(info string) { infoByt := []byte(info) // 这里假设是个约束 infoByt = infoByt[:Len] Set(infoByt) } func (t *Third) Get() string { infoByt := make([]byte, Len, Len) infoByt = Get(infoByt) return string(infoByt) } func main() { third1 := Third{} info := \u0026#34;12345\u0026#34; third1.Store(info) wg := \u0026amp;sync.WaitGroup{} ctx := context.Background() wg.Add(1) go Go1(ctx, \u0026#34;\u0026#34;, wg) // 写入空数据，预期使用父 goid 数据，即 12345 for i := 1125; i \u0026lt; 1130; i++ { wg.Add(1) v := strconv.Itoa(i) if i%10 == 0 { v = \u0026#34;\u0026#34; } go Go1(ctx, v, wg) } wg.Wait() /* very long handle logic*/ third2 := Third{} infoGet := third2.Get() fmt.Printf(\u0026#34;in main, getInfo, [%s] \u0026#34;, infoGet) } 执行结果为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 // 未开启 bpf info: 12345 info: 1129 raw info: [1129], info get: [] info: 1126 raw info: [1126], info get: [] info: 1128 raw info: [1128], info get: [] raw info: [], info get: [] info: 1125 info: 1127 raw info: [1125], info get: [] raw info: [1127], info get: [] in main, getInfo, [] // 开启 bpf info: 12345 info: 1129 raw info: [], info get: [12345] // 传入空值，使用父 goid 存入数据 raw info: [1129], info get: [1129] info: 1126 raw info: [1126], info get: [1126] info: 1127 raw info: [1127], info get: [1127] info: 1125 raw info: [1125], info get: [1125] info: 1128 raw info: [1128], info get: [1128] in main, getInfo, [12345] 上述示例对比了开启bpf前后的用户态代码输出。可以看到，当子goroutine缺少某个信息时，可以获取父goroutine的数据作为缺省值。\n# 应用 意味着我们可以在父goroutine中存入我们需要的数据，而后无论是否创建新的goroutine，均能获取该信息。维护了goroutine session的数据。\n# ebpf 逻辑 这里仍然附上了ebpf的主要逻辑以便说明实现过程。除了之前文章中涉及的ebpf向用户态写入数据，本文使用了golang创建goroutine相关的uprobe来维护goroutine session状态。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 struct { __uint(type, BPF_MAP_TYPE_LRU_HASH); __uint(key_size, sizeof(u64)); // pid_tgid __uint(value_size, sizeof(u64)); // parent goid __uint(max_entries, MAX_ENTRIES); } go_goid_map SEC(\u0026#34;.maps\u0026#34;); // 用来获取 goid 状态 struct { __uint(type, BPF_MAP_TYPE_HASH); __uint(key_size, sizeof(u64)); __uint(value_size, sizeof(u8) * 5); __uint(max_entries, 100); } info_map SEC(\u0026#34;.maps\u0026#34;); // 用来存储 goid-\u0026gt;info struct { __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY); } events SEC(\u0026#34;.maps\u0026#34;); static __always_inline u64 get_goid(u32 tgid, u32 pid) { unsigned long task_addr = (unsigned long)bpf_get_current_task(); unsigned long fsbase = 0; unsigned long g = 0; u64 goid = 0; // 直接基于 偏移量进行处理了 // offset(task_struct, thread) = 4992 // offset(thread_struct, fsbase) = 40 bpf_probe_read(\u0026amp;fsbase, sizeof(fsbase), (void *)(task_addr + OFF_TASK_THRD + OFF_THRD_FSBASE)); bpf_probe_read(\u0026amp;g, sizeof(g), (void *)(fsbase - 8)); bpf_probe_read(\u0026amp;goid, sizeof(goid), (void *)(g + GOID_OFFSET)); return goid; } SEC(\u0026#34;uprobe/main_set\u0026#34;) int uprobe__main_set(struct pt_regs *ctx) { uintptr_t info_p = 0; u8 info[5]; u64 pid_tgid = bpf_get_current_pid_tgid(); u32 pid = (u32)(pid_tgid \u0026amp; 0x00FF); u32 tgid = (u32)(pid_tgid \u0026gt;\u0026gt; 32); u64 goid = 0; goid = get_goid(tgid, pid); SARG(ctx, 0, info_p); bpf_probe_read(\u0026amp;info, sizeof(info), (const void *)info_p); bpf_map_update_elem(\u0026amp;info_map, \u0026amp;goid, \u0026amp;info, BPF_ANY); event_t event = {}; event.pid_tgid = pid_tgid; memcpy(event.info, info, sizeof(info)); bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } SEC(\u0026#34;uprobe/main_get\u0026#34;) int uprobe__main_get(struct pt_regs *ctx) { uintptr_t info_p = 0; u64 pid_tgid = bpf_get_current_pid_tgid(); u32 pid = (u32)(pid_tgid \u0026amp; 0x00FF); u32 tgid = (u32)(pid_tgid \u0026gt;\u0026gt; 32); u64 goid = 0; goid = get_goid(tgid, pid); void *r_info_p = NULL; r_info_p = bpf_map_lookup_elem(\u0026amp;info_map, \u0026amp;goid); if (r_info_p == NULL) { return 0; } event_t event = {}; event.pid_tgid = pid_tgid; SARG(ctx, 0, info_p); u8 info[5]; memcpy(info, r_info_p, sizeof(info)); memcpy(event.info, info, sizeof(event.info)); event.res = bpf_probe_write_user((u8 *)info_p, info, sizeof(info)); event.addr = info_p; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } /* golang_runtime_newproc1 func newproc1(fn *funcval, argp unsafe.Pointer, narg int32, callergp *g, callerpc uintptr) *g { */ SEC(\u0026#34;uprobe/golang_runtime_newproc1\u0026#34;) int uprobe__golang_runtime_newproc1(struct pt_regs *ctx) { u64 pid_tgid = bpf_get_current_pid_tgid(); uintptr_t g_addr = 0; u64 cur_goid = 0; SARG(ctx, 3, g_addr); bpf_probe_read(\u0026amp;cur_goid, sizeof(cur_goid), (void *)(g_addr + GOID_OFFSET)); bpf_map_update_elem(\u0026amp;go_goid_map, \u0026amp;pid_tgid, \u0026amp;cur_goid, BPF_ANY); return 0; } SEC(\u0026#34;uprobe/golang_runtime_runqput\u0026#34;) int uprobe__golang_runtime_runqput(struct pt_regs *ctx) { u64 pid_tgid = bpf_get_current_pid_tgid(); uintptr_t g_addr = 0; u64 *parent_goid = NULL; u64 child_goid = 0; void *v_p = NULL; parent_goid = bpf_map_lookup_elem(\u0026amp;go_goid_map, \u0026amp;pid_tgid); if (parent_goid == NULL) { return 0; } // 1. 获取新 goroutine 的 goid SARG(ctx, 1, g_addr); bpf_probe_read(\u0026amp;child_goid, sizeof(child_goid), (void *)(g_addr + GOID_OFFSET)); // 2. 设置新 goid 绑定的 caller 信息 v_p = bpf_map_lookup_elem(\u0026amp;info_map, parent_goid); if (v_p == NULL) { return 0; } // 设置子 goid 绑定 caller 为 父 goid 信息 bpf_map_update_elem(\u0026amp;info_map, \u0026amp;child_goid, v_p, BPF_ANY); bpf_map_delete_elem(\u0026amp;go_goid_map, \u0026amp;pid_tgid); return 0; } 以上。\n","date":"2022-11-25T01:14:00Z","permalink":"https://liyan-ah.github.io/p/%E5%9F%BA%E4%BA%8Eebpf%E5%AE%9E%E7%8E%B0%E7%9A%84gls/","title":"基于ebpf实现的gls"},{"content":"在之前的示例中，仅涉及到ebpf对用户空间数据的读取。工程性较强的如：ebpf采集mysql请求信息及ebpf对应用安全的思考也仅是通过urpobe采集用户空间的数据。本文介绍点ebpf的“黑魔法”：将用户空间数据的读取、用户空间数据的写入结合起来，成为用户空间数据交互的桥梁。\n# 运行效果 在看运行效果之前，需要先看下目标示例的代码以便更好的理解本文介绍的功能：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 // user/obj/obj.go package main import ( \u0026#34;fmt\u0026#34; ) var Len = 5 // 预设的 uprobe //go:noinline func Set(info []byte) { fmt.Println(\u0026#34;info: \u0026#34;, string(info)) return } // 预设的 uprobe //go:noinline func Get(info []byte) []byte { fmt.Printf(\u0026#34;info addr: %p \u0026#34;, info) fmt.Println(string(info)) // 请注意这里的输出操作 return info } type Third struct { Info string } func (t *Third) SetSomething(info string) { infoByt := []byte(info) // 这里假设是个约束 infoByt = infoByt[:Len] Set(infoByt) // 在这里调用预设的处理函数 } func (t *Third) GetSomething() string { infoByt := make([]byte, Len, Len) infoByt = Get(infoByt) // 在这里调用预设的处理函数 return string(infoByt) } func main() { third1 := Third{} info := \u0026#34;12345\u0026#34; third1.SetSomething(info) // 请注意，这里进行写入的对象 /* very long handle logic, many goroutines or proces happend here */ third2 := Third{} // 请注意，这里读取的对象和上述执行写入的对象是完全没有关系的 infoGet := third2.GetSomething() fmt.Printf(\u0026#34;after getInfo, [%s] \u0026#34;, infoGet) } 这段代码非常简单，下面进行了两次执行来说明ebpf达到的效果：\n1 2 3 4 5 6 7 8 9 10 11 $ ./obj // 第一次，没有使用 ebpf 生效。代码的正常输出结果 info: 12345 info addr: 0xc0000180f0 // 请注意这里 after getInfo, [] $ ./obj // 第二次，开始执行前开启 ebpf 监听 info: 12345 info addr: 0xc0000180f0 12345 // 请注意这里 after getInfo, [12345] 请关注上述示例里的注释。通过ebpf的attach，实现了数据从用户空间-\u0026gt;ebpf空间-\u0026gt;用户空间，这个过程并不关心用户代码里发生了什么，ebpf只关注预设的uprobe是怎么被调用的。\n# 应用及思考 ebpf的这个功能显然具有很广泛的应用，但是具体的应用就需要结合业务的应用来说明了（颇有一些拿着锤子找钉子的感觉），比如：结合调用了特定埋点sdk的使用，能够用来对traceId信息的补全。\n事物自然都有两面性，ebpf提供了变更用户空间数据的潜力，自然就会带来风险：代码里的逻辑似乎不再靠谱了。而且，想象下将代码里的读操作，变更为删除操作，将会对用户空间的安全造成很大的破坏。\n# ebpf 逻辑 之前一直是使用bpftrace来进行示例演示的，但是本文涉及的功能需要使用long bpf_probe_write_user(void *dst, const void *src, u32 len)这个bpf-helper函数。笔者没有找到bpftrace里的调用方式，因此采用cilium-ebpf来进行示例演示。其中涉及的主要bpf代码附在下面，基本表述了相对原生的bpf-helper的调用方法。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 struct{ __uint(type, BPF_MAP_TYPE_HASH); __uint(key_size, sizeof(u32)); __uint(value_size, sizeof(u8)*5); __uint(max_entries, 100); } info_map SEC(\u0026#34;.maps\u0026#34;); struct event{ u64 pid_tgid; u8 info[5]; // 这里的成员长度，请结合 obj.go 来看 uintptr_t addr; long res; }; typedef struct event event_t; // Force emitting struct event into the ELF. const struct event *unused __attribute__((unused)); struct { __uint(type, BPF_MAP_TYPE_PERF_EVENT_ARRAY); } events SEC(\u0026#34;.maps\u0026#34;); SEC(\u0026#34;uprobe/main_set\u0026#34;) int uprobe__main_set(struct pt_regs *ctx){ uintptr_t info_p = 0; u8 info[5]; u64 pid_tgid = bpf_get_current_pid_tgid(); SARG(ctx, 0, info_p); bpf_probe_read(\u0026amp;info, sizeof(info), (const void*)info_p); u32 tgid = (u32)(pid_tgid \u0026gt;\u0026gt; 32); bpf_map_update_elem(\u0026amp;info_map, \u0026amp;tgid, \u0026amp;info, BPF_ANY); event_t event = {}; event.pid_tgid = pid_tgid; memcpy(event.info, info, sizeof(info)); bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } SEC(\u0026#34;uprobe/main_get\u0026#34;) int uprobe__main_get(struct pt_regs *ctx){ uintptr_t info_p = 0; u64 pid_tgid = bpf_get_current_pid_tgid(); void* r_info_p = NULL; u32 tgid = (u32)(pid_tgid \u0026gt;\u0026gt; 32); r_info_p = bpf_map_lookup_elem(\u0026amp;info_map, \u0026amp;tgid); if (r_info_p == NULL){ return 0; } event_t event = {}; event.pid_tgid = pid_tgid; SARG(ctx, 0, info_p); u8 info[5]; memcpy(info, r_info_p, sizeof(info)); memcpy(event.info, info, sizeof(event.info)); event.res = bpf_probe_write_user((u8*)info_p, info, sizeof(info)); event.addr = info_p; bpf_perf_event_output(ctx, \u0026amp;events, BPF_F_CURRENT_CPU, \u0026amp;event, sizeof(event)); return 0; } 以上，周末愉快。\n","date":"2022-11-04T18:00:00Z","permalink":"https://liyan-ah.github.io/p/%E9%BB%91%E9%AD%94%E6%B3%95--%E7%94%A8-ebpf-%E6%9E%84%E5%BB%BA%E7%94%A8%E6%88%B7%E7%A9%BA%E9%97%B4%E6%95%B0%E6%8D%AE%E7%9A%84%E6%A1%A5%E6%A2%81/","title":"黑魔法--用 ebpf 构建用户空间数据的桥梁"},{"content":" 本文笔者继续介绍ebpf 的应用：使用bpftrace采集mysql连接信息，包括数据库地址、db_name、user_name。在展示采集操作的同时，附上对ebpf对云时代应用安全的一些思考。\n# 目标 使用bpftrace对一个运行中进程的mysql请求进行采集，目标采集内容包括数据库地址、db_name、user_name。\n目标进程代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 // blog/main.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;time\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; _ \u0026#34;github.com/go-sql-driver/mysql\u0026#34; \u0026#34;xorm.io/xorm\u0026#34; ) var sqlE *xorm.Engine func init() { fmt.Println(\u0026#34;init from main\u0026#34;) var err error sqlE, err = xorm.NewEngine(\u0026#34;mysql\u0026#34;, \u0026#34;test:mysqltest@tcp(localhost:3306)/test_db?charset=utf8\u0026amp;parseTime=true\u0026#34;) // 随便写个数据库信息，假装是正确的 if err != nil { log.Printf(\u0026#34;init mysql failed: %+v \u0026#34;, err) } } type Resp struct { Code int `json:\u0026#34;code\u0026#34;` Msg string `json:\u0026#34;msg\u0026#34;` } type SqlInfo struct { Id int64 `json:\u0026#34;id\u0026#34; xorm:\u0026#34;pk bigint(20)\u0026#34;` Created time.Time `json:\u0026#34;created\u0026#34; xorm:\u0026#34;created\u0026#34;` Info string `json:\u0026#34;info\u0026#34;` } func (sql *SqlInfo) TableName() string { return \u0026#34;sql_info\u0026#34; } func Mysql(c *gin.Context) { info := c.Query(\u0026#34;info\u0026#34;) if info == \u0026#34;\u0026#34; { now := time.Now().Format(\u0026#34;2008-01-02 15:04:05\u0026#34;) info = now } sqlInfo := SqlInfo{ Info: info, } affected, err := sqlE.Insert(\u0026amp;sqlInfo) if err != nil { log.Printf(\u0026#34;insert db with error: %+v \u0026#34;, err) } else { log.Printf(\u0026#34;affect column nums: %d \u0026#34;, affected) } c.JSON(http.StatusOK, \u0026amp;Resp{Code: 0, Msg: \u0026#34;mysql req over\u0026#34;}) return } func main() { r := gin.Default() srv := \u0026amp;http.Server{ Addr: \u0026#34;0.0.0.0:9981\u0026#34;, } log.Println(\u0026#34;server start at: 0.0.0.0:9981\u0026#34;) r.GET(\u0026#34;/sql\u0026#34;, Mysql) srv.Handler = r err := srv.ListenAndServe() if err != nil { log.Fatal(\u0026#34;error with start listener\u0026#34;) } } # bpftrace 代码 直接上代码了：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 #! /bin/bpftrace /* 保存在 blog/blog.bt 里 这里使用的 uprobe 函数为 go-sql-driver 里的内容。源代码在： https://github.com/go-sql-driver/mysql/blob/master/connector.go#L23 定义为： func (c *connector) Connect(ctx context.Context) (driver.Conn, error) {...} */ uprobe:./blog:\u0026#34;github.com/go-sql-driver/mysql.(*connector).Connect\u0026#34; { printf(\u0026#34;Connect \u0026#34;); $cfg_addr = *(uint64*)sarg0; // 获取 c.cfg 的地址 $user_addr = *(uint64*)($cfg_addr); // 获取 c.cfg.User $user_len = *(uint64*)($cfg_addr+8); // 获取 len(c.cfg.User) //$pwd_addr = *(uint64*)($cfg_addr+16); // 请注意这里注释掉的内容 //$pwd_len = *(uint64*)($cfg_addr+24); $addr_addr = *(uint64*)($cfg_addr+48); $addr_len = *(uint64*)($cfg_addr+56); $db_addr = *(uint64*)($cfg_addr+64); $db_len = *(uint64*)($cfg_addr+72); printf(\u0026#34;user: %s \u0026#34;, str($user_addr, $user_len)); //printf(\u0026#34;pwd: %s \u0026#34;, str($pwd_addr, $pwd_len)); printf(\u0026#34;addr: %s \u0026#34;, str($addr_addr, $addr_len)); printf(\u0026#34;db: %s \u0026#34;, str($db_addr, $db_len)); } 而后启动应用程序blog，启动监听程序sudo bpftrace ./blog.bt，请求blog的/sql接口以触发blog对sql的请求。整个过程对blog程序来说没有任何的不平凡之处，但是我们已经获取了采集结果。 附上执行结果如下：\n1 2 3 4 5 6 7 8 9 10 11 12 $ ./blog init from main [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \u0026#34;debug\u0026#34; mode. Switch to \u0026#34;release\u0026#34; mode in production. - using env:\texport GIN_MODE=release - using code:\tgin.SetMode(gin.ReleaseMode) 2022/10/21 20:15:38 server start at: 0.0.0.0:9981 [GIN-debug] GET /sql --\u0026gt; main.Mysql (3 handlers) 2022/10/21 20:18:52 insert db with error: dial tcp 127.0.0.1:3306: connect: connection refused [GIN] 2022/10/21 - 20:18:52 | 200 | 3.679499ms | 127.0.0.1 | GET \u0026#34;/sql\u0026#34; 此时，在采集侧：\n1 2 3 4 5 6 $ sudo ./blog.bt Attaching 1 probe... Connect user: test addr: localhost:3306 db: test_db 我们已经获取了需要的信息。\n# 对采集代码的一些说明 bpftrace语法部分，参见github-bpftrace-reference_guid。里面有ebpf的一些简单介绍以及bpftrace的使用说明。代码里的主要逻辑，则需要参见golang的语法来理解。部分简述如下：\n类里的方法，实际调用的时候，第一个参数为对象的地址； go-1.16 及之前的版本，参数存储在栈上； 剩下的内容就比较好理解了：ebpf提供的核心功能包括按需读取用户空间内的数据。结合golang-常见类型字节数可以比较快的推导出我们需要的信息在地址内的偏移量。同时，在bpftrace无侵入遍历golang链表曾经提到过，如果目标对象比较大，无法在ebpf代码里完整定义该对象（内核限制单个ebpf的hook点程序的栈空间大小在512B），我们访问对象里的成员时，使用的方法就是偏移量访问。\n# ebpf 与应用安全的一些思考 最后提一点自己的思考。\n请回到bpftrace代码里，里面的pasword信息获取的操作被注释掉了。其实我们去掉注释，仍然能够按照预期获取结果。这就意味着，如果我们拥有机器上的权限，并且机器满足我们的采集需求，应用里的核心信息（这里是数据库的密码）将被简单的获取。无论数据库密码如何存储：配置文件、源代码、通过网络配置下发等。只要有涉及数据库访问的用户态函数，有涉及数据库密码传递的内容，这些信息存在被获取的风险，只要采集人拥有root权限。\n这里引出另外一个问题：如果一个用户拥有机器上的管理员权限，TA是否应该拥有机器上所有进程信息的准入权。这里的进程信息，显然是包括机器上容器内的进程信息的，无论是公有云或者私有云。\n","date":"2022-10-21T19:48:00Z","permalink":"https://liyan-ah.github.io/p/ebpf%E9%87%87%E9%9B%86mysql%E8%AF%B7%E6%B1%82%E4%BF%A1%E6%81%AF%E5%8F%8Aebpf%E5%AF%B9%E5%BA%94%E7%94%A8%E5%AE%89%E5%85%A8%E7%9A%84%E6%80%9D%E8%80%83/","title":"ebpf采集mysql请求信息及ebpf对应用安全的思考"},{"content":" x86_64 架构下，寄存器传参时，仅 arg1-arg6 会通过寄存器进行，arg7+ 的参数，将会放到栈上进行。\n# 验证代码 1 2 3 4 # 环境 ├── arg.bt ├── arg_test └── hello.c 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 // hello.c, gcc -o arg_test hello.c #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; void print_arg(int arg1, int arg2, int arg3, int arg4, int arg5, int arg6, int arg7, int arg8){ printf(\u0026#34;%d, %d, %d, %d, %d, %d, %d, %d \u0026#34;, arg1, arg2, arg3, arg4, arg5, arg6, arg7, arg8); return; } int main(){ print_arg(1,2,3,4,5,6,7,8); } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 // arg.bt #!/bin/bpftrace uprobe:./arg_test:print_arg { printf(\u0026#34;== enter print_arg \u0026#34;); printf(\u0026#34;arg1: %d \u0026#34;, arg0); printf(\u0026#34;arg2: %d \u0026#34;, arg1); printf(\u0026#34;arg3: %d \u0026#34;, arg2); printf(\u0026#34;arg4: %d \u0026#34;, arg3); printf(\u0026#34;arg5: %d \u0026#34;, arg4); printf(\u0026#34;arg6: %d \u0026#34;, arg5); printf(\u0026#34;arg7: %d \u0026#34;, sarg0); printf(\u0026#34;arg8: %d \u0026#34;, sarg1); } # 执行结果 1 2 3 4 5 6 7 8 9 10 11 12 13 sudo bpftrace arg.bt Attaching 1 probe... == enter print_arg arg1: 1 arg2: 2 arg3: 3 arg4: 4 arg5: 5 arg6: 6 arg7: 7 arg8: 8 ./arg_test # 参照 X86 64 Register and Instruction Quick Start\n","date":"2022-08-31T19:51:00Z","permalink":"https://liyan-ah.github.io/p/x86_64-%E5%AF%84%E5%AD%98%E5%99%A8%E4%BC%A0%E5%8F%82%E6%96%B9%E5%BC%8F/","title":"x86_64 寄存器传参方式"},{"content":" bpftrace 基于 bcc 进行开发的工具，语法简洁、功能强大。用其分析Linux 环境下的程序会很方便。本文构造了一个入参为链表头节点的函数使用场景，通过使用bpftrace无侵入遍历链表成员的方式，介绍bpftrace attach uprobe 的使用。更多使用说明见:bpftrace官网使用文档\n# 执行结果 下面直接给出执行结果。可以看到，通过bpftrace脚本输出的结果与代码中实际遍历的结果相同。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 sudo ./handle.bt // 先启动监听 Attaching 1 probe... // 启动后停止在这里 === enter main.handle. // 目标程序执行后输出 name: Alice age : 10 name: Bob age : 11 name: Claire age : 12 === total node: 3 ./demo // 再执行目标程序 cur name: Alice, cur aget: 10 cur name: Bob, cur aget: 11 cur name: Claire, cur aget: 12 # 示例说明 系统环境如下：\n1 2 3 Linux 4.18.0-193.6.3.el8_2.v1.2.x86_64 bpftrace v0.14.0-72-g6761-dirty go version go1.16.15 linux/amd64 示例环境目录：\n1 2 3 4 5 . ├── demo ├── go.mod ├── handle.bt └── main.go 其中：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 // main.go package main import ( \u0026#34;context\u0026#34; \u0026#34;fmt\u0026#34; ) type Student struct { Name string Age int64 // Comment [600]Byte 这样会使得这个问题变得很麻烦，hhh Next *Student } // 添加如下配置以防止函数被编译优化掉 //go:noinline func handle(ctx context.Context, student *Student) { for cur := student; cur != nil; cur = cur.Next { fmt.Printf(\u0026#34;cur name: %s, cur aget: %d \u0026#34;, cur.Name, cur.Age) } return } func main() { first := \u0026amp;Student{ Name: \u0026#34;Alice\u0026#34;, Age: 10, Next: \u0026amp;Student{ Name: \u0026#34;Bob\u0026#34;, Age: 11, Next: \u0026amp;Student{ Name: \u0026#34;Claire\u0026#34;, Age: 13, Next: nil, }}} handle(context.Background(), first) } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 // handle.bt #!/bin/bpftrace // 当目标结构体较小时(使得整体栈开销 \u0026lt; 512Byte)，可以直接构造使用 struct student{ u64 name_ptr; u64 name_length; long age; struct student *next; }; uprobe:./demo:\u0026#34;main.handle\u0026#34; { printf(\u0026#34;=== enter main.handle. \u0026#34;); $cur = (struct student *)sarg2; if ($cur == 0){ printf(\u0026#34;input param is nil. \u0026#34;); return; } $node_count = 1; unroll(10){ // 这里定义的最大节点数量为10 printf(\u0026#34;name: %s \u0026#34;, str($cur-\u0026gt;name_ptr, $cur-\u0026gt;name_length)); printf(\u0026#34;age : %d \u0026#34;, $cur-\u0026gt;age); $cur = $cur-\u0026gt;next; if ($cur == 0){ printf(\u0026#34;=== total node: %d \u0026#34;, $node_count); return; } $node_count += 1; } printf(\u0026#34;==== meet max \u0026#34;); return; } 在编译完成main.go后，通过sudo bpftrace -l \u0026quot;uprobe:./demo:*\u0026quot; \u0026gt; uprobe.info的方式，可以获取demo中所有可以attach的uprobe信息。这里说明下取student*指针值时，为什么取sarg3。bpftrace中对内存传参的参数支持是sarg0, sarg1, sarg2...，且每个参数实际只对应8Byte大小的空间。对于func handle(ctx context.Context, student *Student)函数来说，由于context.Context实际占用2*8Byte的空间（见golang常见类型字节数)，因此需要使用sarg2来取student的值，而非直觉上的sarg1。\n整个过程比较简单、明了。只要拥有root权限，基本上可以对系统内的任何进程进行详细的分析。\n","date":"2022-07-22T21:48:00Z","permalink":"https://liyan-ah.github.io/p/bpftrace-%E6%97%A0%E4%BE%B5%E5%85%A5%E9%81%8D%E5%8E%86golang%E9%93%BE%E8%A1%A8/","title":"bpftrace 无侵入遍历golang链表"},{"content":" liam同学在让 Vim 在保存文件时自动格式化代码一文中展示了保存时自动化格式代码的vim配置。作为emacs用户，自然有自己的解决方案。以下呈现。\n# 配置 emacs进行c/c++的开发，离不开支持代码自动补全、库函数联想等功能，所以本文顺带把lsp配置也一并带上了，不同于emacs-若干语言 lsp 配置备注里的eglot，这里使用的是ccls。直接上配置吧，比较简单：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 ;; 使用国内 elpa 源来加速插件安装 (defun w-install(pkg) ;; would be a wrapper for package-install (require \u0026#39;package) (setq package-archives \u0026#39;((\u0026#34;gnu\u0026#34; . \u0026#34;http://mirrors.tuna.tsinghua.edu.cn/elpa/gnu/\u0026#34;) (\u0026#34;melpa\u0026#34; . \u0026#34;http://mirrors.tuna.tsinghua.edu.cn/elpa/melpa/\u0026#34;))) (package-initialize) (package-refresh-contents) (unless (package-installed-p pkg) (package-install pkg))) ;; 辅助判断插件安装通用函数 (defun ensure-package-installed (\u0026amp;rest packages) \u0026#34;Assure every package was installed, ask for installation if it\u0026#39;s not. a list of installed packages or nil for every skipped package.\u0026#34; (mapcar (lambda (package) (if (package-installed-p package) nil (if (y-or-n-p (format \u0026#34;Package %s is missing. Install it?\u0026#34; package)) (w-install package) package))) packages)) ;; clang-format 在文件保存时格式化代码 (ensure-package-installed \u0026#39;clang-format) (defun clang-format-on-save-hook() \u0026#34;Create a buffer local save hook.\u0026#34; (add-hook \u0026#39;before-save-hook (lambda () (when (locate-dominating-file \u0026#34;.\u0026#34; \u0026#34;.clang-format\u0026#34;) (clang-format-buffer)) ;; Continue to save nil) nil ;; Buffer local hook. t)) ;; Run this hook for c-mode-hook and c++-mode-hook (add-hook \u0026#39;c-mode-hook (lambda () (clang-format-on-save-hook))) (add-hook \u0026#39;c++-mode-hook (lambda () (clang-format-on-save-hook))) ;; create default clang-format file ;; https://releases.llvm.org/3.6.2/tools/docs/ClangFormatStyleOptions.html ;; clang-format -style=llvm -dump-config \u0026gt; .clang-format ;; 另外，这里列出使用的 lsp-language-server 配置。 ;; 服务端使用 ccls，客户端则使用 ccls.el。同时将 ccls 作为 c-mode 的hook运行 ;; https://github.com/MaskRay/ccls/wiki/Build ;; set up lsp-mode for c/c++ (ensure-package-installed \u0026#39;ccls) (use-package ccls :hook ((c-mode c++-mode objc-mode cuda-mode) . (lambda() (require \u0026#39;ccls) (lsp)))) 代码格式部分则主要由.clang-format文件控制。其配置方法可以参见官网：ClangFormat。\n","date":"2022-07-15T20:34:00Z","permalink":"https://liyan-ah.github.io/p/%E8%AE%A9emacs%E5%9C%A8%E4%BF%9D%E5%AD%98%E6%96%87%E4%BB%B6%E6%97%B6%E8%87%AA%E5%8A%A8%E6%A0%BC%E5%BC%8F%E5%8C%96%E4%BB%A3%E7%A0%81/","title":"让emacs在保存文件时自动格式化代码"},{"content":" ebpf 分析golang程序时，离不开对参数大小的判断。这里列出来一些基本类型的大小，并通过汇编对应验证函数的方式来肯定判断结果。\n# 信息 这里列出基本类型及其作为参数传递时，占用的空间大小如下表。\n类型 长度 说明 指针 8B 64位机为 8Byte, 32位机位4Byte context 16B interface 类型。其中，前8B是类型信息，后8B是对象的指针信息 interface 16B 2 个指针，详见draveness-go-interface，或者 runtime/runtime2.go iface/eface 定义 int64 8B - int 8B 64位机为 8Byte, 32位机位4Byte string 16B 8B 地址 + 8B string长度 slice 24B 8B地址 + 8B slice 成员数量 + 8B slice capability func 8B func 作为函数参数时，传递的是 func 的地址 需要注意的是，作为函数参数传递时，golang会对参数按照 8B 进行对齐。\n# 验证示例 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 // main.go package main import \u0026#34;context\u0026#34; type A struct { p1 int64 a byte b int64 } type FuncPt func(A) type InterA interface { Echo(A) } func CheckPointer(a *A) {} func CheckCtx(ctx context.Context) {} func CheckInterface(inter InterA) {} func CheckString(s string) {} func CheckSlice(arr []string) {} func CheckFunc(fn FuncPt) {} func CheckAlign(a byte) {} func CheckStruct(a A) {} func main() {} 对该代码进行汇编:\ngo build -gcflags \u0026quot;-S\u0026quot; . \u0026gt; main.s 可以得到汇编后的结果，并验证上述类型所占大小的描述。这里推荐下曹大的plan9 汇编入门，里面对golang汇编后的plan9进行了介绍。由其介绍可知，汇编后函数签名后的$x-y指代的是该函数的栈空间以及参数大小（入参+返回参数，go-1.17及之后的版本未验证）。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 # command-line-arguments \u0026#34;\u0026#34;.CheckPointer STEXT size=16 args=0x8 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:17)\tTEXT\t\u0026#34;\u0026#34;.CheckPointer(SB), LEAF|NOFRAME|ABIInternal, $0-8 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:17)\tFUNCDATA\tZR, gclocals·2a5305abe05176240e61b8620e19a815(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:17)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:17)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckCtx STEXT size=16 args=0x10 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:18)\tTEXT\t\u0026#34;\u0026#34;.CheckCtx(SB), LEAF|NOFRAME|ABIInternal, $0-16 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:18)\tFUNCDATA\tZR, gclocals·f207267fbf96a0178e8758c6e3e0ce28(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:18)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:18)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckInterface STEXT size=16 args=0x10 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:19)\tTEXT\t\u0026#34;\u0026#34;.CheckInterface(SB), LEAF|NOFRAME|ABIInternal, $0-16 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:19)\tFUNCDATA\tZR, gclocals·f207267fbf96a0178e8758c6e3e0ce28(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:19)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:19)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckString STEXT size=16 args=0x10 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:20)\tTEXT\t\u0026#34;\u0026#34;.CheckString(SB), LEAF|NOFRAME|ABIInternal, $0-16 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:20)\tFUNCDATA\tZR, gclocals·2a5305abe05176240e61b8620e19a815(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:20)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:20)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckSlice STEXT size=16 args=0x18 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:21)\tTEXT\t\u0026#34;\u0026#34;.CheckSlice(SB), LEAF|NOFRAME|ABIInternal, $0-24 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:21)\tFUNCDATA\tZR, gclocals·2a5305abe05176240e61b8620e19a815(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:21)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:21)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckFunc STEXT size=16 args=0x8 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:22)\tTEXT\t\u0026#34;\u0026#34;.CheckFunc(SB), LEAF|NOFRAME|ABIInternal, $0-8 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:22)\tFUNCDATA\tZR, gclocals·2a5305abe05176240e61b8620e19a815(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:22)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:22)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckAlign STEXT size=16 args=0x8 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:23)\tTEXT\t\u0026#34;\u0026#34;.CheckAlign(SB), LEAF|NOFRAME|ABIInternal, $0-8 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:23)\tFUNCDATA\tZR, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:23)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:23)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.CheckStruct STEXT size=16 args=0x18 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:24)\tTEXT\t\u0026#34;\u0026#34;.CheckStruct(SB), LEAF|NOFRAME|ABIInternal, $0-24 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:24)\tFUNCDATA\tZR, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:24)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:24)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. \u0026#34;\u0026#34;.main STEXT size=16 args=0x0 locals=0x0 funcid=0x0 leaf 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:26)\tTEXT\t\u0026#34;\u0026#34;.main(SB), LEAF|NOFRAME|ABIInternal, $0-0 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:26)\tFUNCDATA\tZR, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:26)\tFUNCDATA\t$1, gclocals·33cdeccccebe80329f1fdbee7f5874cb(SB) 0x0000 00000 (/Users/liyan/zone/go_learn/param/main.go:28)\tRET\t(R30) 0x0000 c0 03 5f d6 00 00 00 00 00 00 00 00 00 00 00 00 .._............. ","date":"2022-06-06T14:36:00Z","permalink":"https://liyan-ah.github.io/p/golang-%E5%B8%B8%E8%A7%81%E7%B1%BB%E5%9E%8B%E5%AD%97%E8%8A%82%E6%95%B0/","title":"golang 常见类型字节数"},{"content":" 一直都比较赞赏protocol buffer。由于其表现性强、压缩比高，可以把很多结构都写到proto文件中，同时添加很多的注释。当需要进行进行数据存储时，使用proto序列化结果替代json，可以省去很多的冗余字段。本篇找了一些golang中protocol buffer的使用示例，以及protocol对象与json对象互相转换的示例。\n# 依赖环境 这部分主要参照官网教程来：\nprotoc 安装：\ngithub-protobuf-releases 下载对应平台的 protoc 编译器即可； protoc-gen-go 安装：\ngo install google.golang.org/protobuf/cmd/protoc-gen-go@latest 需要能够安装对应语言的插件，proto 文件才被翻译为对应语言可调用的模块； # 示例代码 比较推荐将proto文件单独放入一个仓库。proto一般定义的是需要服务/模块间共享的，所以单独放在一个仓库里便于调用及约定的维护。\n1 2 3 4 . ├── main.go └── proto └── user.proto 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 // main.go package main import ( \u0026#34;bytes\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;proto/message\u0026#34; \u0026#34;github.com/gin-gonic/gin\u0026#34; \u0026#34;github.com/gogo/protobuf/jsonpb\u0026#34; jsoniter \u0026#34;github.com/json-iterator/go\u0026#34; \u0026#34;google.golang.org/protobuf/proto\u0026#34; ) func main() { msg := message.UserInfo{UserList: []*message.UserInfo_User{{Username: \u0026#34;test\u0026#34;}}} msg.UserList = append(msg.UserList, \u0026amp;message.UserInfo_User{Username: \u0026#34;test1\u0026#34;}) // go message 可以直接序列化为 json byte byt, err := jsoniter.Marshal(\u0026amp;msg) if err != nil { log.Fatal(\u0026#34;cannot parse to json\u0026#34;) } fmt.Println(\u0026#34;json result: \u0026#34;, string(byt)) // 可以将 json 对象反序列化为 go message 对象 msg1 := \u0026amp;message.UserInfo{} err = jsonpb.Unmarshal(bytes.NewReader(byt), msg1) if err != nil { log.Fatal(\u0026#34;parse failed, \u0026#34;, err) } fmt.Printf(\u0026#34;parsed: %+v \u0026#34;, msg1) // protobuf 本身的字符串表征 msg1Str := msg1.String() fmt.Println(\u0026#34;msg1 string, \u0026#34;, msg1Str) // protobuf 序列化 out, err := proto.Marshal(msg1) fmt.Println(\u0026#34;msg1 marshal result is, \u0026#34;, string(out)) msg2 := message.UserInfo{} // 将序列化后的结果，反序列化为 message 对象 proto.Unmarshal(out, \u0026amp;msg2) fmt.Printf(\u0026#34;unmarshal result msg2 is: %+v \u0026#34;, \u0026amp;msg2) engine := gin.Default() engine.GET(\u0026#34;check\u0026#34;, func(c *gin.Context) { // message 对象可以直接用来作为接口的返回值 c.JSON(http.StatusOK, \u0026amp;msg1) }) srv := \u0026amp;http.Server{} srv.Addr = \u0026#34;0.0.0.0:9988\u0026#34; srv.Handler = engine srv.ListenAndServe() } // proto/user.proto syntax = \u0026#34;proto3\u0026#34;; package user_info; // 对于 golang 的使用说，这里的 go_package 是必须的。表述的是编译后的模块名 option go_package = \u0026#34;./message\u0026#34;; message UserInfo{ message User{ string username = 1; uint32 age = 2; string graduate = 3; } repeated User user_list = 1; } 进行编译:protoc -I./proto user.proto --go_out=./，\n1 2 3 4 5 6 7 8 9 10 . ├── go.mod ├── go.sum ├── main.go ├── message │ └── user.pb.go └── proto └── user.proto 2 directories, 5 files 执行 go run main.go。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 go run main.go json result: {\u0026#34;user_list\u0026#34;:[{\u0026#34;username\u0026#34;:\u0026#34;test\u0026#34;},{\u0026#34;username\u0026#34;:\u0026#34;test1\u0026#34;}]} parsed: user_list:{username:\u0026#34;test\u0026#34;} user_list:{username:\u0026#34;test1\u0026#34;} msg1 string, user_list:{username:\u0026#34;test\u0026#34;} user_list:{username:\u0026#34;test1\u0026#34;} msg1 marshal result is, test test1 unmarshal result msg2 is: user_list:{username:\u0026#34;test\u0026#34;} user_list:{username:\u0026#34;test1\u0026#34;} [GIN-debug] [WARNING] Creating an Engine instance with the Logger and Recovery middleware already attached. [GIN-debug] [WARNING] Running in \u0026#34;debug\u0026#34; mode. Switch to \u0026#34;release\u0026#34; mode in production. - using env:\texport GIN_MODE=release - using code:\tgin.SetMode(gin.ReleaseMode) [GIN-debug] GET /check_must --\u0026gt; main.main.func1 (3 handlers) # 总结 protocol buffer 在大多数场景下，都能兼容json对象的使用场景。其劣势为序列化相关操作时额外的性能开销。对于与外部进行交互、不会进行频繁序列化、反序列化的数据，可以考虑优先使用protocol buffer。\n","date":"2022-05-19T17:53:00Z","permalink":"https://liyan-ah.github.io/p/golang-proto3-%E4%BD%BF%E7%94%A8/","title":"golang proto3 使用"},{"content":" goroutine 开销为 2KB（最少），对比线程 2MB 的开销，有明显的优势。当goroutine 栈资源不足时，runtime 会将整个 goroutine stack 拷贝、重新分配空间。\nInstead of using a thread for every goroutine, Go multiplexes goroutines across multiple threads (\u0026ldquo;M:N scheduling\u0026rdquo;). So instead of each thread having a default 2MB stack, each goroutine has a tiny 2KB stack that\u0026rsquo;s managed by the runtime instead of the operating system. When the program needs to grow the stack for a goroutine and there\u0026rsquo;s not enough room, the runtime copies the entire goroutine\u0026rsquo;s stack to another place in memory where it has enough room to expand.\nChallenges of BPF Tracing Go\n","date":"2022-04-19T14:33:00Z","permalink":"https://liyan-ah.github.io/p/challenges-of-bpf-tracing-go/","title":"challenges of bpf tracing go"},{"content":" 工作需要（抛弃了kubectl搞一套环境的方法），需要在centos8上构建一套docker镜像并运行golang程序。这里记录下docker安装及golang程序打包镜像的过程。\n# 安装docker 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 sudo yum install -y yum-utils sudo yum-config-manager \\ --add-repo \\ https://download.docker.com/linux/centos/docker-ce.repo sudo yum install docker-ce docker-ce-cli containerd.io \\# 这里报了一个错 \\# (try to add \u0026#39;--allowerasing\u0026#39; to command line to replace conflicting packages or \u0026#39;--skip-broken\u0026#39; to skip uninstallable packages or \u0026#39;--nobest\u0026#39; to use not only best candidate packages) \\# 重新执行 sudo yum install docker-ce docker-ce-cli containerd.io --allowerasing \\# 启动 docker sudo systemctl start docker \\# 测试 sudo docker run hello-world \\# Hello from Docker! \\# This message shows that your installation appears to be working correctly. # 构建golang服务镜像 先看下工作目录的结构：\n1 2 3 4 5 6 . ├── Dockerfile ├── gin-srv ├── go.mod ├── go.sum └── main.go 简单写一个golang的程序:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 package main import \u0026#34;time\u0026#34; import \u0026#34;github.com/gin-gonic/gin\u0026#34; type Resp struct{ Errno int `json:\u0026#34;errno\u0026#34;` Data map[string]int64 `json:\u0026#34;data\u0026#34;` } func main(){ r := gin.Default() r.GET(\u0026#34;/ping\u0026#34;, func(c *gin.Context){ resp := \u0026amp;Resp{Errno:0, Data: map[string]int64{ \u0026#34;now\u0026#34;: time.Now().Unix(), }} c.JSON(200, \u0026amp;resp) }) r.Run(\u0026#34;0.0.0.0:8080\u0026#34;) } 构建一个Dockerfile，以centos作为base以便能够正常登陆容器进行调试：\n1 2 3 4 FROM centos:8 ADD . ./ EXPOSE 8080 ENTRYPOINT [\u0026#34;./gin-srv\u0026#34;] 启动容器：\n1 2 3 4 # 构建镜像 sudo docker build -t gin_docker . # 启动镜像 sudo docker run --name gin_docker -p 8080:8080 -d gin_docker 访问容器中的服务：\n1 2 $ curl localhost:8080/ping {\u0026#34;errno\u0026#34;:0,\u0026#34;data\u0026#34;:{\u0026#34;now\u0026#34;:1646381863}} 容器起来了。可以继续后面的性能评估及agent启动工作了。\n# 参考文献 Install Docker Engine on CentOS Golang应用打包docker镜像并运行\n","date":"2022-03-04T15:00:00Z","permalink":"https://liyan-ah.github.io/p/centos-%E5%AE%89%E8%A3%85docker%E5%B9%B6%E6%9E%84%E5%BB%BAgolang%E9%95%9C%E5%83%8F/","title":"centos 安装docker并构建golang镜像"},{"content":" 最近在做 eBPF 的技术调研。看到很多对 eBPF 的介绍。为了加强对内容的理解，笔者选择了其中的一篇尝试翻译。本着便于笔者自己理解的角度，很多内容加入了自己的一些理解，因此并不能算是严格意义上的“翻译”。文章涉及了 eBPF 的介绍、优势、不足，算是一篇 eBPF 的很好的介绍。现在把它贴上来，算是纪念自己的第一篇“译文”。\n原文地址：What Is eBPF and Why Does It Matter for Observability?\n# eBPF 及其对可观测领域的影响 当实现安全性、网络化以及可观测的特性时，在linux 内核中工作是非常理想化的。然而，它并非缺少挑战。无论是变更内核源码或者新增 内核模块，开发者通常会面对复杂的架构及难以调试的抽象层。扩展的 BPF(eBPF) 能够解决这两个问题。 伯克利包过滤器扩展技术(Extended Berkeley Packet Filter, eBPF) 是一种内核技术(自 Linux 4.x 引入)允许程序在无需变更内核源码或添加 额外的内核模块。你可以认为它是一种内核内置的轻量级的、沙箱式的虚拟机，编程人员可以通过 BPF 字节码来最大化的利用内核的资源。 使用 eBPF 消除了变更内核源码并且简化了软件利用现有层级的能力。因此，它是一种强大的技术，有可能从根本上改变网络、可观测性及安全 服务的工作方式。 这是一篇 eBPF 是什么、怎么工作以及什么时候考虑利用这种技术的文章。\n# eBPF 是怎么工作的 eBPF 是事件驱动的，并且绑定到特定的代码路径。代码路径包含特殊的触发点(triggers)，或者称为钩子(hooks)。触发时，会执行所有绑定 到上面的 eBPF 程序。一些钩子的示例包括网络事件、系统调用、函数执行以及内核跟踪点。 当被触发时，代码会首先被编译成 BPF 字节码。然后，字节码会在执行前被校验，以确保不包含任何循环。校验会确保程序不会有意或无意的 破坏内核。 当代码在一个钩子上执行后，会产生辅助调用(helper calls)。这些辅助调用是一些eBPF访问内存的函数。辅助调用需要内核提前定义，目前 调用的函数列表仍在持续增长中。 eBPF 最开始的时候是作为一种增加过滤网络包时可观测性及安全性的工具。然而，时至今日，它已经成为一种用来让用户态的程序更加安全、 便捷、表现更好的工具。\n# eBPF 的优势 eBPF 通常被用来进行追踪用户态的进程，这里列出一些它的优势：\n高速、高效。eBPF 可以将网络包从内核态移动至用户态。而且，eBPF支持一个运行时（just-in-time, JIT）的编译器。在字节码被编译出来 后即可被执行，毋需基于平台重新解释； 低侵入性。当被用作调试器时，eBPF 无需停止服务便可以观测它的状态； 安全性。程序会被高效地加载到沙盒中，意味着内核源码被保护起来不会发生变更。执行时的校验能够确保资源不会由于程序陷入死循环而 阻塞； 便捷。相对于构建并维护内核的模块，编写内核的函数钩子要简单的多； 一致追踪。eBPF能够带来一个单一、有效、可用性强的追踪程序的框架。这增加了可视化及安全性； 可编程性。使用 eBPF 在不引入额外架构层的情况下，丰富了系统的特性。而且，由于代码是直接运行在内核里的，在不同的eBPF事件间存储 数据，而非像其他追踪程序一样转存出来，是可行的； 表达丰富。eBPF极具表达能力，这通常只能在其他高级语言中能够看到； # eBPF 最佳实践 考虑到 eBPF 仍然是一项新的技术，很多使用仍待进一步开发。关于 eBPF 的最佳实践仍在随着这种技术的改进而不断增加。虽然没有已定义的 最佳实践存在，仍然有一些措施可以采纳以确保程序高效、便捷。 如果你在生态系统中使用了 eBPF，我们建议你：\n使用 LLVM Clang 来将 C 代码编辑为 eBPF 字节码。当 eBPF 刚出现时，编码及汇编均需要手动操作。然后， 开发者使用内核的汇编器生成字节码。幸运的是，现在已经不再需要这样操作了。Clang 为 C 语言编写的 eBPF 提供了前端及工具； 使用 BCC 工具集来编写 BPF 程序。BPF 编译器集合（BPF Compiler Collection, BCC） 是一个帮助 构建高效内核追踪及管理程序的工具集。针对性能分析及网络拥塞控制相关的任务尤其合适。 # eBPF 的不足 尽管很强大，eBPF 并不是适合所有项目/生态系统的万金油。eBPF 有一些显而易见的不足，这些不足会让它在一些场景下不适用。一些开发者 可能会发现在如下场景下 eBPF 不适用：\neBPF 限制在 Linux 系统及较新的内核版本。eBPF 是在 Linux 内核上发展并且完全聚焦在其上。这导致它相对于其他工具而言移植性不强。 此外，你需要一个相当新的内核。如果运行在任何早于 v4.13 的内核上，你将不能使用它。 沙盒编程是存在限制的。eBPF 通过限制应用程序可以接触的资源来提升安全性。然而，由于限制了操作系统的访问，功能上也被限制了。 # eBPF 适用哪些领域 eBPF 云原生应用 领域正迅速的获得关注。目前，eBPF 在以下两个场景中获得普遍 使用：\n需要使用内核追踪实现可观测性。在这种场景下，eBPF 表现得更加快速、高效。这里不涉及到上下文切换，并且 eBPF 程序是事件驱动的所以毋需一个特定的触发器\u0026ndash;所以你不会存在精度上的问题。 传统的安全监控不起作用。eBPF 在分布式及容器化的环境中有巨大的应用潜力，包括Kubernets。 在这些环境中，eBPF 可以缩小可见性的差距，因为他可以提供HTTP 可见性追踪。 在如下安全度量领域，你也可以发现 eBPF 被使用： 防火墙； 设备驱动； 网络性能监控； # New Relic and eBPF Pixie (acquired by New Relic), is an open source, kubernetes-native-in-cluster observability platform that provides instant visibility into Kubernetes workloads with no manual instrumentation. eBPF provides most of the magic behind the Pixie platform. As described earlier, eBPF allows you to run restricted code when an event is triggered. This event could be a function call either in kernel space(kprobes) or userspace(uprobes). Pixie uses both uprobes and kprobes to enable observability across services and applications.\nPixie automatically harvests telemetry data by leveraging eBPF, and its edge-machine intelligence connects this data with Kubernetes metadata to provide visibility while maintaining data locality. This visibility complements New Relic’s powerful Kubernetes observability solution. And starting in late May, you\u0026rsquo;ll be able to send Pixie-generated telemetry data to New Relic One, gaining scalable retention, powerful visualizations, advanced correlation, and intelligent alerting capabilities.\n# eBPF 正在可见的创造效率 eBPF 是一个提升 Linux 内核可观测、网络及安全性的新技术。它毋需变更内核源码或者添加新的模块，所以你可以在不引入复杂性的前提下， 提升系统的基础建设。 我们简要的谈到 eBPF 是什么、如何工作以及为什么它在分布式环境中如此有用。通过监控内核层，很多云上的可观测问题被解决了。你可以 享受数据中更深层次的可见性、更丰富的上下文以及更准确的信息。\n","date":"2022-03-02T16:34:00Z","permalink":"https://liyan-ah.github.io/p/ebpf%E5%8F%8A%E5%85%B6%E5%AF%B9%E5%8F%AF%E8%A7%82%E6%B5%8B%E7%9A%84%E6%84%8F%E4%B9%89%E8%AF%91%E6%96%87/","title":"eBPF及其对可观测的意义【译文】"},{"content":" 工作原因，需要安装一个 local-k8s。中间碰了很多坑，做个记录。 环境：Linux test 4.18.0-193.el8.x86_64\n# kubectl kubectl安装说明，可以直接使用包管理器安装，如：\n1 2 3 4 5 6 7 8 9 10 cat \u0026lt;\u0026lt;EOF | sudo tee /etc/yum.repos.d/kubernetes.repo [kubernetes] name=Kubernetes baseurl=https://packages.cloud.google.com/yum/repos/kubernetes-el7-x86_64 enabled=1 gpgcheck=1 repo_gpgcheck=1 gpgkey=https://packages.cloud.google.com/yum/doc/yum-key.gpg https://packages.cloud.google.com/yum/doc/rpm-package-key.gpg EOF sudo yum install -y kubectl # minicube minicube安装说明 也比较方便，官网里有不同系统的安装方式。笔者使用curl的安装：\n1 2 curl -LO https://storage.googleapis.com/minikube/releases/latest/minikube-linux-amd64 sudo install minikube-linux-amd64 /usr/local/bin/minikube # start cluster # 安装 kvm How to Install KVM on CentOS 8\n1 2 3 4 5 # check cat /proc/cpuinfo | egrep \u0026#34;vmx|svm\u0026#34; # install sudo yum install @virt # start minikube start --driver=\u0026lt;kvm2|hyperkit\u0026gt; --cni=flannel --cpus=4 --memory=8000 -p=\u0026lt;cluster-name\u0026gt;，其中，笔者使用的centos系统使用--driver=kvm2选项。执行时存在诸多问题：\n# kvm2 错误 参照错误提示来。需要安装libvirt，笔者直接sudo yum install libvirt进行的。\n# not in libvirt group 不确定为什么需要单独搞一个libvirt group，按照issue-5617 的说明，需要将用户添加到libvirt用户组中。笔者直接进行sudo usermod -a -G libvirt ${USERNAME}。\n# virsh 报错 1 2 error: failed to connect to the hypervisor error: authentication failed: access denied by policy 需要在将当前用户添加到libvirt之后，需要配置polkit规则，确保libvirt组中的用户能够访问libvirt。\n1 2 3 4 5 6 7 # 方案参考 https://blog.csdn.net/cunjiu9486/article/details/109074019 # /etc/polkit-1/rules.d/80-libvirt.rules polkit.addRule(function(action, subject){ if (action.id == \u0026#34;org.libvirt.unix.manage\u0026#34; \u0026amp;\u0026amp; subject.local \u0026amp;\u0026amp; subject.active \u0026amp;\u0026amp; subject.isInGroup(\u0026#34;libvirt\u0026#34;)){ return polkit.Result.YES; } }); 添加规则后，还需要重启 polkitd。简单粗暴：\n1 nohup /usr/lib/polkit-1/polkitd -r \u0026gt; /dev/null \u0026amp; # Cannot find suitable emulator for x86_64 通过 sudo systemctl status libvirtd 查看，发现报错是：cannot initialize crypt，继续安装yum install libgcrypt。\n# dnsmasq: unknown user or group: dnsmasq 1 2 groupadd dnsmasq useradd dnsmasq -g dnsmasq # Failed to start host 提示建议删除刚才的cluster，不清楚为啥，提示了就搞起来：\n1 2 3 minikube delete $cluster_name # 再次执行 minikube start --driver=\u0026lt;kvm2|hyperkit\u0026gt; --cni=flannel --cpus=4 --memory=8000 -p=\u0026lt;cluster-name\u0026gt; 这次可以了！\n1 2 * Enabled addons: storage-provisioner, default-storageclass * Done! kubectl is now configured to use \u0026#34;${cluster_name}\u0026#34; cluster and \u0026#34;default\u0026#34; namespace by default ","date":"2022-02-24T17:27:00Z","permalink":"https://liyan-ah.github.io/p/centos-%E6%9E%84%E5%BB%BA-local-k8s/","title":"centos 构建 local-k8s"},{"content":"之前办公一直在Windows系统中，诸如流程图、部署图等图表使用的是visio。迁移到Mac上后，visio便不能使用了。转战到sketch 上，用着颇为顺手，无奈试用期到了之后，就无法使用了。评估了下使用需求及产品价格，只能启用。\n目前在使用draw.io 进行日常绘图，开源、跨平台、免费、使用流畅，可以在线使用或者客户端使用。基本满足日常需求。用着还是比较好的。\n","date":"2022-02-16T10:51:00Z","permalink":"https://liyan-ah.github.io/p/mac-%E7%BB%98%E5%9B%BE%E5%B7%A5%E5%85%B7%E6%8E%A8%E8%8D%90/","title":"Mac 绘图工具推荐"},{"content":" # ELK docker 部署实践 本文主要对 ELK 套件中的 filebeat, logstash, elasticsearch 的安装进行实践，以及简单运行。\n# Elasticsearch 安装 这里参照官网给出的docker-compose.yml文件设置elasticsearch集群。elastisearch支持single-node及multi node cluster两种部署模式。在本文中，实际上两种方式都能达到效果。使用single-node启动的环境，查看集群状态时会出现status:yellow。将docker-compose.yml文件放置在一个单独的目录下，然后创建data01, data02, data03目录。依据实际需要，还可创建plugins目录映射。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 version: \u0026#39;2\u0026#39; services: es01: container_name: es01 image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0 ports: - 9200:9200 - 9300:9300 volumes: - ./data01:/usr/share/elasticsearch/data environment: - node.name=es01 - cluster.name=es-docker-cluster - discovery.seed_hosts=es02 - cluster.initial_master_nodes=es01,es02 - bootstrap.memory_lock=true - \u0026#34;ES_JAVA_OPTS=-Xms128m -Xmx128m\u0026#34; ulimits: memlock: soft: -1 hard: -1 networks: - elastic es02: container_name: es02 image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0 environment: - node.name=es02 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01 - cluster.initial_master_nodes=es01,es02 - bootstrap.memory_lock=true - \u0026#34;ES_JAVA_OPTS=-Xms128m -Xmx128m\u0026#34; volumes: - ./data02:/usr/share/elasticsearch/data ulimits: memlock: soft: -1 hard: -1 networks: - elastic es03: container_name: es03 image: docker.elastic.co/elasticsearch/elasticsearch:7.15.0 environment: - node.name=es03 - cluster.name=es-docker-cluster - discovery.seed_hosts=es01,es02 - cluster.initial_master_nodes=es01,es02,es03 - bootstrap.memory_lock=true - \u0026#34;ES_JAVA_OPTS=-Xms128m -Xmx128m\u0026#34; volumes: - data03:/usr/share/elasticsearch/data ulimits: memlock: soft: -1 hard: -1 networks: - elastic volumes: data01: driver: local data02: driver: local data03: driver: local networks: elastic: driver: bridge external: true 注意这里将集群的网络设置为external，这样后续的logstash才能找到服务节点。此外，由于笔者的机器可用存储较小，因此设置es的存储占用设置为128m。实际使用时，可以按照需求进行调整。 运行docker-compose up -d即可后台启动。启动后，curl -X GET \u0026quot;localhost:9200/_cat/nodes?v=true\u0026amp;pretty\u0026quot; 判断集群状态。\n# Logstash 安装 collect, parse transform logs\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: \u0026#39;2\u0026#39; services: logstash: image: docker.elastic.co/logstash/logstash:7.15.0 container_name: logstash user: root ports: - 5004:5004 volumes: - ./config:/usr/share/logstash/config/ - /etc/localtime:/etc/localtime command: bash -c \u0026#34;cd /usr/share/logstash \u0026amp;\u0026amp; logstash -f config/online.conf\u0026#34; networks: - elastic networks: elastic: driver: bridge external: true 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 # ./config/online.conf input { # 这里支持多种 input beats { port =\u0026gt; 5004 codec =\u0026gt; \u0026#34;json\u0026#34; } } filter { # 这里基于 ruby 脚本进行过滤 ruby { path =\u0026gt; \u0026#34;./config/filter.rb\u0026#34; } } output { # 这里将过滤后的结果输出到标准输出及 es 中 stdout { codec =\u0026gt; json } elasticsearch { hosts =\u0026gt; [\u0026#34;es01:9200\u0026#34;] index =\u0026gt; \u0026#34;logstash\u0026#34; #user =\u0026gt; \u0026#34;\u0026#34; #password =\u0026gt; \u0026#34;\u0026#34; } } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # config/filter.rb # 按照 online.conf 中的配置，logstash 启动后，会读取 filter.rb，并使用 filter 函数作为过滤函数。 require \u0026#34;json\u0026#34; BEGIN{ puts \u0026#34;start event filter\u0026#34; } END{ puts \u0026#34;end event filter\u0026#34; } def filter(event) puts event if event.get(\u0026#34;[errno]\u0026#34;) != 0 return [] end valid_age = 0 event.get(\u0026#34;[data]\u0026#34;).each{ | info | if info[\u0026#34;age\u0026#34;] \u0026lt; 10 valid_age += info[\u0026#34;age\u0026#34;] end } event.set(\u0026#34;[data]\u0026#34;, valid_age) return [event] end logstash 启动后，会监听容器内的 5004 接口（配置于online.conf中），如果有信息传入，则会经过filter.rb中的 filter() 函数对数据进行处理。而后输出到标准输出及 es01容器5004端口的elasticsearch服务。由于elasticsearch及logstash容器使用了相同的网络，因此可以互相感知。\n# filebeat 安装 filebeat 作为轻量级的日志收集器，仅占用很少的资源，即可完成日志的采集，并且转发至配置的logstash进行后续的处理、归档等操作。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 version: \u0026#39;2\u0026#39; services: filebeat: image: docker.elastic.co/beats/filebeat:7.16.0 container_name: filebeat user: root environment: - strict.perms=false volumes: - ./filebeat.yml:/usr/share/filebeat/filebeat.yml - ./data:/usr/share/filebat/data networks: - elastic command: bash -c \u0026#34;cd /usr/share/filebeat \u0026amp;\u0026amp; filebeat -e -c ./filebeat.yml\u0026#34; networks: elastic: driver: bridge external: true 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # filebeat.yml filebeat.inputs: - type: log enabled: true paths: - /usr/share/filebeat/input.log filebeat.config: modules: path: ${path.config}/modules.d/*.yml reload.enabled: false filbeat.autodiscover: providers: - type: docker hints.enabled: true output.logstash: hosts: \u0026#34;logstash:5004\u0026#34; 容器启动后，会监听/usr/share/filebeat/input.log文件。当该文件发生变更时，filebeat会读取增量的内容并进行转发。\n# let it run 经过上述步骤，一个简单的日志监听、采集、处理、存档的流程就构建了。为了测试，可以在filebeat容器的/usr/share/filebeat/input.log中写入：\n1 {\u0026#34;errno\u0026#34;: 0,\u0026#34;data\u0026#34;: [{\u0026#34;age\u0026#34;: 9,\u0026#34;name\u0026#34;: \u0026#34;tt\u0026#34;},{\u0026#34;age\u0026#34;: 8,\u0026#34;name\u0026#34;: \u0026#34;gg\u0026#34;}]} 按照logstash:online.conf的逻辑，会向elasticsearch的logstash写入信息。\n# 参考文献 Linux-ELK日志收集 Install Elasticsearch with Docker Logstash介绍 ","date":"2022-01-04T00:06:00Z","permalink":"https://liyan-ah.github.io/p/elk-docker-%E5%AE%9E%E8%B7%B5/","title":"ELK-docker 实践"},{"content":" Quic 协议作为应用层的协议，在无线、弱网场景下的移动通信领域有广阔的应用场景。本文简单记录一些 Quic 的知识点，同时附上介绍的详细文章；\n# Quic 协议 Quic协议是应用层（5层网络模型下，由于基于传输层协议，笔者倾向于认为其是应用层协议，但是博文中多次标注其是传输层协议），对标 HTTP 协议，基于 UDP 协议构建。\n# Quic 协议优点 建立连接延时低。相对于 HTTP 协议的至少 3RTT 的建联，Quic 协议可以实现 0RTT 建联； 改进了拥塞控制。将拥塞控制算法的选择交由应用程序控制；同时抛弃了基于 TCP 的 seq 标记，改由严格递增的 package number + offset，优化了拥塞时的重传； 举例，需要传递 N,N+1,N+2 三个包，传递过程中，N 丢失了；TCP的重传会将N,N+1,N+2三个包都重传；Quic 会重传一个 N+3（即package_num+1），但是 offset 记为 0（即stream_offset不变）。这样在另一端将三个包按照 offset 重新进行组织； 基于 Connection 及 Stream 进行多路复用； 消除队头阻塞，更好的支持多路复用，处理多个会话时，不会因为其中一个会话的丢失，导致其他会话结果也重传(TCP消息重传逻辑)； 默认支持加密认证； # 总结 Quic 协议相当于在 UDP 的基础上，在更高层次协议上实现了 TCP 的大部分功能：可靠传输，拥塞控制等，同时对 TCP 的这些功能进行了优化；\n# 参考文献 技术扫盲：新一代基于UDP的低延时网络传输层协议——QUIC详解\n","date":"2021-11-09T21:11:00Z","permalink":"https://liyan-ah.github.io/p/quic%E5%8D%8F%E8%AE%AE/","title":"Quic协议"},{"content":" 微软推出的language server protol 确实提升了文本编辑器的使用体验。就 emacs 的使用而言，配合各个语言的 lsp 实现，能够减少配置语言开发环境的难度。这里记录一下使用 emacs 中的 rust, golang, python, c/c++ lsp 配置\n# rust 这里使用 rust-analyzer 作为 rust 的语言服务器，在安装 rust-mode后，通过绑定语言服务器信息，即可在打开由 cargo 创建的工程时，顺利进入 lsp-mode。需要关注的是，在非cargo创建的项目中，笔者的lsp-mode使用体验很差，甚至缺少代码补充、语法提示等功能。可能是rust-analyzer主要是针对cargo项目进行的设置，也可能是笔者设置的问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 ;; config for rust-lsp for emacs ;; rls install address: https://github.com/rust-lang-nursery/rls (unless (package-installed-p \u0026#39;rust-mode) (w-install \u0026#39;rust-mode)) (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\.rs\\\u0026#39;\u0026#34; . rust-mode)) (add-hook \u0026#39;rust-mode-hook \u0026#39;lsp) (unless (package-installed-p \u0026#39;rustic) (w-install \u0026#39;rustic)) (unless (package-installed-p \u0026#39;cargo) (w-install \u0026#39;cargo)) (use-package rustic) ; lsp-compatible rust mode (add-hook \u0026#39;rust-mode-hook \u0026#39;rustic-mode) (add-hook \u0026#39;rustic-mode-hook (lambda () (setq rustic-lsp-server \u0026#39;rust-analyzer) ; not rls (setq lsp-rust-analyzer-server-command \u0026#39;(\u0026#34;/opt/homebrew/bin/rust-analyzer\u0026#34;)) ;(setq rustic-format-on-save t) ; has annoying bug move point to other buffer bug (setq rustic-indent-offset 4) (setq rustic-match-angle-brackets nil) ;; thought this would be better, was wrong. ;(setq rustic-compile-display-method \u0026#39;popwin:display-buffer-1) ; display if possible in popup-win )) (use-package cargo) (setq lsp-rust-server \u0026#39;rust-analyzer) # golang golang作为谷歌的亲儿子，是拥有官方维护的语言服务器的。而且gopls的使用体验非常好，完全不逊色与目前用户较多的goland及vscode。配合dlv-mode使用，在调试上笔者认为能够更加的贴合unix风格，也更加方便。\n1 2 3 4 5 6 7 8 9 10 11 12 13 ;; Go - lsp-mode ;; Set up before-save hooks to format buffer and add/delete imports. ;; go install github.com/golang/tools/cmd/gopls ;;(require \u0026#39;lsp-mode) (setq lsp-ui-mode nil) (defun lsp-go-install-save-hooks () (add-hook \u0026#39;before-save-hook #\u0026#39;lsp-format-buffer t t) (add-hook \u0026#39;before-save-hook #\u0026#39;lsp-organize-imports t t)) (add-hook \u0026#39;go-mode-hook #\u0026#39;lsp-go-install-save-hooks) ;; Start LSP Mode and YASnippet mode (add-hook \u0026#39;go-mode-hook #\u0026#39;lsp-deferred) (add-hook \u0026#39;go-mode-hook #\u0026#39;yas-minor-mode) # python python的语言服务器，笔者目前使用的是lsp-python-ms进行配置的。这个插件解决了很多python lsp的问题（实际上，在碰到这个插件之前，笔者一度要放弃安装python lsp）。由于python是解释型语言，对象的成员都较为灵活，一般编码阶段很难确认对象的成员及其确切的类型。所以在pylsp使用过程中，往往会碰到无法有效提示的情况。满足一般提示需求吧。\n1 2 3 4 5 6 7 8 9 ;;; set env for python ;; copied from ;; https://gitee.com/nutora-emacs/lsp-python-ms ;; python lsp-server use python-lsp-server ;; install as: pip3 install python-lsp-server (ensure-package-installed \u0026#39;lsp-python-ms) (require \u0026#39;lsp-python-ms) (setq lsp-python-ms-auto-install-server t) (add-hook \u0026#39;python-mode-hook #\u0026#39;lsp) # c/c++ 实际上，笔者很喜欢c/c++的语言服务器，简单、方便，安装时无比的顺畅。完全符合笔者对c语言简单、强大、靠谱的印象。\n1 2 3 4 5 6 7 8 9 ;; set up lsp-mode for c/c++ ;; brew install llvm ;; https://clangd.llvm.org/installation (unless (package-installed-p \u0026#39;eglot) (w-install \u0026#39;eglot)) (require \u0026#39;eglot) (add-to-list \u0026#39;eglot-server-programs \u0026#39;((c++-mode c-mode) \u0026#34;clangd\u0026#34;)) (add-hook \u0026#39;c-mode-hook \u0026#39;eglot-ensure) (add-hook \u0026#39;c++-mode-hook \u0026#39;eglot-ensure) # 使用的一点备注 这里唠叨一点\n# lsp 的管理单位是文件目录 这里对于golang及rust尤为明显。在使用emacs打开一个关联了有效语言服务器的文件时，底部会提示为当前文件选择一个工作目录。尤其是，当路径A已经设为工作目录时，再将A/B设为工作目录，A/B的打开状态是会出现异常的。所以尽量保持每个工作目录的独特。\n这里附上一些emacs lsp-mode中笔者常用的函数：\n指令 说明 lsp-workspace-folders-remove 将工作目录移除 lsp-workspace-folders-add 添加工作目录 lsp-workspace-restart 重启工作目录 # 其他备注 当安装了一个语言的lsp服务及对应的emacs客户端配置时，如果打开对应语言的文件发现lsp没有生效，且打开toggle-debug-on-error设置开启也没有发现任何报错，笔者建议重启emacs。似乎emacs热加载功能往往不会如人所愿。\n# 参考文献 emacs lsp mode\n及其他网络文献\n","date":"2021-10-12T20:26:00Z","permalink":"https://liyan-ah.github.io/p/emacs-%E8%8B%A5%E5%B9%B2%E8%AF%AD%E8%A8%80-lsp-%E9%85%8D%E7%BD%AE%E5%A4%87%E6%B3%A8/","title":"emacs-若干语言 lsp 配置备注"},{"content":" 记一次redisgo库使用时，连接远程redis服务写数据报错的问题。\nredis写数据时，出现报错write: broken pipe及write: connection reset by peer。看着都是网络的问题，使用redis-cli可以登陆并且执行查询等操作。经过排查，是写的数据量过大，导致写数据持续时间过长，排查的思路是猜想-\u0026gt;验证@A@。\n对于多个数据可以进行拆分。对于单个完整的数据，还没有太好的拆分思路（或许基于 pb 进行压缩，会是个好方式？）\n# 参考文章 python redis读写报错：Broken Pipe Error Redis\n","date":"2021-08-18T17:26:00Z","permalink":"https://liyan-ah.github.io/p/redisgo-%E8%BF%9E%E6%8E%A5%E6%8A%A5%E9%94%99/","title":"redisgo 连接报错"},{"content":" php作为动不动搞个大事情世界上最好的语言,经常偶尔会出现由于版本升级导致的不兼容问题。笔者在工作中遇到了php7.1升级到php7.4导致的each弃用、mcrypt库启动导致的不兼容。在这里备注下兼容方式。\n# each弃用 从php7.2开始，官方开始弃用each函数。作为一个伪码农我是很震惊的，无法想象哪天python把range弃用了，代码维护人员是否有毅力将所有的历史内容都重新适配下。php官方就是这么任性自信，直接删除，不做兼容。网上找到的兼容方案是这样的：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 function func_new_each(\u0026amp;$array){ $res = array(); $key = key($array); if($key !== null){ next($array); $res[1] = $res[\u0026#39;value\u0026#39;] = $array[$key]; $res[0] = $res[\u0026#39;key\u0026#39;] = $key; }else{ $res = false; } return $res; } // 替换前 list($scalar_type, $scalar_value) = each($methName-\u0026gt;me); // 替换后 list($scalar_type, $scalar_value) = func_new_each($methName-\u0026gt;me); # mcrpt库弃用 这个更狠了，整个库直接弃用。改为推荐openssl。好在工程不是长期维护的，后续可能还有重构的规划，所以以解决问题为优先目标吧，直接将废弃的mcrypt作为插件，重新编入php7.4:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 #! /bin/bash # any problem please contact me # used to install mcrypt.so extentions for php php_path=${1:-\u0026#34;/usr/local/php\u0026#34;}; echo \u0026#34;install php under ${php_path}\u0026#34;; function Info(){ echo `whoami`@`hostname`:`pwd`; } function check_env(){ mised=1; for i in {0}; do set -x; command -v ${php_path}/bin/php \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || break command -v ${php_path}/bin/phpize \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || break command -v ${php_path}/bin/php-config \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 || break set +x; mised=0; done return ${mised}; } check_env; if [ $? -ne 0 ]; then echo \u0026#34;missing php exe file\u0026#34;; exit 233; fi # wget mcrypt wk_dir=\u0026#34;${HOME}/php_extend\u0026#34;; mkdir -p ${wk_dir}; if [ $? -ne 0 ]; then echo \u0026#34;cannot create ${wk_dir}, check permission\u0026#34;; exit 20; fi rm -rf ${wk_dir}/*; cd ${wk_dir} \u0026amp;\u0026amp; wget http://pecl.php.net/get/mcrypt-1.0.4.tgz; if [ $? -ne 0 ]; then echo \u0026#34;download mcrypt-1.0.4 failed\u0026#34;; exit 23; fi # prepare cd ${wk_dir} \u0026amp;\u0026amp; tar -xvf mcrypt-1.0.4.tgz; cd ${wk_dir}/mcrypt-1.0.4 \u0026amp;\u0026amp; ${php_path}/bin/phpize; if [ $? -ne 0 ]; then echo \u0026#34;mcrypt path init failed\u0026#34;; exit 233; fi # configure cd ${wk_dir}/mcrypt-1.0.4 \u0026amp;\u0026amp; ./configure --prefix=${wk_dir}/mcrypt --with-php-config=${php_path}/bin/php-config; if [ $? -ne 0 ]; then echo \u0026#34;=========\u0026gt; attention that, configure failed, would try to make\u0026#34;; fi # XXX: there is a sudo cd ${wk_dir}/mcrypt-1.0.4 \u0026amp;\u0026amp; make \u0026amp;\u0026amp; sudo make install # check if has output extend_dir=$(${php_path}/bin/php-config --extension-dir); if [ ! -f \u0026#34;${extend_dir}/mcrypt.so\u0026#34; ]; then echo \u0026#34;======\u0026gt; mcrypt.so generate failed\u0026#34;; exit 233; fi ini_dir=$(${php_path}/bin/php-config --ini-path); if [ ! -f \u0026#34;${ini_dir}/php.ini\u0026#34; ]; then echo \u0026#34;======\u0026gt; missing php ini file, ${ini_dir}/php.ini\u0026#34;; exit 233; fi cat \u0026lt;\u0026lt; EOF mcrypt.so is generated in ${extend_dir}/mcrypt.so, please do with sudo permission: echo \u0026#34;extension=mcrypt.so\u0026#34; \u0026gt;\u0026gt; ${ini_dir}/php.ini EOF # XXX: there is a sudo # need sudo, and should run ok #sudo echo \u0026#34;extension=mcrypt.so\u0026#34; \u0026gt;\u0026gt; ${ini_dir}/php.ini #if [ $? -ne 0 ]; then # echo \u0026#34;cannot write `extension=mcrypt.so` into ${ini_dir}/php.ini, please check permission\u0026#34;; # exit 2333; #fi # #echo \u0026#34;mcrypt.so install ok\u0026#34;; 语言的兼容性确实像噩梦一样。希望不要老是整这些幺蛾子。\n# 参考文献 php7.2 废弃each方法 php7.2 安装 mcrypt扩展 ","date":"2021-08-02T20:34:48Z","permalink":"https://liyan-ah.github.io/p/php-7.1%E5%8D%87%E7%BA%A7%E8%87%B37.4%E5%85%BC%E5%AE%B9%E6%80%A7/","title":"PHP-7.1升级至7.4兼容性"},{"content":" go-simplejson是go lang语言中操作json非常方便的开源库。最近使用simplejson进行数据插入操作时遇到了问题，经过排查后最终解决。现记录如下。\n# 问题描述 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // 创建了一个json对象J，需要从其他地方获取剩余json信息后，插入到J中的data字段中。初始版本如下： import ( \u0026#34;fmt\u0026#34; simplejson \u0026#34;github.com/bitly/go-simplejson\u0026#34; ) func main() { js, _ := simplejson.NewJson([]byte(` { \u0026#34;errno\u0026#34;: 0, \u0026#34;errmsg\u0026#34;: \u0026#34;test\u0026#34; }`)) var js_2 = new(simplejson.Json) *js_2 = *js jsArr := []*simplejson.Json{} js1, _ := simplejson.NewJson([]byte(`{\u0026#34;num\u0026#34;: 1}`)) js2, _ := simplejson.NewJson([]byte(`{\u0026#34;num\u0026#34;: 2}`)) jsArr = append(jsArr, js1) jsArr = append(jsArr, js2) js.Set(\u0026#34;data\u0026#34;, jsArr) js.Get(\u0026#34;data\u0026#34;).GetIndex(0).Set(\u0026#34;test\u0026#34;, 1) jsB, _ := js.MarshalJSON() fmt.Println(string(jsB)) } // % go run js_check.go // {\u0026#34;data\u0026#34;:[{\u0026#34;num\u0026#34;:1},{\u0026#34;num\u0026#34;:2}],\u0026#34;errmsg\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;errno\u0026#34;:0} # 问题排查 经过dlv逐行调试，实际问题出在js.Get(\u0026quot;data\u0026quot;).GetIndex(0).Set(\u0026quot;test\u0026quot;, 1)中。跳转至定义，该操作实际做如下转换:\n1 2 3 4 arr, ok := js.Get(\u0026#34;data\u0026#34;).data.([]interface{}) if ok { \u0026amp;simplejson.Json(arr[index]).Set(\u0026#34;test\u0026#34;, 1) } 这里由于jsArr是[]*simplejson.Json，类型断言为[]interface{}失败。所以无法正常设置值。查看simplejson.go，其中的Json对象结构如下：\n1 2 3 type Json struct { data interface{} } 其实可以通过js.Interface()获取其中的真实数据。\n# 解决方案 变更为如下代码即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 package main import ( \u0026#34;fmt\u0026#34; simplejson \u0026#34;github.com/bitly/go-simplejson\u0026#34; ) func main() { js, _ := simplejson.NewJson([]byte(` { \u0026#34;errno\u0026#34;: 0, \u0026#34;errmsg\u0026#34;: \u0026#34;test\u0026#34; }`)) var js_2 = new(simplejson.Json) *js_2 = *js jsArr := []interface{}{} js1, _ := simplejson.NewJson([]byte(`{\u0026#34;num\u0026#34;: 1}`)) js2, _ := simplejson.NewJson([]byte(`{\u0026#34;num\u0026#34;: 2}`)) jsArr = append(jsArr, js1.Interface()) jsArr = append(jsArr, js2.Interface()) js.Set(\u0026#34;data\u0026#34;, jsArr) js.Get(\u0026#34;data\u0026#34;).GetIndex(0).Set(\u0026#34;test\u0026#34;, 1) jsB, _ := js.MarshalJSON() fmt.Println(string(jsB)) } // % go run js_check.go // {\u0026#34;data\u0026#34;:[{\u0026#34;num\u0026#34;:1,\u0026#34;test\u0026#34;:1},{\u0026#34;num\u0026#34;:2}],\u0026#34;errmsg\u0026#34;:\u0026#34;test\u0026#34;,\u0026#34;errno\u0026#34;:0} ","date":"2021-07-22T17:58:00Z","permalink":"https://liyan-ah.github.io/p/go-simplejson-%E6%8F%92%E5%85%A5%E6%95%B0%E7%BB%84/","title":"go-simplejson 插入数组"},{"content":" 从过往的经历中来看，使用websocket作为http协议的替代似乎是一种潮流。websocket以其小包头、全双工的优势，弥补了http协议的性能上的缺陷。对于长链接需求，完全可以在初始化时创建websocket连接，在业务交互时直接进行通信，使得通信过程更加流畅。相信在基于Quic的http3协议走向成熟应用前，websocket在性能上都具有优势。本文以golang语言为基础，构造场景进行两种协议的性能对比。\n# 场景 在服务端分别启动了http服务及websocket服务，返回所接受到的信息。构造BenchmarkHttp、BenchmarkWS进行请求，发送递增字符串。\n# 代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 // server.go /* golang中使用的是http1.1协议，默认为长链接。仅第一次发送请求时进行握手。 */ package main import ( \u0026#34;flag\u0026#34; \u0026#34;fmt\u0026#34; \u0026#34;io\u0026#34; \u0026#34;log\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;sync\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; ) var ws_addr = flag.String(\u0026#34;ws_addr\u0026#34;, \u0026#34;localhost:9080\u0026#34;, \u0026#34;websocket http service address\u0026#34;) var http_addr = flag.String(\u0026#34;http_addr\u0026#34;, \u0026#34;localhost:9090\u0026#34;, \u0026#34;http address address\u0026#34;) var upgrader = websocket.Upgrader{} // use default options func ws_echo(w http.ResponseWriter, r *http.Request) { c, err := upgrader.Upgrade(w, r, nil) if err != nil { log.Print(\u0026#34;upgrade:\u0026#34;, err) return } defer c.Close() for { mt, message, err := c.ReadMessage() if err != nil { log.Println(\u0026#34;read:\u0026#34;, err) break } log.Printf(\u0026#34;recv: %s\u0026#34;, message) err = c.WriteMessage(mt, message) if err != nil { log.Println(\u0026#34;write:\u0026#34;, err) break } } } func http_echo(w http.ResponseWriter, req *http.Request) { req.ParseForm() echo_data := req.Form.Get(\u0026#34;echo\u0026#34;) fmt.Println(echo_data) io.WriteString(w, echo_data) return } func start_websocket() { http.HandleFunc(\u0026#34;/ws_echo\u0026#34;, ws_echo) log.Fatal(http.ListenAndServe(*ws_addr, nil)) } func start_http() { http.HandleFunc(\u0026#34;/http_echo\u0026#34;, http_echo) log.Fatal(http.ListenAndServe(*http_addr, nil)) } func main() { flag.Parse() log.SetFlags(0) wg := sync.WaitGroup{} wg.Add(2) go start_websocket() go start_http() wg.Wait() } 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 // web_test.go package main import ( \u0026#34;fmt\u0026#34; \u0026#34;io/ioutil\u0026#34; \u0026#34;net/http\u0026#34; \u0026#34;net/url\u0026#34; \u0026#34;strconv\u0026#34; \u0026#34;testing\u0026#34; \u0026#34;github.com/gorilla/websocket\u0026#34; ) func BenchmarkHttp(b *testing.B) { client := \u0026amp;http.Client{} for i := 0; i \u0026lt; b.N; i++ { i_str := strconv.Itoa(i) req, err := http.NewRequest(http.MethodGet, \u0026#34;http://localhost:9090/http_echo?echo=\u0026#34;+i_str, nil) if err != nil { fmt.Println(\u0026#34;create new request failed\u0026#34;, err.Error()) return } //b.ResetTimer() resp, err := client.Do(req) if err != nil { fmt.Println(\u0026#34;got http request error\u0026#34;, err.Error()) return } _, _ = ioutil.ReadAll(resp.Body) //fmt.Println(string(body)) } } func BenchmarkWs(b *testing.B) { addr := \u0026#34;localhost:9080\u0026#34; u := url.URL{Scheme: \u0026#34;ws\u0026#34;, Host: addr, Path: \u0026#34;/ws_echo\u0026#34;} c, _, err := websocket.DefaultDialer.Dial(u.String(), nil) if err != nil { fmt.Println(\u0026#34;Error, create websocket connect failed\u0026#34;) return } for i := 0; i \u0026lt; b.N; i++ { err = c.WriteMessage(websocket.TextMessage, []byte(strconv.Itoa(i))) if err != nil { fmt.Println(\u0026#34;write ws message failed, \u0026#34;, err.Error()) continue } _, message, err := c.ReadMessage() if err != nil { fmt.Println(\u0026#34;Error, recv message failed\u0026#34;) fmt.Println(string(message)) continue } //fmt.Println(string(message)) } err = c.WriteMessage(websocket.CloseMessage, websocket.FormatCloseMessage(websocket.CloseNormalClosure, \u0026#34;\u0026#34;)) c.Close() } # 结果 1 2 3 4 5 go test -bench=. -benchtime=3s -run=none BenchmarkHttp-8 57764\t62737 ns/op BenchmarkWs-8 101538\t36740 ns/op PASS ok web_perf\t8.850s 从结果中可以直观的看到，websocket协议有明显的性能优势。\n# 问题结论 上次提出了两个问题，后来经过测试，有了结论。这里贴一下。\n单个goroutine 崩溃时，该进程内其他的goroutine也会崩溃。通常的做法是使用一层wrapper，进行recover获取及现场、日志等保存； golang中线程的实现，runtime中，初始化时会申请内核态线程；见runtime/proc.go； # 问题思考 http1.0, http1.1, http2.0, http3.0, websocket, quic协议的介绍； rpc调用与websocket通信之间的网络延时对比； # 文章推荐 net/http长链接\u0026amp;连接池使用时的超时陷阱 换电脑后，hexo-next 窝火的报错 golang调度器初始化\n","date":"2021-07-15T19:29:10Z","permalink":"https://liyan-ah.github.io/p/http%E5%8F%8Awebsocket%E6%80%A7%E8%83%BD%E5%AF%B9%E6%AF%94/","title":"http及websocket性能对比"},{"content":" 写点东西还是难，果然还是搬运工来的轻松些。今天搬运点Golang的GMP模型看看。最近在准备一篇Golang的GC实践。慢慢搞吧。\n# 前言 Golang作为语言层面支持并发的语言，使用go可以让搬砖体验飞起。但是从直觉来说，事情并没有这么简单：从操作系统层面来说，进程和线程是操作系统认可的并行机制。协程以及Golang的所谓纤程是期望一堆程序员期望将操作系统的工作拿过来，以满足一些优化的效果。所以诸如Python的协程以及Golang的纤程，总是能够对应到操作系统认可的执行单元上。对于Python的协程还好理解一些，是严格运行在自己的线程里的，只是语言层面实现了线程内的上下文切换优化。所以对于CPU密集型的操作，仅使用协程是无法达到优化效果的：这种场景下Python会推荐多进程。相比起来，Golang的go野心更大一些：期望给用户以go作为接口，在语言内实现与操作系统调度单元的交互。Golang里实际的调度模型是GMP。\n# 搬运 这里搬运一些文章，介绍GMP。\n[典藏版] Golang 调度器 GMP 原理与调度全分析 从单进程开始介绍，后面的调试部分能学到一些东西\nGo语言学习 - GMP模型 G调度这块说的比较详细，可以看看\n6.5 调度器 # 日常膜拜\n# 思考 goroutine还是运行在一个进程里的。多线程想对比多进程，稳定性上会差一些：如果线程内出现了coredump等异常，整个进程可能就退出了。所以goroutine运行在一个进程内，会不会一个g出现了crash，整个程序崩溃？ Python的进程及线程，解释器层面分别使用了C的fork以及pthread(Linux)进行实现。g的实现是怎么样的。 ","date":"2021-04-15T21:39:29Z","permalink":"https://liyan-ah.github.io/p/golang-gmp/","title":"golang GMP"},{"content":" golang作为一种高级语言，实现了面向对象语言的封装、继承、多态的特性。本文简要介绍下golang面向对象的这些特性。\n# 封装 # 访问权限控制 Golang采用首字母大小写的方式控制访问权限。举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 // lib/pub.go package learn type A struct{ // 定义对象 private int Public string } func NewA(private int, public string) A{ return A{private: private, Public: public} } func (a A) PrintInf(){ // 可通过a.PrintInf() 访问该函数 print(a.private, a.Public) } var ( private = 1 Public = \u0026#34;aa\u0026#34; ) // main.go package main import ( \u0026#34;go_learn/lib\u0026#34; ) func main(){ a := learn.NewA(1, \u0026#34;aa\u0026#34;) print(a.Public, a.private) // a.private不可包外访问，编译报错 print(learn.private, learn.Public) // learn.private不可包外访问，编译报错 } 和 C++/Java/Python等常见的面向对象语言不同，Golang的结构体中不支持函数的定义。某个结构体的函数，可以通过函数名前的归属生命来表示。\n# 访问结构体私有成员 这是个很有意思的话题。C++和Python都是有方法可以越过结构体的访问限制的，Golang通过unsafe.Pointer类型的转换也可以达到相同的目的。举个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 // learn/pub.go package learn type A struct{ private int Public string } func (a A) PrintInf(){ print(a.private, a.Public) return } func NewA(private int, public string) A{ return A{private: private, Public: public} } var ( private = 1 Public = \u0026#34;aa\u0026#34; ) // main.go /* 测试golang封装、继承、多态特性 */ package main import ( \u0026#34;unsafe\u0026#34; \u0026#34;go_learn/lib\u0026#34; ) type AA struct{ Private int Public string } func main(){ a := learn.NewA(1, \u0026#34;aa\u0026#34;) //print(a.Public, a.private) //print(learn.Public, learn.private) p := unsafe.Pointer(\u0026amp;a) aa := \u0026amp;AA{} aa = (*AA)(p) // golang unsafe.Pointer 更加接近 C/C++中指针的用法，编译器进行的校验较少； print(aa.Private, aa.Public) // 可以正常运行。 } # 总结 简单备注了下Golang封装的特性。后续再备注下继承、多态的使用吧。由于Golang采用鸭子式的继承检查思想，继承和多态的特性使用会相对较繁琐。\n","date":"2021-04-08T21:16:00Z","permalink":"https://liyan-ah.github.io/p/golang-%E5%B0%81%E8%A3%85/","title":"golang 封装"},{"content":" 在日常的工作中，固定QPS或者固定并发数是常用的两个衡量系统容量时采用的流量控制手段。本文以Go语言高级编程 服务流量限制的内容为开端，对服务流量限制进行展开描述，同时对Jmeter及golang ratelimit中的流量限制方法进行描述。\n起因 漏桶法 令牌桶法 Jmeter中流量吞吐控制 golang ratelimit # 起因 流量限制手段在系统流量控制以及系统质量评估上都有广泛的应用。对于有多个子模块/下游的系统，如果已知其中一个模块/下游是整个系统处理能力的瓶颈，从系统的入口添加流量限制并添加超量告警，不失为是保护系统的有效手段。从质量保证的手段来说，在衡量一个系统的稳定性时，需要有一个有效的手段来控制给予系统的压力并进行控制。\n固定并发数量的流量控制方式是相对容易实现的：对于系统而言，可以添加一个连接池；对于请求方而言，维护一个请求并发池即可。对于固定QPS的流量控制手段而言，则又复杂一些：由于基本指令的直接支持，所以固定QPS的流量控制手段多在基于并发的流量控制上进行二次的封装。封装的措施实际上又会影响控制的效果。笔者曾经在搜索系统上，尝试基于Jmeter，使用1000个线程来产生一个固定的100QPS的并发数。由于Jmeter固定吞吐量实现的特点，导致实际产生的效果中，100个请求多集中在1分钟的前几秒，甚至是最开始1s的前若干ms。使得服务承受的顺势并发非常大，服务出现异常也是可以预见的事情了。\n了解一些流量控制的手段还是有必要的。本文主要梳理一下Go语言高级编程提到的漏桶及令牌桶两种方法，并且进行简单的实现。\n# 漏桶法 基于Leaky_bucket的描述，目前广泛流行的漏桶法存在两种模式：度量法（the leaky bucket as a meter）及队列法（the leaky bucket as a queue）。\n度量法在处理时，单位时间内的请求如果超过了预设的数量，会将请求丢弃。比如，需要固定的流量为100QPS，我们以100ms作为一个衡量单元，即10 query/100ms。则，在单位的100ms内，如果请求数量超过了10，则将超过10的请求丢弃。对于队列法，则会将超过的请求均放在一个队列里，在下个时间单位内，按照先进先出的原则，处理队列内的请求。\n在请求数量较多且分布均匀的场景下，度量法更加适用。系统已经处于处理的极限，额外的请求存储似乎不太现实。对于流量分布不均的场景下，队列法能够抹平流量的不均匀。在队列长度可控的场景下，队列法能够兼顾请求方（尽量不丢请求）及服务方（控制流量）。至于超出的部分，应该考虑引入告警等方式来把控风险。\n# 令牌桶法 对令牌桶法的详细介绍见Token bucket。令牌桶法可以认为是更加一般的漏桶法。严格意义上的漏桶法要求每次仅有一个单位的请求被允许，令牌桶法则将其扩展为固定时间段内，产出多个令牌，被请求申请。当令牌桶法每次仅允许一个令牌时，显然就成了漏桶法。\n# Jmeter中吞吐量的控制逻辑 笔者找到的Jmeter最新版本为ConstantThroughputTimer。在该实现中，主要分为单线程、多线程、共享线程等模式下的吞吐量（Jmeter中的吞吐量为Query Per Minutes)等模式。可以看出，Jmeter在不同的限流逻辑下，计算每个线程需要的delay时间实现jmeter的请求调度，体现了漏桶法的思路。 相关代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 // Calculate the delay based on the mode private long calculateDelay() { long delay; // N.B. we fetch the throughput each time, as it may vary during a test double msPerRequest = MILLISEC_PER_MIN / getThroughput(); switch (mode) { case AllActiveThreads: // Total number of threads delay = Math.round(JMeterContextService.getNumberOfThreads() * msPerRequest); break; case AllActiveThreadsInCurrentThreadGroup: // Active threads in this group delay = Math.round(JMeterContextService.getContext().getThreadGroup().getNumberOfThreads() * msPerRequest); break; case AllActiveThreads_Shared: // All threads - alternate calculation delay = calculateSharedDelay(allThreadsInfo,Math.round(msPerRequest)); break; case AllActiveThreadsInCurrentThreadGroup_Shared: //All threads in this group - alternate calculation final org.apache.jmeter.threads.AbstractThreadGroup group = JMeterContextService.getContext().getThreadGroup(); ThroughputInfo groupInfo = threadGroupsInfoMap.get(group); if (groupInfo == null) { groupInfo = new ThroughputInfo(); ThroughputInfo previous = threadGroupsInfoMap.putIfAbsent(group, groupInfo); if (previous != null) { // We did not replace the entry groupInfo = previous; // so use the existing one } } delay = calculateSharedDelay(groupInfo,Math.round(msPerRequest)); break; case ThisThreadOnly: default: // e.g. 0 delay = Math.round(msPerRequest); // i.e. * 1 break; return delay; } # golang ratelimit介绍 golang中也有很多请求控制的方法。工程中经常使用的 chan(bool)+WaitGroup池化了请求限制，可以认为是令牌桶法的思路的一种简化；golang自带的Ticker则会在固定的时间间隔内产生一个就绪的状态，可以看出漏桶法的思想。更加工程化的选择，可以看下golang ratelimituber开源的这个golang版本的ratelimit实现。水平优先，就贴一个网上找来的源码分析文章uber-go 漏桶限流器使用与原理分析。\n# 总结 本文对常用的两个限流方法漏桶法及令牌桶法进行了简单的描述。同时简单涉及了下Jmeter中的流量限制及golang中不同请求限制措施的思路。\n","date":"2021-02-07T17:30:00Z","permalink":"https://liyan-ah.github.io/p/ratelimit%E6%9C%8D%E5%8A%A1%E6%B5%81%E9%87%8F%E9%99%90%E5%88%B6/","title":"ratelimit服务流量限制"},{"content":" org-mode agenda界面变更任务状态、添加备注、添加日记（每日总结）、编辑记录\n以下操作均在org-agenda中的agenda for current week or day视图下快速编辑：\n操作 快捷键 变更任务状态 t 添加备注 z 添加日记 i 编辑note z 重建agenda r 打开日历 a 下周任务列表 f 上周任务列表 b 打开任务所在原始文件 enter ","date":"2021-01-11T21:49:00Z","permalink":"https://liyan-ah.github.io/p/org-mode%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"org-mode使用备注"},{"content":" 为了更好的live in emacs，一款合适的日程管理工具总是需要的。在挣扎了若干次后，最终还是把org-mode这一优秀的日程管理工具捡起来了。本文简单记录下使用的方法。\n# org-mode介绍 在神的编辑器emacs的传说中，往往有org-mode的身影。虽然按照(org官网)orgmode官网的描述，org-mode并不仅限于在emacs中使用，如开始使用 Org 模式吧，在没有 Emacs 的情况下这篇文章就详细讲解了在vscode中使用org-mode的方式，但是配合emacs的万物皆系于kbd之上的使用习惯，org-mode确实能够发挥最大的功能。\norg-mode的基本功能包括设置待办事项、设置待办的标签、查看日历、查看某一天的待办及进度。基本上，满足了对优秀日程管理工具的所有想象。\n这里贴一下开源世界旅行手册中涉及的org-mode与oneNote的对比，能够更加直观的了解org-mode的功能：\norg-mode vs oneNote Org-mode OneNote 标签 强大 不支持 日程表 强大 不支持 界面 字符 漂亮 TablePC 不支持 非常好 摘录 保持源格式 便捷 Emacs 内置 安装麻烦 # 基本使用流程 目前还处于探索阶段了，简单描述下org-mode的配置流程。 0. 版本 使用的是emacs-27.1版本，默认内置了org-mode(值得一提的是，当我在写一篇文章时，发现hexo#admin编辑器是支持部分emacs快捷键的，又反映了emacs影响之广)。\n设置\norg-mode在使用时，一般是在文本文档中编辑待办内容，将待办内容加入org-mode的日程表。而后通过org-agenda来查看指定日期的待办内容，并随着待办内容设置事务的进度。\n使用前，如果是使用emacs进行编辑的话，可以在emacs配置文件中作如下设置： 1 2 3 4 ;; 将.org结尾的文档，均以org-mode打开 (add-to-list \u0026#39;auto-mode-alist \u0026#39;(\u0026#34;\\.org\\\u0026#39;\u0026#34; . org-mode)) ;; 将org-agenda绑定为Ctrl-c a 快捷键 (global-set-key (kbd \u0026#34;C-c a\u0026#34;) \u0026#39;org-agenda) 重新打开emacs使配置生效，重新载入emacs配置文件即可。 使用时，可以单独建立一个文件夹，来存储不同需求的日程文档（如，笔者在~/.org/目录下创建了2021.org,learn.org等多个文档）。以下是一个简单的待办文档内容（引用自文章3）：\n1 2 3 4 5 6 7 8 9 10 11 #+STARTUP: overview #+TAGS: { 桌面(d) 服务器(s) } 编辑器(e) 浏览器(f) 多媒体(m) 压缩(z) #+TAGS: { @Windows(w) @Linux(l) } #+TAGS: { 糟糕(1) 凑合(2) 不错(3) 很好(4) 极品(5) } #+SEQ_TODO: TODO(T) WAIT(W) | DONE(D!) CANCELED(C@) #+COLUMNS: %10ITEM %10PRIORITY %15TODO %65TAGS * 工作 \u0026lt;2021-01-10\u0026gt;-\u0026lt;2022-01-10\u0026gt; ** Emacs \u0026lt;2021-01-10 21:00 ++1d\u0026gt; 神之编辑器 *** org-mode 组织你的意念 （更多的内容可以查看下原文，本文仅简单介绍） 以#+开头的可以认为是本地设置内容。#+TAGS: 后设置的内容，是本日程中预设的日程标签，标签()中的是该标签的缩写，需要保持唯一。在下面的日程（或者标题，可以很容易的看出来，和markdown是类似的语法）上使用快捷键Ctrl-c Ctrl-c(或者说，C-c C-c)，即可给日程打上标签。每个{}内的标签是互斥的，在设置时，可以注意下。\n下面的日程中,\u0026lt;2021-01-10\u0026gt;-\u0026lt;2022-01-10\u0026gt;表示该事件时间范围为2021-01-10至2022-01-10结束。\u0026lt;2021-01-10 21:00 ++1d\u0026gt;表示这个子任务的时间开始于2021-01-10 21:00而后每天重复一次(++1w，++1m为周、月，以此类推)。\n而后，保存文件。使用Ctrl-c [将当前日程文件纳入org-mode的日程表。使用前面配置的快捷键C-c a唤出日历，会出现如下提示：\nPress key for an agenda command: a 本周事件 t 显示所有事件 m 查询标签 L 当前缓冲区时间线 s 查询关键词 T 查询带 TODO 关键词的项 M 查询带 TODO 关键词的标签 # 显示已停止事件 q 退出日程表 选择a，可以查看本周的事件。如果已经到了所设置的事件区间，即可看到我们设置的事件内容。 以上算是简单的入门了。 # 相关文章 使用org-mode 管理日常事务- 日知录 用Org-mode实现GTD 组织你的意念：Emacs org mode. ","date":"2021-01-10T20:30:00Z","permalink":"https://liyan-ah.github.io/p/emacs-start-org-mode--org-mode%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"emacs! start org-mode! --org-mode使用备注"},{"content":" 使用emacs过程中，配合evil使用，按照tab的划分，将编辑、浏览、leetcode等任务划分到不同的tab便于切换及管理。美中不足的是，模拟标签的elscreen默认将其他标签的颜色设置成:background blue :foreground black的配色，每次切换任务时，都需要重复确认需要跳转到哪个标签，就比较麻烦了。查找了一下重置face-attribute的方法，备注下。\n在初始文件的最后添加：\n1 2 3 4 5 ;; 选中标签设置为绿底黑字，其他标签为黄底黑字 (set-face-attribute \u0026#39;elscreen-tab-other-screen-face nil :background \u0026#34;yellow\u0026#34; :foreground \u0026#34;black\u0026#34;) (set-face-attribute \u0026#39;elscreen-tab-current-screen-face nil :background \u0026#34;green\u0026#34; :foreground \u0026#34;black\u0026#34;) 备注下elscreen原始代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 (defface elscreen-tab-current-screen-face \u0026#39;((((class color)) (:background \u0026#34;white\u0026#34; :foreground \u0026#34;black\u0026#34;)) (t (:underline t))) \u0026#34;Face for current screen tab.\u0026#34; :group \u0026#39;elscreen) (defface elscreen-tab-other-screen-face \u0026#39;((((type x w32 mac ns) (class color)) :background \u0026#34;Gray85\u0026#34; :foreground \u0026#34;Gray50\u0026#34;) (((class color)) (:background \u0026#34;blue\u0026#34; :foreground \u0026#34;black\u0026#34; :underline t))) \u0026#34;Face for tabs other than current screen one.\u0026#34; :group \u0026#39;elscreen) emacs defface\n","date":"2020-12-23T19:23:00Z","permalink":"https://liyan-ah.github.io/p/elscreen%E6%A0%87%E7%AD%BE%E8%83%8C%E6%99%AF%E9%A2%9C%E8%89%B2/","title":"elscreen标签背景颜色"},{"content":" 最近开始使用Mac了。在使用过程中，发现了一些Mac OS和Centos体验上不同的地方。在这里做一下备注。\n# 部分Linux指令缺失 Mac OS并没有实现所有的Linux下的指令，如realpath这里就需要单独安装一些扩展包了：\nbrew install coreutils\n# 终端Basic颜色不友好 可以单独下载一些配色方案。从尽量使用原生配色的角度来说，只需要在.bashrc下面作如下配置即可：\n# for color\nexport CLICOLOR=1\n# grep\nalias grep=\u0026lsquo;grep \u0026ndash;color=always\u0026rsquo;\n此外，配合.vimrc中配色变更食用更佳：\n\u0026quot; 设置搜索高亮\nset hlsearch\n\u0026quot; 设置语法高亮\nsyntax on\n# 启动shell配置不同 Mac OS默认使用zsh作为登陆shell。所以设置.bashrc作为启动配置时，需要在~/.zshrc中进行配置：\n[ -f ~/.bashrc ] \u0026amp;\u0026amp; source ~/.bashrc\n后面碰到再补充吧。\n","date":"2020-12-10T19:40:00Z","permalink":"https://liyan-ah.github.io/p/mac%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"Mac使用备注"},{"content":"目录内容：\n1 text text.bak 希望从中找到text.bak。使用find实现。\n错误操作：\n1 2 3 \u0026gt;find -name *.bak* . find: paths must precede expression: . Usage: find [-H] [-L] [-P] [-Olevel] [-D help|tree|search|stat|rates|opt|exec] [path...] [expression] -name会作为EXPRESSIONS存在。find要求的参数位置为：\n1 find [-H] [-L] [-P] [-D debugopts] [-Olevel] [path...] [expression] 所以，正确格式为：\n1 2 find . -name *.bak ./text.bak 关于正则中.会作为通配符，如需匹配text.bak需要对.进行转义的情况，也需要关注下。本例中就不涉及了。\n","date":"2020-11-12T21:44:28Z","permalink":"https://liyan-ah.github.io/p/find%E5%8C%B9%E9%85%8D%E6%96%87%E4%BB%B6%E5%90%8D/","title":"find匹配文件名"},{"content":" # sed功能介绍 先看下官方的介绍\nSed is a stream editor. A stream editor is used to perform basic text transformations on an input stream (a file or input from a pipeline).\nWhile in some ways similar to an editor which permits scripted edits (such as ed), sed works by making only one pass over the input(s), and\nis consequently more efficient. But it is sed’s ability to filter text in a pipeline which particularly distinguishes it from other types of\neditors.\n大概的意思，是面向流的文本编辑工具。一般用来对文件中的文本进行替换等操作。\n以下备注一些常用的操作方式了。\n# 使用介绍 我们以上段文字为例，使用sed进行文本的操作。\n1 2 3 4 5 6 7 8 9 10 11 12 sed -i \u0026#34;s#Sed#SED#g\u0026#34; text 使用 -i 才可以直接修改 text 里面的内容，否则无法修改（但是会将修改后的内容输出到标准输出） 这里使用#作为sed的限位符而非/，是因为一般文本中，/符号出现的频率要较#高。直接使用#就不需要频繁转义了。 sed -i \u0026#39;2,2 s#in#in_#g\u0026#39; text 将 行号 [2,2] 中的 in 全部替换为 in_，注意，input也会被替换为in_put sed -i \u0026#39;/While.*/, /.*editors/ s#in#in_#g\u0026#39; text 将 While.* .*editors 之间的 in 全部替换为 in_ sed -i \u0026#39;2,+1 s#in#in_#g\u0026#39; text 将 [2, 2+1=3] 行内的 in 全部替换为 in_ 基本上常用的一些 sed替换方式就是这些了。man文档中还有一些基于倍数的替换范围决定方式，这里就不说明了。使用的时候，还是尽量使用通俗易懂的方式。\n","date":"2020-11-12T16:36:51Z","permalink":"https://liyan-ah.github.io/p/sed%E4%BD%BF%E7%94%A8%E5%A4%87%E6%B3%A8/","title":"sed使用备注"},{"content":"最近研究了一下pluma的使用。发现官网上的简单示例对于刚入门的人来说还是麻烦了些（而且还有语法错误）。\n下面重新整理了一个例子，作为备注。\n其中，device为一个虚基类，作为接口类存在。keyboard及screen作为实现了device的子类存在，实现具体的操作。在pluma上注册后，在main中调用接口，实现keyboard及screen的调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 // device.hpp #ifndef _DEVICE_HPP_ #define _DEVICE_HPP_ #include \u0026#34;Pluma/Pluma.hpp\u0026#34; class Device{ public: virtual std::string getDescription() const=0; }; // create DevicedProvider class PLUMA_PROVIDER_HEADER(Device); #endif 1 2 3 // device.cpp #include \u0026#34;device.hpp\u0026#34; PLUMA_PROVIDER_SOURCE(Device, 6, 3); 如上所示，是device的定义。其中PLUMA_PROVIDER_HEADER和PLUMA_PROVIDER_SOURCEpluma提供的宏。功能暂且不论。我们继续往下看。\n1 2 3 4 5 6 7 8 9 10 11 12 // screen.hpp #include \u0026#34;Pluma/Pluma.hpp\u0026#34; #include \u0026#34;device.hpp\u0026#34; class Screen: public Device{ public: std:: string getDescription() const{ return \u0026#34;screen\u0026#34;; } }; PLUMA_INHERIT_PROVIDER(Screen, Device); 1 2 3 4 5 6 7 8 9 10 11 12 // keyboard.hpp #include \u0026#34;Pluma/Pluma.hpp\u0026#34; #include \u0026#34;device.hpp\u0026#34; class Keyboard: public Device{ public: std:: string getDescription() const{ return \u0026#34;keyboard\u0026#34;; } }; PLUMA_INHERIT_PROVIDER(Keyboard, Device); 上面实现了screen及keyboard的逻辑。实现了之后，需要进行注册：\n1 2 3 4 5 6 7 8 9 10 11 12 // connect.cpp #include \u0026lt;Pluma/Connector.hpp\u0026gt; #include \u0026#34;keyboard.hpp\u0026#34; #include \u0026#34;screen.hpp\u0026#34; PLUMA_CONNECTOR bool connect(pluma::Host\u0026amp; host){ // add a keyboard provider to host host.add( new KeyboardProvider() ); host.add( new ScreenProvider() ); return true; } 这里在connect中进行了两个子类的注册。之所以使用connect是因为后面的pluma使用的时候，官网给出的示例代码中，会从connect入口开始调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 // main.cpp #include \u0026#34;Pluma/Pluma.hpp\u0026#34; #include \u0026#34;device.hpp\u0026#34; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; int main() { pluma:: Pluma plugins; plugins.acceptProviderType\u0026lt;DeviceProvider\u0026gt;(); plugins.load(\u0026#34;./plugin/connect.so\u0026#34;); //plugins.load(\u0026#34;./plugin/keyboard.so\u0026#34;); std::vector\u0026lt;DeviceProvider*\u0026gt; providers; plugins.getProviders(providers); std::cout\u0026lt;\u0026lt;\u0026#34;size for providers are:\u0026#34; \u0026lt;\u0026lt; providers.size()\u0026lt;\u0026lt; std:: endl; if (!providers.empty()){ for (std::vector\u0026lt;DeviceProvider*\u0026gt;::iterator device=providers.begin(); device != providers.end(); ++ device){ Device* myDevice = (*device)-\u0026gt;create(); std::cout \u0026lt;\u0026lt; myDevice-\u0026gt;getDescription() \u0026lt;\u0026lt; std::endl; delete myDevice; } } return 0; } 这里就是主要的调用逻辑了。官网中myDevice附近的拼写有主意，这是个坑了。\n这里回顾下目录结构：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 . ├── connect.cpp ├── device.hpp ├── device.cpp ├── keyboard.hpp ├── main.cpp ├── plugin # 用来存储插件结果的目录 ├── Pluma # 为了方便，这里将Pluma的include及src文件均拷贝到这里 │ ├── Config.hpp │ ├── Connector.hpp │ ├── Dir.cpp │ ├── Dir.hpp │ ├── DLibrary.cpp │ ├── DLibrary.hpp │ ├── Host.cpp │ ├── Host.hpp │ ├── PluginManager.cpp │ ├── PluginManager.hpp │ ├── Pluma.hpp │ ├── Pluma.inl │ ├── Provider.cpp │ ├── Provider.hpp │ └── uce-dirent.h └── screen.hpp 看下编译过程：\n1 2 3 4 5 # 生成device.so g++ connect.cpp device.cpp Pluma/*.cpp -shared -fPIC -o plugin/connect.so -I./ # 生成main g++ main.cpp device.hpp device.cpp Pluma/*.cpp -o main -I./ -ldl 执行：\n1 2 3 4 ./main size for providers are:2 keyboard screen 以上就是实践的内容了。\n","date":"2020-10-29T21:19:00Z","permalink":"https://liyan-ah.github.io/p/c-%E6%8F%92%E4%BB%B6%E7%AE%A1%E7%90%86--pluma%E5%AE%9E%E8%B7%B5/","title":"c++插件管理--pluma\u003c实践\u003e"},{"content":"\u0026lt;一\u0026gt; 这里记录一些python调试的方法：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # coding=UTF-8 \u0026#39;\u0026#39;\u0026#39; python debug method 1 use print function to get output informatino \u0026#39;\u0026#39;\u0026#39; DEBUG = True def _debug_(*args, **kwds): \u0026#39;\u0026#39;\u0026#39; depends on DEBUG value, print some function \u0026#39;\u0026#39;\u0026#39; global DEBUG if DEBUG: print(args, kwds) if __name__ == \u0026#34;__main__\u0026#34;: _debug_(\u0026#34;this is a test\u0026#34;) 最常见的调试方法了。print可以依据需求调整为其他的方式（logging输出日志或者直接输出到文件中均可）。\n1 2 # 输出结果如下： ((\u0026#39;this is a test\u0026#39;,), {}) \u0026lt;二\u0026gt;然后就是更直接一些的调试方法了\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 # coding=UTF-8 import pdb def test_function(): \u0026#39;\u0026#39;\u0026#39; regard it as a test funcion \u0026#39;\u0026#39;\u0026#39; try: a = 1 b = 0 c = a / b except Exception, e: pdb.set_trace() return if __name__ == \u0026#34;__main__\u0026#34;: test_function() 直接一点了，直接在代码中显式设置断点。这样，在异常发生时，就可以直接中断调试了。\npython中的pdb应该可以认为是一种阉割版的gdb了。仅对listprint及其他的python的内置函数有较好的支持。相互配合来看的话，也能发现很多问题。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # 输出如下： \u0026gt; test_debug.py(11)test_function() -\u0026gt; return (Pdb) list 6 a = 1 7 b = 0 8 c = a / b 9 except Exception, e: 10 pdb.set_trace() 11 -\u0026gt; return 12 13 if __name__ == \u0026#34;__main__\u0026#34;: 14 test_function() [EOF] (Pdb) print(e) integer division or modulo by zero (Pdb) print(a, b, c) *** NameError: name \u0026#39;c\u0026#39; is not defined (Pdb) print(a, b) (1, 0) (Pdb) quit() 唔，先这样吧。可以考虑收集一些python的内置解析包来配合调试了。\n","date":"2019-07-17T22:51:00Z","permalink":"https://liyan-ah.github.io/p/python%E8%B0%83%E8%AF%95%E6%96%B9%E6%B3%95%E5%85%B6%E4%B8%80/","title":"python调试方法（其一）"},{"content":"考虑以下场景：\n期望通过给定的变量名称var_str，打印出该名称对应的变量值${var_str}。使用指令eval可以很方便的实现：\n1 2 3 var_str=\u0026#34;1213\u0026#34;; ned_param_name=\u0026#34;var_str\u0026#34;; eval echo \u0026#39;$\u0026#39;\u0026#34;${ned_param_name}\u0026#34;; 输出结果为1213;\neval命令解释如下：\n1 2 3 4 5 6 7 eval [arg ...] The args are read and concatenated together into a single command. This command is then read and executed by the shell, and its exit status is returned as the value of eval. If there are no args, or only null arguments, eval returns 0. eval [参数 ...] 参数将会被读取并作为一个指令被读入。然后这个指令将会被shell读取并执行，执行结果 将会作为eval的结果。如果没有参数传入，或者只有空参数，eval指令将会返回0。 对于上述的例子，echo $var_str将会被读入，并被shell重新执行。输出结果为1213。该结果即作为eval的输出结果。\n","date":"2019-06-04T21:53:00Z","permalink":"https://liyan-ah.github.io/p/shell-%E8%AE%BF%E9%97%AE%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%90%8C%E5%90%8D%E5%8F%98%E9%87%8F/","title":"shell-访问字符串同名变量"},{"content":"lisp中，do循环形象如下:\n1 2 3 (do (variable-definition*) (end-test-form result-form*) statement*); 其中，(variable-definition*)是一些行日(var init next)的赋值结构。在do开始时，var会被赋值为init。并且在一次循环结束后，var会被赋值为next所表示的内容。\n形如：\n1 2 3 4 5 (do ((n 0 (+ 1 n)) (cur 0 next) (next 1 (+ cur next))) ((= 10 n) (format t \u0026#34;|end ~d\u0026#34; cur)) (format t \u0026#34;~d|\u0026#34; cur)); 输出：\n1 0|1|1|2|3|5|8|13|21|34||end 55 类似于python中的：\n1 2 3 4 5 6 cur = 0 next = 1 for i in range(10): print(\u0026#34;%d|\u0026#34; % cur) cur, next = next, cur + next print(\u0026#34;|end %d\u0026#34; % cur) ","date":"2019-06-03T22:42:00Z","permalink":"https://liyan-ah.github.io/p/lisp-do%E5%BE%AA%E7%8E%AF/","title":"lisp-do循环"},{"content":"lisp声明、使用变量的一种方法，是使用let语句。\n形如：\n1 2 3 4 5 6 7 8 9 10 11 12 ;(let ((variable declare1) (variable declare2) (...)) ; (varaible used here)); (defun foo(x) (format t \u0026#34;Parameter: ~a~%\u0026#34; x) (let ((x 2)) (format t \u0026#34;Outer LET: ~a~%\u0026#34; x) (let ((x 3)) (format t \u0026#34;Inner LET: ~a~%\u0026#34; x)) (format t \u0026#34;Outer LET: ~a~%\u0026#34; x)) (format t \u0026#34;Parameter: ~a~%\u0026#34; x)); (foo 10); 声明的作用域，和C语言很相似，存在覆盖的特点。输出：\n1 2 3 4 5 Parameter: 10 Outer LET: 2 Inner LET: 3 Outer LET: 2 Parameter: 10 使用let声明时，变量声明域内，无法使用前一个在本声明域内声明的变量：\n1 2 3 4 5 6 (defun year-day(y) (let ((m (* y 12)) (d (* m 30))) (format t \u0026#34;Year:~d~%Month:~d~%Day:~d~%\u0026#34; y m d))); (year-day 1); *** - LET: variable M has no value 使用let*可以进行如此操作：\n1 2 3 4 5 6 7 (defun year-day(y) (let* ((m (* y 12)) (d (* m 30))) (format t \u0026#34;Year:~d~%Month:~d~%Day:~d~%\u0026#34; y m d))); (year-day 1); Year:1 Month:12 Day:360 just like this.\n","date":"2019-05-30T22:51:00Z","permalink":"https://liyan-ah.github.io/p/lisp-let%E5%8F%98%E9%87%8F%E5%A3%B0%E6%98%8E/","title":"lisp-let变量声明"},{"content":"lisp中的lambda表达式，显然和python中的很相似。\n参照《实用common lisp编程》：\n1 2 3 4 5 6 7 8 ;按照 min max, 步长step为参数的fn计算的长度输出 * (defun plot (fn min max step) (loop for i from min to max by step do (loop repeat (funcall fn i) do (format t \u0026#34;*\u0026#34;)) (format t \u0026#34;~%\u0026#34;))) (plot #\u0026#39;exp 0 4 1/2); (plot #\u0026#39;(lambda (x) (* 2 x)) 0 10 1); 输出：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 * ** *** ***** ******** ************* ********************* ********************************** ******************************************************* ** **** ****** ******** ********** ************ ************** **************** ****************** ******************** #\u0026rsquo;为lisp语言的语法糖，展开表示为function。后者将会把一个函数生成为一个函数对象，后者可以通过funcall调用。\ninteresting。\n","date":"2019-05-29T23:28:00Z","permalink":"https://liyan-ah.github.io/p/lisp-lambda%E5%87%BD%E6%95%B0/","title":"lisp-lambda函数"},{"content":"目前，lisp的开发环境基本上被lispbox所垄断。所以本文来说一CLISP，C语言实现的LISP解释器的安装。\n1 2 3 4 5 wget \u0026#34;https://ftp.gnu.org/pub/gnu/clisp/latest/clisp-2.49.tar.gz\u0026#34; tar -xvf clisp-2.49.tar.gz cd clisp-2.49 ./configure --prefix=LOCAL_PATH --ignore-absence-of-libsigsegv cd src \u0026amp;\u0026amp; make \u0026amp;\u0026amp; make install 这样就可以将CLISP安装到\u0026ndash;prefix指定的路径。\n然后是使用。\n1 2 cd LOCAL_PATH/bin/ ./clisp 就会出现欢迎界面：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 i i i i i i i ooooo o ooooooo ooooo ooooo I I I I I I I 8 8 8 8 8 o 8 8 I \\ `+\u0026#39; / I 8 8 8 8 8 8 \\ `-+-\u0026#39; / 8 8 8 ooooo 8oooo `-__|__-\u0026#39; 8 8 8 8 8 | 8 o 8 8 o 8 8 ------+------ ooooo 8oooooo ooo8ooo ooooo 8 Welcome to GNU CLISP 2.49 (2010-07-07) \u0026lt;http://clisp.cons.org/\u0026gt; Copyright (c) Bruno Haible, Michael Stoll 1992, 1993 Copyright (c) Bruno Haible, Marcus Daniels 1994-1997 Copyright (c) Bruno Haible, Pierpaolo Bernardi, Sam Steingold 1998 Copyright (c) Bruno Haible, Sam Steingold 1999-2000 Copyright (c) Sam Steingold, Bruno Haible 2001-2010 Type :h and hit Enter for context help. [1]\u0026gt; 尝试进行函数求值：\n1 2 3 4 5 6 7 [1]\u0026gt; (defun sum(x y) (format t \u0026#34;~d\u0026#34; (+ x y))) SUM [2]\u0026gt; (sum 1 2) 3 NIL [3]\u0026gt; (exit) Bye. 或者，将以下内容写入test.lisp文件然后执行：\n1 2 3 (defun sum(x y) (format t \u0026#34;~d\u0026#34; (+ x y))) (sum 1 2) 执行LOCAL_PATH/bin/clisp test.lisp成功输出。\n","date":"2019-05-28T22:16:00Z","permalink":"https://liyan-ah.github.io/p/clisp%E7%BC%96%E8%AF%91/","title":"clisp编译"},{"content":"lisp语言的基本表达式为S-表达式。这与受Algol语言影响的C系语言有很大的不同。显然，这很有趣：\n1 2 3 4 5 ;the bellow is hello world function in lisp (defun hello-world() \u0026#34;hello world function in lisp\u0026#34; (format t \u0026#34;hello, world!\u0026#34;));``` 由\u0026lt;code\u0026gt;()\u0026lt;/code\u0026gt;所包围的内容，为*列表*，其余内容为原子。显然，lisp表达式有很多列表表示（List Processing)。 ","date":"2019-05-28T21:52:00Z","permalink":"https://liyan-ah.github.io/p/lisp-hello-world/","title":"lisp-hello world"}]